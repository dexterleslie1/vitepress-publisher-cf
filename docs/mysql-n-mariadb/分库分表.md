# 分库分表



## 介绍

MySQL分库分表是一个比较复杂的话题，它指的是将一个大型数据库拆分成多个更小的数据库（分库）和/或将一个数据库中的表拆分成多个更小的表（分表）。这样做主要为了解决单机数据库性能瓶颈，提高数据库的扩展性和可用性。  但同时也带来了数据一致性、分布式事务等新的挑战。

让我们从几个方面来探讨MySQL分库分表：

**1. 为什么需要分库分表？**

* **单机数据库性能瓶颈：** 当数据量过大，单机数据库的性能无法满足需求时，需要进行分库分表。  这包括查询速度变慢、写入速度变慢、磁盘I/O压力过大等。
* **单点故障：**  依赖单机数据库存在单点故障的风险，一旦数据库服务器宕机，整个系统就会瘫痪。分库分表可以提高系统的可用性。
* **硬件成本：**  单机数据库的硬件成本会随着数据量的增加而线性增长，分库分表可以降低硬件成本。


**2. 分库分表策略：**

* **水平分库分表：**  这是最常用的策略，指的是按照一定的规则将数据分散到不同的数据库和表中。常见的规则包括：
    * **按用户ID分库分表：**  将用户数据按照用户ID的范围分到不同的数据库或表中。
    * **按地理位置分库分表：**  将数据按照地理位置（例如省份、城市）分到不同的数据库或表中。
    * **按哈希值分库分表：**  使用哈希函数对主键进行计算，然后根据哈希值将数据分到不同的数据库或表中。  这可以更加均衡地分配数据。
    * **按日期分库分表：**  将数据按照日期分到不同的数据库或表中。  适合具有时间属性的数据。

* **垂直分库分表：**  指的是将数据库中的表按照功能模块进行拆分，将不同的表放到不同的数据库中。  例如，可以将用户信息表和订单信息表放到不同的数据库中。

**3. 分库分表带来的挑战：**

* **数据一致性：**  在分库分表后，需要保证数据的一致性，这需要使用分布式事务或其他一致性保证机制。
* **全局ID生成：**  需要一个全局ID生成器来保证ID的唯一性。
* **跨库查询：**  在分库分表后，跨库查询变得更加复杂，需要使用中间件或其他技术来解决。
* **数据迁移：**  分库分表后，可能需要进行数据迁移，这需要一个完善的数据迁移方案。
* **复杂度增加：**  分库分表增加了系统的复杂度，需要更高的运维成本。


**4. 常用的中间件：**

* **MyCat:**  一个开源的MySQL数据库中间件，可以实现分库分表，以及其他一些高级功能。
* **Sharding-JDBC:**  一个开源的JDBC代理，可以实现分库分表，无需修改代码。
* **360 Atlas:**  360公司开源的数据库中间件，功能强大，性能优异。

**5.  选择合适的策略：**

选择合适的策略需要根据实际情况，考虑数据量、查询模式、业务场景等因素。  如果数据量不大，或者查询模式比较简单，则不需要进行分库分表。  如果数据量很大，或者查询模式比较复杂，则需要选择合适的策略进行分库分表。

总而言之，MySQL分库分表是一个复杂的系统工程，需要仔细规划和设计。  在进行分库分表之前，需要充分评估其利弊，并选择合适的策略和中间件。  你有什么具体的问题吗？ 例如，你目前的数据库面临什么挑战？ 你想了解哪方面的细节？  告诉我更多信息，我可以更针对性地回答你的问题。



## 为何需要分库分表的 PoC

>todo 使用分区表技术是否能够解决 PoC 问题

### 场景描述

在电商场景中，订单数据是海量的。在海量数据情况下新增、查询订单的性能要求也是很高的。需求如下：

- 新增订单
- 根据订单 ID 查询
- 用户查询订单
  - 用户查询指定日期范围+所有状态的订单，查询条件**用户ID+订单删除状态（固定值未删除）+日期范围+分页**，新的订单排在最前。
  - 用户查询指定日期范围+指定状态的订单，查询条件**用户ID+订单状态+订单删除状态（固定值未删除）+日期范围+分页**，新的订单排在最前。
- 商家查询订单
  - 商家查询指定日期范围+所有状态的订单，查询条件**商家ID+订单删除状态+日期范围+分页** ，新的订单排在最前。
  - 商家查询指定日期范围+指定状态的订单，查询条件**商家ID+订单状态+订单删除状态+日期范围+分页** ，新的订单排在最前。

### 结果

详细用法请参考示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-scale-out-and-scale-up-poc` 的 OrderPerfTests

测试结果如下：

```
Benchmark                                            (databaseMemory)  (springProfile)   Mode  Cnt      Score        Error  Units
OrderPerfTests.testGetById                                       512m               1w  thrpt    3  72380.928 ± 110476.228  ops/s
OrderPerfTests.testGetById                                       512m              10w  thrpt    3   4632.219 ±  13523.535  ops/s
OrderPerfTests.testGetById                                       512m             100w  thrpt    3   3177.508 ±   2669.446  ops/s
OrderPerfTests.testGetById                                       512m             200w  thrpt    3   3320.235 ±   2769.689  ops/s
OrderPerfTests.testGetById                                       512m             300w  thrpt    3   3396.831 ±   4104.290  ops/s
OrderPerfTests.testGetById                                       512m             400w  thrpt    3   3646.733 ±   4549.670  ops/s
OrderPerfTests.testGetById                                       512m             500w  thrpt    3   3608.979 ±   4154.478  ops/s
OrderPerfTests.testGetById                                       512m              1kw  thrpt    3   4042.818 ±   2888.409  ops/s
OrderPerfTests.testGetById                                       512m              2kw  thrpt    3   5149.547 ±    844.557  ops/s
OrderPerfTests.testGetById                                       512m              3kw  thrpt    3   4792.952 ±   2113.506  ops/s
OrderPerfTests.testGetById                                       512m              5kw  thrpt    3   5491.243 ±   2525.230  ops/s
OrderPerfTests.testGetById                                       512m             10kw  thrpt    3   4110.091 ±  23807.502  ops/s
OrderPerfTests.testGetById                                         2g               1w  thrpt    3  86116.877 ±   7427.763  ops/s
OrderPerfTests.testGetById                                         2g              10w  thrpt    3   4026.605 ±   4273.267  ops/s
OrderPerfTests.testGetById                                         2g             100w  thrpt    3   3106.811 ±   2732.081  ops/s
OrderPerfTests.testGetById                                         2g             200w  thrpt    3   3126.006 ±   1483.135  ops/s
OrderPerfTests.testGetById                                         2g             300w  thrpt    3   3141.088 ±   2072.136  ops/s
OrderPerfTests.testGetById                                         2g             400w  thrpt    3   3326.246 ±   1030.679  ops/s
OrderPerfTests.testGetById                                         2g             500w  thrpt    3   3264.082 ±    267.817  ops/s
OrderPerfTests.testGetById                                         2g              1kw  thrpt    3   3410.775 ±    770.503  ops/s
OrderPerfTests.testGetById                                         2g              2kw  thrpt    3   3753.443 ±   3454.017  ops/s
OrderPerfTests.testGetById                                         2g              3kw  thrpt    3   3810.294 ±   3996.763  ops/s
OrderPerfTests.testGetById                                         2g              5kw  thrpt    3   5036.040 ±   4822.040  ops/s
OrderPerfTests.testGetById                                         2g             10kw  thrpt    3   5533.812 ±   3991.918  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m               1w  thrpt    3   6961.986 ±    188.954  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m              10w  thrpt    3   6787.534 ±    486.831  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             100w  thrpt    3   6800.024 ±    810.788  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             200w  thrpt    3   6698.767 ±    692.020  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             300w  thrpt    3   6036.964 ±   1205.780  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             400w  thrpt    3   4656.386 ±   3376.792  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             500w  thrpt    3   3897.630 ±   1745.542  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m              1kw  thrpt    3   2142.438 ±    408.728  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m              2kw  thrpt    3   1782.081 ±    454.955  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m              3kw  thrpt    3   1597.927 ±    383.316  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m              5kw  thrpt    3   1445.111 ±    231.377  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                     512m             10kw  thrpt    3   1318.561 ±    180.776  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g               1w  thrpt    3   6967.853 ±    831.255  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g              10w  thrpt    3   6921.607 ±    970.091  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             100w  thrpt    3   6810.424 ±    628.390  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             200w  thrpt    3   7031.991 ±    747.316  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             300w  thrpt    3   6783.933 ±    528.661  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             400w  thrpt    3   6737.221 ±    490.101  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             500w  thrpt    3   6925.204 ±   1410.309  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g              1kw  thrpt    3   6093.240 ±   1522.615  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g              2kw  thrpt    3   4703.413 ±   1078.760  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g              3kw  thrpt    3   3247.979 ±   3316.394  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g              5kw  thrpt    3   2178.358 ±   3314.161  ops/s
OrderPerfTests.testListByMerchantIdAndStatus                       2g             10kw  thrpt    3   1661.221 ±   1566.017  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m               1w  thrpt    3   7352.067 ±   1804.768  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m              10w  thrpt    3   7403.830 ±   1986.711  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             100w  thrpt    3   7475.767 ±   1707.617  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             200w  thrpt    3   7329.922 ±   2089.522  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             300w  thrpt    3   2406.029 ±    483.258  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             400w  thrpt    3   1676.011 ±    390.662  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             500w  thrpt    3   1344.672 ±    152.291  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m              1kw  thrpt    3    932.105 ±    249.321  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m              2kw  thrpt    3    701.114 ±    108.000  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m              3kw  thrpt    3    667.260 ±     30.304  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m              5kw  thrpt    3    595.053 ±     20.911  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus              512m             10kw  thrpt    3    563.377 ±    160.201  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g               1w  thrpt    3   7406.192 ±   1745.556  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g              10w  thrpt    3   7513.564 ±   1358.545  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             100w  thrpt    3   7364.323 ±   1913.298  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             200w  thrpt    3   7201.397 ±   2176.901  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             300w  thrpt    3   7246.256 ±   1823.870  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             400w  thrpt    3   7233.073 ±   1694.308  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             500w  thrpt    3   7248.923 ±   2110.194  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g              1kw  thrpt    3   6339.845 ±  18050.549  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g              2kw  thrpt    3   1543.406 ±   2212.919  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g              3kw  thrpt    3   1090.008 ±   1080.538  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g              5kw  thrpt    3    753.576 ±    899.312  ops/s
OrderPerfTests.testListByMerchantIdAndWithoutStatus                2g             10kw  thrpt    3    616.795 ±    311.903  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m               1w  thrpt    3   5793.917 ±   2038.185  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m              10w  thrpt    3   5961.553 ±   2156.963  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             100w  thrpt    3   6132.693 ±   2408.663  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             200w  thrpt    3   6228.570 ±    786.035  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             300w  thrpt    3   6361.761 ±    943.935  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             400w  thrpt    3   6591.528 ±   1330.949  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             500w  thrpt    3   6828.678 ±   1478.435  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m              1kw  thrpt    3   5951.631 ±    459.669  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m              2kw  thrpt    3   4750.496 ±   1392.160  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m              3kw  thrpt    3   4402.331 ±    860.324  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m              5kw  thrpt    3   4073.952 ±    395.386  ops/s
OrderPerfTests.testListByUserIdAndStatus                         512m             10kw  thrpt    3   4085.318 ±    556.830  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g               1w  thrpt    3   5882.163 ±   1864.754  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g              10w  thrpt    3   5921.221 ±   1031.198  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             100w  thrpt    3   6110.049 ±   1925.834  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             200w  thrpt    3   6304.817 ±   1882.837  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             300w  thrpt    3   6208.378 ±   1074.093  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             400w  thrpt    3   6327.695 ±   1015.877  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             500w  thrpt    3   6255.638 ±   2223.648  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g              1kw  thrpt    3   6381.064 ±   2030.206  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g              2kw  thrpt    3   6625.540 ±   1546.890  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g              3kw  thrpt    3   6515.792 ±   1290.068  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g              5kw  thrpt    3   5775.547 ±   1019.879  ops/s
OrderPerfTests.testListByUserIdAndStatus                           2g             10kw  thrpt    3   5352.496 ±    329.820  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m               1w  thrpt    3   4902.312 ±   4096.316  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m              10w  thrpt    3   4885.705 ±   3730.421  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             100w  thrpt    3   5221.466 ±    642.455  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             200w  thrpt    3   5213.212 ±    660.545  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             300w  thrpt    3   5745.586 ±   2148.176  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             400w  thrpt    3   6137.512 ±    675.973  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             500w  thrpt    3   6147.559 ±    154.274  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m              1kw  thrpt    3   5728.266 ±   1159.493  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m              2kw  thrpt    3   4269.926 ±    509.818  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m              3kw  thrpt    3   3998.645 ±    542.502  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m              5kw  thrpt    3   3666.444 ±   1022.558  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                  512m             10kw  thrpt    3   3658.705 ±    799.616  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g               1w  thrpt    3   4980.992 ±   3577.672  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g              10w  thrpt    3   4947.861 ±   1615.948  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             100w  thrpt    3   5112.123 ±   2149.943  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             200w  thrpt    3   5157.290 ±   1420.638  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             300w  thrpt    3   5422.897 ±   2122.159  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             400w  thrpt    3   5565.150 ±   3468.918  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             500w  thrpt    3   5454.005 ±   3474.087  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g              1kw  thrpt    3   5588.838 ±    899.687  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g              2kw  thrpt    3   6201.022 ±   1136.808  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g              3kw  thrpt    3   5727.930 ±    571.957  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g              5kw  thrpt    3   4646.497 ±    647.647  ops/s
OrderPerfTests.testListByUserIdAndWithoutStatus                    2g             10kw  thrpt    3   4394.166 ±    484.603  ops/s
```

结论：大部分业务查询在数据量超过 500w 后，性能会随着数据量继续增加呈现明显下降趋势，所以一般单表数据不宜超过 500w。



## 分库分表的方式

>todo MySQL 垂直分表、垂直分库、水平分表、水平分库 PoC

让我们用一个电商系统的例子来说明 MySQL 的垂直分表、垂直分库、水平分表、水平分库。假设这个电商系统包含以下几张表：

* `users` (用户表):  `user_id`, `username`, `password`, `email`, `address`, `phone`, `register_time` ...
* `products` (商品表): `product_id`, `product_name`, `description`, `price`, `stock`, `category_id` ...
* `orders` (订单表): `order_id`, `user_id`, `product_id`, `order_time`, `total_amount`, `status` ...
* `order_items` (订单详情表): `item_id`, `order_id`, `product_id`, `quantity`, `price` ...


**1. 垂直分表 (Vertical Table Sharding):**

* **原理:** 将一张表拆分成多张表，每张表包含原表的一部分列。  目的是降低单表数据量，提升查询速度。

* **例子:** 将 `users` 表拆分成 `users_profile` 和 `users_info` 两张表：

    * `users_profile`: `user_id`, `username`, `password`  (核心信息)
    * `users_info`: `user_id`, `email`, `address`, `phone`, `register_time` (扩展信息)

* **优点:**  降低单表数据量，提高查询特定字段的效率。
* **缺点:**  需要 JOIN 操作才能获取完整用户信息，增加了查询复杂度，可能会降低效率，尤其是在数据量很大的情况下。


**2. 垂直分库 (Vertical Database Sharding):**

* **原理:** 将不同的表放在不同的数据库实例中。

* **例子:**

    * `db_user`:  `users_profile`, `users_info` 表
    * `db_product`: `products` 表
    * `db_order`: `orders`, `order_items` 表

* **优点:**  隔离不同业务模块的数据，降低单库压力，提高可用性。 不同的业务模块可以使用不同规格的数据库实例，节省资源。
* **缺点:**  跨库 JOIN 查询变得非常复杂，性能严重下降，增加了分布式事务的难度。


**3. 水平分表 (Horizontal Table Sharding):**

* **原理:**  将一张表的数据拆分到多个表中，每个表存储原表的一部分数据。

* **例子:** 将 `orders` 表水平拆分成 `orders_0`, `orders_1`, `orders_2` 三个表，例如使用 `order_id % 3` 的方式：

    * `orders_0`:  `order_id`  % 3 == 0 的订单
    * `orders_1`:  `order_id`  % 3 == 1 的订单
    * `orders_2`:  `order_id`  % 3 == 2 的订单


* **优点:**  能够处理海量数据，提高数据库的读写性能。
* **缺点:**  需要使用分片键进行路由，增加应用层复杂度；跨分片查询困难；需要考虑数据一致性问题。


**4. 水平分库 (Horizontal Database Sharding):**

* **原理:** 将一张表的数据拆分到多个数据库实例中，每个数据库实例存储表的一部分数据。

* **例子:** 将 `orders` 表水平拆分到 `db_order_0`, `db_order_1`, `db_order_2` 三个数据库实例中，同样使用 `order_id % 3` 的方式。

    * `db_order_0`: `orders` 表 (存储 `order_id` % 3 == 0 的订单)
    * `db_order_1`: `orders` 表 (存储 `order_id` % 3 == 1 的订单)
    * `db_order_2`: `orders` 表 (存储 `order_id` % 3 == 2 的订单)


* **优点:**  大幅提高数据库处理能力，提升扩展性。
* **缺点:**  实现复杂，需要考虑数据一致性、事务、路由等问题；跨库查询变得非常困难；数据迁移和维护成本高。


**总结:**

不同的分库分表方式适用于不同的场景。  垂直分表和垂直分库比较容易实现，但扩展性有限；水平分表和水平分库扩展性好，但实现复杂。  实际应用中，常常会结合多种方式来解决问题，例如，可以先进行垂直分库，再对某些大表进行水平分库分表。  选择合适的方案需要根据具体的业务需求、数据量、性能要求等因素综合考虑。  同时，也需要选择合适的中间件来简化分库分表的开发和维护工作。



## 分库分表带来的新问题

- 事务一致性问题
- 跨节点关联查询
- 跨节点分页、排序
- 主键冲突
- 公共表



## Sharding-JDBC

详细用法请参考示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc`



### 介绍

Sharding-JDBC 是一个开源的 Java 框架，用于实现 MySQL 的分库分表功能。它通过在 JDBC 层面进行拦截，无需修改原有的数据库访问代码，即可实现数据库分片。  这意味着你只需要在你的 Spring Boot 或其他 Java 应用中添加 Sharding-JDBC 的依赖，并进行简单的配置，就可以将你的数据库访问自动路由到正确的数据库和表中，而无需修改大量的业务代码。

**主要功能和特性:**

* **透明化分库分表:**  无需修改原有 SQL 语句，Sharding-JDBC 会自动根据配置的规则将 SQL 语句路由到正确的数据库和表。
* **支持多种分片策略:**  支持多种分片算法，包括哈希分片、范围分片、列表分片等，可以根据实际情况选择合适的策略。
* **数据一致性保证:** 提供多种数据一致性解决方案，例如通过分布式事务或乐观锁来保证数据的一致性。
* **灵活的配置:**  通过配置文件或代码配置来实现分库分表，方便灵活地调整配置。
* **易于扩展:**  Sharding-JDBC 提供了丰富的扩展接口，方便用户自定义扩展功能。
* **完善的监控和管理:**  提供监控和管理功能，方便用户监控分库分表的状态和性能。
* **支持多种数据库:**  虽然主要针对 MySQL，但理论上支持其他多种关系型数据库。

**核心组件:**

* **Sharding-JDBC-Core:**  核心组件，提供分库分表、数据路由等功能。
* **Sharding-JDBC-Proxy:**  代理组件，在数据库连接层实现分库分表，无需修改应用代码。
* **Sharding-JDBC-Spring:**  Spring 集成组件，方便 Sharding-JDBC 与 Spring 框架集成。

**使用场景:**

* **海量数据存储:**  处理单表数据量过大的问题。
* **高并发访问:**  提高数据库的并发处理能力。
* **水平扩展:**  方便地进行数据库水平扩展。


**优点:**

* **易于使用:**  配置简单，无需修改大量代码。
* **高性能:**  性能损耗较低。
* **功能完善:**  提供丰富的功能，满足各种分库分表需求。
* **开源免费:**  可以免费使用。


**缺点:**

* **学习成本:**  需要学习 Sharding-JDBC 的配置和使用方式。
* **复杂性:**  对于复杂的场景，配置和维护可能比较复杂。
* **依赖 Java:**  只能在 Java 应用中使用。


**与其他分库分表方案的比较:**

相比于其他分库分表方案（例如自行编写代码实现分库分表），Sharding-JDBC 提供了更完善的功能和更简单的使用方式，减少了开发和维护的成本。  但它也有一定的学习成本，并且在极端复杂的场景下可能需要更深入的了解和定制。

总而言之，Sharding-JDBC 是一个功能强大、易于使用的 MySQL 分库分表框架，适合大多数需要进行分库分表的 Java 应用。  但需要根据实际情况选择合适的策略和配置，并充分了解其优缺点。



### 基本概念

Sharding-JDBC 的基本概念围绕着如何将一个大的数据库水平拆分成多个小的数据库（分库）以及一个大的表水平拆分成多个小的表（分表）来实现数据库水平扩展。  以下是几个核心概念：

**1. 分库分表 (Sharding):**  这是 Sharding-JDBC 的核心功能。它允许将数据库和表水平拆分成多个物理单元，以提高数据库的处理能力和存储容量。

* **分库 (Sharding Databases):** 将一个逻辑数据库拆分成多个物理数据库实例。例如，一个用户表可以被拆分成 user_db_0, user_db_1, user_db_2 等多个数据库。
* **分表 (Sharding Tables):** 将一个逻辑表拆分成多个物理表。例如，一个订单表可以被拆分成 order_table_0, order_table_1, order_table_2 等多个表，这些表可以分布在不同的数据库实例上，也可以在一个数据库实例上。

**2. 逻辑表和物理表 (Logical Table & Actual Table):**

* **逻辑表 (Logical Table):**  应用程序看到的表，它代表了所有分片表的集合。  应用程序不需要关心底层的分库分表细节，只需要操作逻辑表。
* **物理表 (Actual Table):**  实际存在于数据库中的表。  一个逻辑表对应多个物理表。

**3. 数据分片策略 (Sharding Strategy):**  决定如何将数据分片到不同的物理数据库和表中。  常用的策略包括：

* **范围分片 (Range Sharding):**  根据数据的某个范围进行分片。 例如，用户 ID 从 1 到 1000 的数据放在数据库 0，1001 到 2000 的数据放在数据库 1。
* **哈希分片 (Hash Sharding):**  使用哈希函数将数据映射到不同的分片。  例如，使用用户 ID 的哈希值对分片数量取模，来确定数据应该放在哪个分片。
* **广播表 (Broadcast Table):**  将表的数据复制到所有分片上。  常用于一些公共数据表。
* **键值分片（Key Sharding）：**  基于主键或者其他唯一键进行分片，类似于哈希分片，但是对键的处理更加直接。


**4. 分片键 (Sharding Key):**  用于确定数据应该分片到哪个数据库或表的键。  数据分片策略依赖于分片键。

**5. 配置文件 (Configuration File):**  用于配置 Sharding-JDBC 的各种参数，例如数据源、分库分表策略、路由规则等等。  通常使用 YAML 或 JSON 文件进行配置。

**6.  路由 (Routing):**  Sharding-JDBC 根据分片键和配置的路由规则，确定 SQL 语句应该发送到哪个物理数据库或表上执行。

**7.  透明化 (Transparency):**  Sharding-JDBC 对应用程序是透明的，应用程序不需要修改代码就能使用分库分表的功能。

**8.  分布式事务 (Distributed Transaction):**  在跨多个数据库分片的事务场景下，Sharding-JDBC 提供了分布式事务管理，保证数据一致性，这部分通常是最复杂的部分，需要选择合适的策略。

**9. 数据节点:** “数据节点”指的是实际存储数据的数据库实例。  它可以是一个单一的数据库服务器，也可以是数据库集群中的一个成员。  Sharding-JDBC 将逻辑数据库和表拆分成多个数据节点，实现水平扩展。数据节点概念与逻辑数据库和逻辑表密切相关。  一个逻辑数据库可以对应多个数据节点，一个逻辑表也可以对应多个数据节点上的多个物理表。  数据节点的具体数量和配置都取决于你的分库分表策略和应用需求。


理解这些基本概念是使用 Sharding-JDBC 的前提。  通过灵活运用这些概念和功能，可以方便地进行数据库水平扩展，提高数据库的性能和可用性。



### sharding-jdbc 和 MyBatis、SpringBoot 版本兼容性

- org.apache.shardingsphere:sharding-jdbc-spring-boot-starter 4.0.0-RC2 到 4.1.1 和 SpringBoot 2.2.7.RELEASE、mybatis-spring-boot-starter 2.3.2 兼容
- org.apache.shardingsphere:sharding-jdbc-spring-boot-starter 4.0.0-RC1 和 SpringBoot 2.2.7.RELEASE、mybatis-spring-boot-starter 2.3.2 不兼容
- org.apache.shardingsphere:shardingsphere-jdbc-core-spring-boot-starter 5.x 和 SpringBoot 任何版本、mybatis-spring-boot-starter 任何版本不兼容
- org.apache.shardingsphere:shardingsphere-jdbc-core 5.4.x 和 SpringBoot 3.4.0、mybatis-spring-boot-stater 3.0.4 不兼容
- org.apache.shardingsphere:shardingsphere-jdbc-core 5.1.2、5.2.x、5.3.x 和 SpringBoot 3.4.0、mybatis-spring-boot-starter 3.0.4、org.yaml:snakeyaml 1.33 兼容



### 和 SpringBoot 3.4.0 项目集成

>`https://blog.csdn.net/JingAi_jia917/article/details/140318444`
>
>`https://shardingsphere.apache.org/document/5.3.2/en/quick-start/shardingsphere-jdbc-quick-start/`

详细用法请参考示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc-with-springboot3.x`

尝试过 SpringBoot 3.x 项目和 org.apache.shardingsphere:sharding-jdbc-spring-boot-starter、org.apache.shardingsphere:shardingsphere-jdbc-core-spring-boot-starter 集成都不能成功启动项目，最终成功和 org.apache.shardingsphere:shardingsphere-jdbc-core 5.1.2、5.2.x、5.3.x 集成。

提示：使用 org.apache.shardingsphere:shardingsphere-jdbc-core 依赖，需要使用 sharding.yaml 配置 sharding-jdbc。

项目 pom 配置如下：

```xml
<properties>
    <maven.compiler.target>17</maven.compiler.target>
    <maven.compiler.source>17</maven.compiler.source>
</properties>

<dependencies>
    <dependency>
        <groupId>org.mariadb.jdbc</groupId>
        <artifactId>mariadb-java-client</artifactId>
    </dependency>
    
    <!-- sharding-jdbc 依赖 -->
    <dependency>
        <groupId>org.apache.shardingsphere</groupId>
        <artifactId>shardingsphere-jdbc-core</artifactId>
        <version>5.3.2</version>
    </dependency>
    <dependency>
        <groupId>org.yaml</groupId>
        <artifactId>snakeyaml</artifactId>
        <version>1.33</version>
    </dependency>

    <!-- mybatis依赖 -->
    <dependency>
        <groupId>org.mybatis.spring.boot</groupId>
        <artifactId>mybatis-spring-boot-starter</artifactId>
        <version>3.0.4</version>
    </dependency>
    <!-- 分页插件 -->
    <dependency>
        <groupId>com.github.pagehelper</groupId>
        <artifactId>pagehelper-spring-boot-starter</artifactId>
        <version>2.1.0</version>
    </dependency>
</dependencies>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-parent</artifactId>
            <version>3.4.0</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

Spring 数据源 application.properties 配置如下：

```properties
spring.datasource.driver-class-name=org.apache.shardingsphere.driver.ShardingSphereDriver
spring.datasource.url=jdbc:shardingsphere:classpath:sharding.yaml
```

sharding-jdbc 的 sharding.yaml 配置文件如下：

```yaml
dataSources:
  ds1:
    # 数据源使用的连接池类型
    dataSourceClassName: com.zaxxer.hikari.HikariDataSource
    driverClassName: org.mariadb.jdbc.Driver
    jdbcUrl: jdbc:mariadb://localhost:3306/demo?allowMultiQueries=true
    username: root
    password: 123456

rules:
  - !SHARDING
    tables:
      # 配置逻辑表order的分片规则
      order:
        # 列id使用内置的雪花算法生成分布式id
        keyGenerateStrategy:
          column: id
          keyGeneratorName: snowflake
        # 指定order表的数据分布情况，配置数据节点
        actualDataNodes: ds1.order_$->{1..2}
        # order表的分片策略，分片策略包括分片键和分片算法
        tableStrategy:
          standard:
            shardingColumn: id
            shardingAlgorithmName: order_inline
    # 配置order_inline分片算法
    shardingAlgorithms:
      order_inline:
        type: inline
        props:
          algorithm-expression: order_$->{id % 2 + 1}
    # 配置主键自动生成算法
    keyGenerators:
      snowflake:
        type: SNOWFLAKE

# 打开sql输出日志
props:
  sql-show: true
```

基于 MyBatis 的业务 SQL 编写只需要使用逻辑表 order 编写，不需要引用底层实际表。



### 和 SpringBoot 2.2.7.RELEASE 项目集成

详细用法请参考示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc`

org.apache.shardingsphere:sharding-jdbc-spring-boot-starter 4.0.0-RC2 到 4.1.1 和 SpringBoot 2.2.7.RELEASE、mybatis-spring-boot-starter 2.3.2 兼容

项目 pom 配置如下：

```xml
<properties>
    <maven.compiler.target>1.8</maven.compiler.target>
    <maven.compiler.source>1.8</maven.compiler.source>
</properties>

<dependencies>
    <dependency>
        <groupId>org.mariadb.jdbc</groupId>
        <artifactId>mariadb-java-client</artifactId>
    </dependency>
    <!-- sharding-jdbc 依赖 -->
    <dependency>
        <groupId>org.apache.shardingsphere</groupId>
        <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
        <version>4.1.1</version>
    </dependency>

    <!-- mybatis依赖 -->
    <dependency>
        <groupId>org.mybatis.spring.boot</groupId>
        <artifactId>mybatis-spring-boot-starter</artifactId>
        <version>2.3.2</version>
    </dependency>
    <!-- 分页插件 -->
    <dependency>
        <groupId>com.github.pagehelper</groupId>
        <artifactId>pagehelper-spring-boot-starter</artifactId>
        <version>2.1.0</version>
    </dependency>
</dependencies>

<dependencyManagement>
    <dependencies>
        <dependency>
            <groupId>org.springframework.boot</groupId>
            <artifactId>spring-boot-starter-parent</artifactId>
            <version>2.2.7.RELEASE</version>
            <type>pom</type>
            <scope>import</scope>
        </dependency>
    </dependencies>
</dependencyManagement>
```

application.properties 中的 sharding-jdbc 配置如下：

```properties
spring.shardingsphere.datasource.names=ds1
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mariadb://localhost:3306/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds1.username=root
spring.shardingsphere.datasource.ds1.password=123456

# 指定t_order表的主键生成策略为SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
# 指定order表的数据分布情况，配置数据节点
spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds1.order_$->{1..2}
# order表的分片策略，分片策略包括分片键和分片算法
spring.shardingsphere.sharding.tables.order.table-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order.table-strategy.inline.algorithm-expression=order_$->{id % 2 + 1}

# 打开sql输出日志
spring.shardingsphere.props.sql.show=true
```

基于 MyBatis 的业务 SQL 编写只需要使用逻辑表 order 编写，不需要引用底层实际表。



### 无法处理 LocalDateTime 数据类型问题

>`https://blog.51cto.com/u_11906056/7036294`

sharding-jdbc 和 SpringBoot 2.2.7.RELEASE（和 SpringBoot 3.4.0 集成不存在此问题）集成后，在处理 LocalDateTime 数据类型时报告错误 `org.springframework.dao.InvalidDataAccessApiUsageException: Error attempting to get column 'create_time' from result set.  Cause: java.sql.SQLFeatureNotSupportedException: getObject with type
; getObject with type; nested exception is java.sql.SQLFeatureNotSupportedException: getObject with type`，通过添加 MyBatis LocalDateTime 类型处理 typehandler 解决此问题：

```java
@Component
public class LocalDateTimeTypeHandler extends org.apache.ibatis.type.LocalDateTimeTypeHandler {
    public LocalDateTimeTypeHandler() {
    }

    @Override
    public void setNonNullParameter(PreparedStatement ps, int i, LocalDateTime parameter, JdbcType jdbcType) throws SQLException {
        ps.setTimestamp(i, new Timestamp(this.toTimeMillis(parameter)));
    }

    @Override
    public LocalDateTime getNullableResult(ResultSet rs, String columnName) throws SQLException {
        Timestamp sqlTimestamp = rs.getTimestamp(columnName);
        return sqlTimestamp != null ? this.toLocalDateTime(sqlTimestamp.getTime()) : null;
    }

    @Override
    public LocalDateTime getNullableResult(ResultSet rs, int columnIndex) throws SQLException {
        Timestamp sqlTimestamp = rs.getTimestamp(columnIndex);
        return sqlTimestamp != null ? this.toLocalDateTime(sqlTimestamp.getTime()) : null;
    }

    @Override
    public LocalDateTime getNullableResult(CallableStatement cs, int columnIndex) throws SQLException {
        Timestamp sqlTimestamp = cs.getTimestamp(columnIndex);
        return sqlTimestamp != null ? this.toLocalDateTime(sqlTimestamp.getTime()) : null;
    }

    private long toTimeMillis(LocalDateTime dateTime) {
        return dateTime.atZone(ZoneId.systemDefault()).toInstant().toEpochMilli();
    }

    private LocalDateTime toLocalDateTime(long timeMillis) {
        return new Date(timeMillis).toInstant().atZone(ZoneId.systemDefault()).toLocalDateTime();
    }
}
```



### 配置基于雪花算法的自动生成ID

详细用法请参考示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc`

application.properties 配置如下：

```properties
# 指定order表的主键生成策略为SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
```

OrderMapper 的新增方法 SQL 如下：

```java
@Insert("insert into `order`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time," +
        "received_time,cancel_time,delete_status) " +
        "values(#{createTime},#{userId},#{merchantId},#{totalAmount},#{totalCount}," +
        "#{status},#{payTime},#{deliveryTime},#{receivedTime},#{cancelTime},#{deleteStatus})")
@Options(useGeneratedKeys = true, keyProperty = "id")
void add(Order order);
```

- 不需要插入主键ID

```java
@SpringBootTest
public class OrderTests {

    @Resource
    OrderMapper orderMapper;

    @Test
    public void test() {
        this.orderMapper.truncate();

        for (int i = 0; i < 5; i++) {
            Order order = new Order();
            LocalDateTime now = LocalDateTime.now().truncatedTo(ChronoUnit.SECONDS);
            order.setCreateTime(now);
            order.setUserId(RandomUtil.randomLong());
            order.setMerchantId(RandomUtil.randomLong());
            order.setTotalAmount(new BigDecimal(1000));
            order.setTotalCount(10);
            order.setStatus(Status.Unpay);
            order.setDeleteStatus(DeleteStatus.Normal);
            this.orderMapper.add(order);

            Long id = order.getId();

            order = this.orderMapper.get(id);
            Assertions.assertEquals(id, order.getId());
            Assertions.assertEquals(Status.Unpay, order.getStatus());
            Assertions.assertEquals(now, order.getCreateTime());
        }
    }
}
```

- 插入 Order 时候不需要设置ID，因为会自动生成。



### 执行原理

#### 介绍

Sharding-JDBC 的执行流程比较复杂，但可以简要概括为以下几个阶段：

**1. SQL 解析与路由:**

* **SQL 解析:**  Sharding-JDBC 首先会拦截数据库操作的SQL语句。它会通过解析器将 SQL 语句解析成抽象语法树 (AST)。  这步至关重要，因为 Sharding-JDBC 需要理解 SQL 的含义才能进行路由。
* **路由:**  根据解析后的 SQL 语句，以及配置的路由规则，Sharding-JDBC 会决定将该 SQL 语句路由到哪个数据库分片(shard)上执行。  路由规则可以基于表名、字段值等多种条件。  这步决定了 SQL 语句最终会发送到哪个实际的数据库实例。  复杂的路由逻辑可能涉及多个分片。

**2. SQL改写 (Rewrite):**

*  在路由之后，Sharding-JDBC 会根据路由结果，对 SQL 语句进行改写。  这主要包括：
    * **添加分片键:**  如果 SQL 语句缺少分片键，Sharding-JDBC 会添加必要的条件来限制查询范围，确保只查询目标分片上的数据。
    * **修改表名:**  将逻辑表名替换成实际分片表名。
    * **拆分 SQL 语句:**  对于某些 SQL 语句（例如 JOIN 语句），Sharding-JDBC 可能会将其拆分成多个 SQL 语句，分别在不同的分片上执行，然后再将结果合并。

**3. SQL 执行:**

*  改写后的 SQL 语句会被发送到对应的数据库分片上执行。  Sharding-JDBC 使用 JDBC 连接池来管理数据库连接。

**4. 结果合并:**

*  如果 SQL 语句被拆分成了多个子查询，Sharding-JDBC 会将各个分片返回的结果进行合并，最终返回一个完整的查询结果集给应用程序。

**5. 事务管理:**

*  Sharding-JDBC 提供了分布式事务管理功能，确保跨多个分片的事务的一致性。  它支持多种分布式事务模式，例如 XA 事务、BASE 事务等等。  这部分是Sharding-JDBC最复杂的部分，依赖具体的配置和选择的分布式事务策略。

**简化流程图:**

```
[应用程序] --> [Sharding-JDBC拦截器] -->
    [SQL解析] --> [路由] --> [SQL改写] -->
    [发送到多个数据库分片] --> [数据库执行] -->
    [结果合并] --> [返回结果给应用程序]
```


**关键组件:**

* **拦截器 (Interceptor):**  拦截 JDBC 调用，并执行路由、改写等操作。
* **路由算法 (Routing Algorithm):**  决定将 SQL 语句路由到哪个数据库分片。
* **SQL 解析器 (SQL Parser):**  解析 SQL 语句，生成 AST。
* **SQL 改写器 (SQL Rewriter):**  根据路由结果改写 SQL 语句。
* **结果合并器 (Result Merger):**  将来自多个分片的查询结果合并。
* **事务管理器 (Transaction Manager):**  管理分布式事务。


需要注意的是，这只是一个高度简化的流程。  Sharding-JDBC 的实际执行流程会根据具体的配置、SQL 语句以及数据分片策略而有所不同。  理解其核心思想在于：它通过拦截、解析、路由和改写 SQL 语句，将一个针对逻辑数据库的请求转换为针对多个物理数据库分片的请求，并最终将结果合并，对应用程序屏蔽了数据库分片的细节。



#### 结果归并算法有哪些呢？

Sharding-JDBC的结果归并算法从功能上主要分为以下几种类型，每种类型都服务于不同的查询需求，它们之间是组合而非互斥的关系：

1. **遍历归并**：
   - 当只有一个数据节点返回结果集时，Sharding-JDBC会使用遍历归并。此时，归并过程相对简单，只需将单个结果集的数据返回即可。
2. **排序归并**：
   - 当查询语句包含排序要求时，需要使用排序归并。
   - 排序归并属于流式归并的一种，通过优先级队列（如最小堆或最大堆）实现。
   - 初始时，会对各个数据节点返回的结果集进行初始排序，并将其头部元素放入优先级队列。
   - 每次获取元素时，从优先级队列中取出最小的（或最大的）元素，然后将其所在结果集的下一个元素放入队列，并重新调整队列的优先级。
   - 这样可以确保每次获取的元素都是全局有序的。
3. **分组归并**：
   - 当查询语句包含分组要求时，需要使用分组归并。
   - 分组归并又可分为流式分组归并和内存分组归并两种。
     - 流式分组归并适用于分组字段较少且内存消耗不大的情况。它会逐条处理结果集中的数据，根据分组字段将数据分组存储。
     - 内存分组归并则适用于分组字段较多或内存消耗较大的情况。它会将结果集的所有数据加载到内存中，再进行分组处理。
4. **分页归并**：
   - 当查询语句包含分页要求时，需要使用分页归并。
   - 分页归并通常是在其他归并类型的基础上进行的装饰者归并。
   - 它会根据分页参数（如偏移量offset和限制行数limit）对结果集进行裁剪，只返回所需的数据行。
5. **聚合归并**：
   - 当查询语句包含聚合函数（如SUM、COUNT、AVG等）时，需要使用聚合归并。
   - 聚合归并会对各个数据节点返回的结果集进行聚合计算，返回最终的聚合结果。

此外，从结构划分上，Sharding-JDBC的结果归并算法还可以分为流式归并、内存归并和装饰者归并三种：

1. **流式归并**：
   - 流式归并是指每次只处理结果集中的一条数据，通过逐条处理的方式返回正确的单条数据。
   - 它的优点是能够极大减少内存的消耗，适用于结果集较大的情况。
   - 遍历、排序以及流式分组都属于流式归并的一种。
2. **内存归并**：
   - 内存归并是指将结果集的所有数据都加载到内存中，再进行归并处理。
   - 它的优点是处理速度快，但缺点是内存消耗较大。
   - 内存分组归并属于内存归并的一种。
3. **装饰者归并**：
   - 装饰者归并是指在其他归并类型的基础上进行的进一步处理。
   - 它的优点是可以灵活地对结果集进行各种处理，如分页、过滤等。
   - 分页归并通常是在其他归并类型的基础上进行的装饰者归并。

综上所述，Sharding-JDBC提供了多种结果归并算法以满足不同的查询需求。这些归并算法在功能上是组合而非互斥的，可以根据实际情况进行选择和组合使用。



### 分片策略和分片算法

Sharding-JDBC 的分片策略和分片算法是其实现数据分片功能的核心组件。以下是对这两者的详细解释：

一、分片策略（Sharding Strategy）

分片策略决定了数据应该被分配到哪些数据源或表中。Sharding-JDBC 提供了多种分片策略，以满足不同的业务需求。

1. **标准分片策略（Standard Sharding Strategy）**：
   - 提供对SQL语句中的`=`、`IN`和`BETWEEN AND`的分片操作支持。
   - 只支持单分片键。
   - 包含两个分片算法：`PreciseShardingAlgorithm`（用于处理`=`和`IN`的分片）和`RangeShardingAlgorithm`（用于处理`BETWEEN AND`分片）。其中，`PreciseShardingAlgorithm`是必选的，而`RangeShardingAlgorithm`是可选的。
2. **复合分片策略（Complex Sharding Strategy）**：
   - 同样提供对SQL语句中的`=`、`IN`和`BETWEEN AND`的分片操作支持。
   - 支持多分片键。由于多分片键之间的关系复杂，因此Sharding-JDBC并未做过多的封装，而是直接将分片键值组合以及分片操作符交于算法接口，由应用开发者自行实现，以提供最大的灵活度。
3. **行表达式分片策略（Inline Sharding Strategy）**：
   - 使用Groovy的行表达式，提供对SQL语句中的`=`和`IN`的分片操作支持。
   - 只支持单分片键。对于简单的分片算法，可以通过简单的配置使用，从而避免繁琐的Java代码开发。例如，`t_user_${user_id % 8}`表示`t_user`表按照`user_id`按8取模分成8个表，表名称为`t_user_0`到`t_user_7`。
4. **Hint分片策略（Hint Sharding Strategy）**：
   - 不通过SQL解析的方式分片，而是通过代码动态指定路由规则。
5. **不分片策略（None Sharding Strategy）**：
   - 不进行分片操作。

二、分片算法（Sharding Algorithm）

分片算法是实现具体分片逻辑的关键。Sharding-JDBC并未提供内置分片算法，而是通过分片策略将各种场景提炼出来，提供更高层级的抽象，并提供接口让应用开发者自行实现分片算法。目前提供的分片算法接口主要有以下几种：

1. **PreciseShardingAlgorithm**：
   - 用于处理使用单一键作为分片键的`=`与`IN`进行分片的场景。
   - 需要配合StandardShardingStrategy使用。
2. **RangeShardingAlgorithm**：
   - 用于处理使用单一键作为分片键的`BETWEEN AND`进行分片的场景。
   - 需要配合StandardShardingStrategy使用。
3. **ComplexKeysShardingAlgorithm**：
   - 用于处理使用多键作为分片键进行分片的场景。
   - 需要配合ComplexShardingStrategy使用。
4. **HintShardingAlgorithm**：
   - 用于处理使用Hint行分片的场景。
   - 需要配合HintShardingStrategy使用。

开发者可以根据自己的业务需求，实现上述接口中的`doSharding`方法，以定义具体的分片逻辑。例如，在实现`PreciseShardingAlgorithm`接口时，可以根据分片键的值来计算目标数据源或表的名称；在实现`RangeShardingAlgorithm`接口时，可以根据分片键的范围来确定目标数据源或表的集合。

总的来说，Sharding-JDBC的分片策略和分片算法为开发者提供了高度的灵活性和可扩展性，使得他们可以根据自己的业务需求来定制数据分片方案。



### 标准分片策略的精准分片算法 - PreciseShardingAlgorithm

application.properties 配置如下：

```properties
spring.shardingsphere.datasource.names=ds1,ds2
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mariadb://localhost:3306/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds1.username=root
spring.shardingsphere.datasource.ds1.password=123456

spring.shardingsphere.datasource.ds2.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds2.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds2.jdbc-url=jdbc:mariadb://localhost:3307/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds2.username=root
spring.shardingsphere.datasource.ds2.password=123456

spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2}

spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.props.worker.id=1

# 配置数据源分片算法
spring.shardingsphere.sharding.tables.order.database-strategy.standard.sharding-column=user_id
spring.shardingsphere.sharding.tables.order.database-strategy.standard.precise-algorithm-class-name=com.future.demo.algorithm.database.MyDatabaseStandardPreciseShardingAlgorithm

# 配置数据表分片算法
spring.shardingsphere.sharding.tables.order.table-strategy.standard.sharding-column=id
spring.shardingsphere.sharding.tables.order.table-strategy.standard.precise-algorithm-class-name=com.future.demo.algorithm.table.MyTableStandardPreciseShardingAlgorithm

```

数据源分片算法

```java
/**
 * 数据源精准分片算法
 */
@Slf4j
public class MyDatabaseStandardPreciseShardingAlgorithm implements PreciseShardingAlgorithm<Long> {
    /**
     * @param collection           spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2} 中已配置的数据源
     * @param preciseShardingValue 分片上下文参数
     * @return 数据所在的数据源名称
     */
    @Override
    public String doSharding(Collection<String> collection, PreciseShardingValue<Long> preciseShardingValue) {
        String logicTableName = preciseShardingValue.getLogicTableName();
        String columnName = preciseShardingValue.getColumnName();
        Long value = preciseShardingValue.getValue();
        log.info("All datasources {} logicTableName {} columnName {} value {}", collection, logicTableName, columnName, value);

        String dataSourceName = "ds" + (value % collection.size() + 1);
        if (!collection.contains(dataSourceName)) {
            throw new UnsupportedOperationException("数据源 " + dataSourceName + " 不存在");
        }

        return dataSourceName;
    }
}
```

数据表分片算法

```java
/**
 * 数据表精准分片算法
 */
@Slf4j
public class MyTableStandardPreciseShardingAlgorithm implements PreciseShardingAlgorithm<Long> {
    /**
     * @param collection           spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2} 中已配置的数据源
     * @param preciseShardingValue 分片上下文参数
     * @return 数据所在的数据表名称
     */
    @Override
    public String doSharding(Collection<String> collection, PreciseShardingValue<Long> preciseShardingValue) {
        String logicTableName = preciseShardingValue.getLogicTableName();
        String columnName = preciseShardingValue.getColumnName();
        Long value = preciseShardingValue.getValue();
        log.info("All tables {} logicTableName {} columnName {} value {}", collection, logicTableName, columnName, value);

        String tableName = logicTableName + "_" + (value % collection.size() + 1);
        if (!collection.contains(tableName)) {
            throw new UnsupportedOperationException("数据表 " + tableName + " 不存在");
        }

        return tableName;
    }
}
```



### 标准分片策略的范围分片算法 - RangeShardingAlgorithm

application.properties 配置如下：

```properties
spring.shardingsphere.datasource.names=ds1,ds2
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mariadb://localhost:3306/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds1.username=root
spring.shardingsphere.datasource.ds1.password=123456

spring.shardingsphere.datasource.ds2.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds2.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds2.jdbc-url=jdbc:mariadb://localhost:3307/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds2.username=root
spring.shardingsphere.datasource.ds2.password=123456

spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2}

spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.props.worker.id=1

# 配置数据源分片算法
spring.shardingsphere.sharding.tables.order.database-strategy.standard.sharding-column=user_id
spring.shardingsphere.sharding.tables.order.database-strategy.standard.precise-algorithm-class-name=com.future.demo.algorithm.database.MyDatabaseStandardPreciseShardingAlgorithm
# 配置范围分片算法，否则报告错误 Cause: java.lang.UnsupportedOperationException: Cannot find range sharding strategy in sharding rule.
spring.shardingsphere.sharding.tables.order.database-strategy.standard.range-algorithm-class-name=com.future.demo.algorithm.database.MyDatabaseStandardRangeShardingAlgorithm

# 配置数据表分片算法
spring.shardingsphere.sharding.tables.order.table-strategy.standard.sharding-column=id
spring.shardingsphere.sharding.tables.order.table-strategy.standard.precise-algorithm-class-name=com.future.demo.algorithm.table.MyTableStandardPreciseShardingAlgorithm
# 配置范围分片算法，否则报告错误 Cause: java.lang.UnsupportedOperationException: Cannot find range sharding strategy in sharding rule.
spring.shardingsphere.sharding.tables.order.table-strategy.standard.range-algorithm-class-name=com.future.demo.algorithm.table.MyTableStandardRangeShardingAlgorithm
```

数据源分片算法

```java
/**
 * 数据源范围分片算法
 */
@Slf4j
public class MyDatabaseStandardRangeShardingAlgorithm implements RangeShardingAlgorithm<Long> {
    /**
     * @param collection         spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2} 中已配置的数据源
     * @param rangeShardingValue
     * @return 数据所在的数据源名称集合
     */
    @Override
    public Collection<String> doSharding(Collection<String> collection, RangeShardingValue<Long> rangeShardingValue) {
        String logicTableName = rangeShardingValue.getLogicTableName();
        String columnName = rangeShardingValue.getColumnName();
        Range<Long> valueRange = rangeShardingValue.getValueRange();
        log.info("All datasources {} logicTableName {} columnName {} valueRange {}", collection, logicTableName, columnName, valueRange);

        // 通过判断 valueRange 计算数据所在的数据源，这里简单地返回所有数据源
        return collection;
    }
}

```

数据表分片算法

```java
/**
 * 数据表范围分片算法
 */
@Slf4j
public class MyTableStandardRangeShardingAlgorithm implements RangeShardingAlgorithm<Long> {
    /**
     * @param collection         spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2} 中已配置的数据源
     * @param rangeShardingValue
     * @return 数据所在的数据表名称列表
     */
    @Override
    public Collection<String> doSharding(Collection<String> collection, RangeShardingValue<Long> rangeShardingValue) {
        String logicTableName = rangeShardingValue.getLogicTableName();
        String columnName = rangeShardingValue.getColumnName();
        Range<Long> valueRange = rangeShardingValue.getValueRange();
        log.info("All tables {} logicTableName {} columnName {} value {}", collection, logicTableName, columnName, valueRange);

        // 通过判断 valueRange 计算数据所在的数据表，这里简单地返回所有数据源
        return collection;
    }
}

```

OrderMapper 范围查询

```java
@Select("select * from `order` where user_id>=#{startUserId} and user_id<=#{endUserId}")
List<Order> listByUserIdRange(@Param("startUserId") Long startUserId, @Param("endUserId") Long endUserId);
```

范围查询测试代码

```java
/**
 * 测试标准分片策略的范围分片算法
 */
@Test
public void testStandardStrategyRangeShardingAlgorithm() {
    List<Order> orderList = this.orderMapper.listByUserIdRange(1L, 10000L);
    Assertions.assertEquals(0, orderList.size());
}
```



### 水平分表

配置逻辑表 order 根据 id%2+1 分片到 order_1 和 order_2 表中



#### 介绍

Sharding-JDBC水平分表是一种数据库分片技术，旨在通过横向拆分表来提高数据库的扩展性和性能。以下是对Sharding-JDBC水平分表的详细解释：

一、基本概念

- **水平分表**：又称为横向拆分，是指将一个表中的数据按照某种规则（如主键、时间等）分散到多个表中。每个表中的数据只是原表数据的一部分，但表的结构与原表相同。
- **Sharding-JDBC**：是一个轻量级的Java框架，可以视为增强版的JDBC驱动。它使用客户端直连数据库，以jar包形式提供服务，无需额外部署和依赖。Sharding-JDBC支持分库分表、读写分离、分布式主键等功能，并兼容JDBC和各种ORM框架。

二、实现原理

Sharding-JDBC水平分表的实现原理主要包括以下几个方面：

- **分片规则**：根据业务需求，定义数据分片的规则。例如，可以根据主键的奇偶性、时间范围、地域等字段进行分片。
- **数据源配置**：配置多个数据源，每个数据源对应一个或多个物理数据库。Sharding-JDBC会根据分片规则，将数据路由到相应的数据源。
- **SQL解析与改写**：Sharding-JDBC会对SQL语句进行解析，根据分片规则将SQL语句改写为多个子查询，然后分别发送到对应的数据源执行。
- **结果归并**：将各个数据源返回的结果集进行归并处理，得到最终的结果集。Sharding-JDBC提供了多种结果归并算法，如遍历归并、排序归并、分组归并等。

三、配置与实现

Sharding-JDBC水平分表的配置与实现通常包括以下几个步骤：

1. **引入Maven依赖**：在项目的pom.xml文件中添加Sharding-JDBC的依赖。
2. **配置数据源**：在application.yml或application.properties文件中配置多个数据源，以及数据源之间的连接信息。
3. **定义分片规则**：在配置文件中定义分片规则，包括分片字段、分片策略等。
4. **编写代码**：根据业务需求编写代码，Sharding-JDBC会根据分片规则自动将数据路由到相应的数据源。

四、优点与限制

Sharding-JDBC水平分表的优点主要包括：

- **提高数据库扩展性**：通过水平分表，可以将数据分散到多个表中，从而提高数据库的存储能力和处理能力。
- **提高查询性能**：由于数据被分散到多个表中，查询时可以并行处理，从而提高查询性能。
- **简化数据库维护**：通过水平分表，可以将大表拆分成小表，便于管理和维护。

然而，Sharding-JDBC水平分表也存在一些限制：

- **分片规则设计复杂**：需要根据业务需求设计合理的分片规则，否则可能导致数据分布不均或查询性能下降。
- **跨库事务处理困难**：由于数据被分散到多个数据源中，跨库事务的处理变得复杂且性能较低。
- **数据迁移和备份困难**：水平分表后，数据的迁移和备份需要考虑到多个数据源之间的数据同步和一致性。

总之，Sharding-JDBC水平分表是一种有效的数据库分片技术，可以提高数据库的扩展性和查询性能。但在使用时需要充分考虑分片规则的设计、跨库事务的处理以及数据迁移和备份等限制因素。



#### 配置

application.properties 配置如下：

```properties
# 指定order表的主键生成策略为SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
# 指定order表的数据分布情况，配置数据节点
# 操作所有表的 SQL 需要根据此信息生成实际 SQL，例如：truncate SQL等
spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds1.order_$->{1..2}
# order表的分片策略，分片策略包括分片键和分片算法
spring.shardingsphere.sharding.tables.order.table-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order.table-strategy.inline.algorithm-expression=order_$->{id % 2 + 1}
```

预先分别创建表 order_1 和 order_2

```sql
CREATE TABLE IF NOT EXISTS order_1(
    id BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT '订单ID' ,
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    merchant_id BIGINT NOT NULL COMMENT '商家ID',
    total_amount DECIMAL(15, 2) NOT NULL COMMENT '金额总数',
    total_count INT NOT NULL COMMENT '商品总数',
    `status` ENUM('Unpay','Undelivery','Unreceive','Received','Canceled') NOT NULL COMMENT '订单状态：未支付、未发货、未收货、已签收、买家取消',
    pay_time DATETIME DEFAULT NULL COMMENT '付款时间',
    delivery_time DATETIME DEFAULT NULL COMMENT '发货时间',
    received_time DATETIME DEFAULT NULL COMMENT '签收时间',
    cancel_time DATETIME DEFAULT NULL COMMENT '取消时间',
    delete_status ENUM('Normal','Deleted') NOT NULL COMMENT '订单删除状态',
    INDEX idx_order1_user_id(user_id) USING BTREE,
    INDEX idx_order1_merchant_id(merchant_id) USING BTREE,
    INDEX idx_order1_user_id_and_status_and_delete_status_and_create_time(user_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order1_user_id_and_delete_status_and_create_time(user_id,delete_status,create_time) USING BTREE,
    INDEX idx_order1_merchantId_and_status_and_deleteStatus_and_createTime(merchant_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order1_merchantId_and_deleteStatus_and_createTime(merchant_id,delete_status,create_time) USING BTREE
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

CREATE TABLE IF NOT EXISTS order_2(
    id BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT '订单ID' ,
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    merchant_id BIGINT NOT NULL COMMENT '商家ID',
    total_amount DECIMAL(15, 2) NOT NULL COMMENT '金额总数',
    total_count INT NOT NULL COMMENT '商品总数',
    `status` ENUM('Unpay','Undelivery','Unreceive','Received','Canceled') NOT NULL COMMENT '订单状态：未支付、未发货、未收货、已签收、买家取消',
    pay_time DATETIME DEFAULT NULL COMMENT '付款时间',
    delivery_time DATETIME DEFAULT NULL COMMENT '发货时间',
    received_time DATETIME DEFAULT NULL COMMENT '签收时间',
    cancel_time DATETIME DEFAULT NULL COMMENT '取消时间',
    delete_status ENUM('Normal','Deleted') NOT NULL COMMENT '订单删除状态',
    INDEX idx_order2_user_id(user_id) USING BTREE,
    INDEX idx_order2_merchant_id(merchant_id) USING BTREE,
    INDEX idx_order2_user_id_and_status_and_delete_status_and_create_time(user_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order2_user_id_and_delete_status_and_create_time(user_id,delete_status,create_time) USING BTREE,
    INDEX idx_order2_merchantId_and_status_and_deleteStatus_and_createTime(merchant_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order2_merchantId_and_deleteStatus_and_createTime(merchant_id,delete_status,create_time) USING BTREE
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
```



#### 单条插入

OrderMapper 插入 SQL 编写和平常编写 SQL 一致，只是此时 SQL 中的 order 表为逻辑表

```java
@Insert("insert into `order`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time," +
        "received_time,cancel_time,delete_status) " +
        "values(#{createTime},#{userId},#{merchantId},#{totalAmount},#{totalCount}," +
        "#{status},#{payTime},#{deliveryTime},#{receivedTime},#{cancelTime},#{deleteStatus})")
@Options(useGeneratedKeys = true, keyProperty = "id")
void add(Order order);
```

SQL 转换过程如下：

```
Logic SQL: insert into `order`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time,received_time,cancel_time,delete_status) values(?,?,?,?,?,?,?,?,?,?,?)
Actual SQL: ds1 ::: insert into `order_2`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time,received_time,cancel_time,delete_status, id) values(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) ::: [2025-02-18 08:09:49.0, 5814640730281880984, 8784506027955728107, 1000, 10, Canceled, null, null, null, null, Normal, 1098520888908709889]                     : 
```



#### 根据单个 id 查询

OrderMapper 代码如下：

```java
@Select("select * from `order` where id=#{id}")
Order get(@Param("id") Long id);
```

SQL 转换过程如下：

```
Logic SQL: select * from `order` where id=?
Actual SQL: ds1 ::: select * from `order_2` where id=? ::: [1098517150592663553]
```



#### 根据 id 列表查询

OrderMapper 代码如下：

```java
/**
 * Sharding-JDBC 会计算所有 id 对应数据所在的实际表
 *
 * @param idList
 * @return
 */
@Select("<script>" +
        "   select * from `order`" +
        "   where id in(" +
        "   <foreach item=\"e\" collection=\"idList\" separator=\",\">" +
        "       #{e}" +
        "   </foreach>)" +
        "</script>")
List<Order> listById(@Param("idList") List<Long> idList);
```

SQL 转换过程如下：

```
Logic SQL: select * from `order`   where id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?       )
Actual SQL: ds1 ::: select * from `order_1`   where id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?       ) ::: [1098383195662974976, 1098383197089038337, 1098383197147758592, 1098383197223256065, 1098383197302947840]
Actual SQL: ds1 ::: select * from `order_2`   where id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?       ) ::: [1098383195662974976, 1098383197089038337, 1098383197147758592, 1098383197223256065, 1098383197302947840]
```



#### 批量插入

OrderMapper 代码如下：

```java
@Insert("<script>" +
        "insert into `order`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time," +
        "received_time,cancel_time,delete_status) values " +
        "   <foreach item=\"e\" collection=\"orderList\" separator=\",\">" +
        "       (#{e.createTime},#{e.userId},#{e.merchantId},#{e.totalAmount},#{e.totalCount},#{e.status},#{e.payTime}," +
        "       #{e.deliveryTime},#{e.receivedTime},#{e.cancelTime},#{e.deleteStatus})" +
        "   </foreach>" +
        "</script>")
void addBatch(@Param("orderList") List<Order> orderList);
```

SQL 转换过程如下：

```
Logic SQL: insert into `order`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time,received_time,cancel_time,delete_status) values             (?,?,?,?,?,?,?,       ?,?,?,?)    ,        (?,?,?,?,?,?,?,       ?,?,?,?)    ,        (?,?,?,?,?,?,?,       ?,?,?,?)    ,        (?,?,?,?,?,?,?,       ?,?,?,?)    ,        (?,?,?,?,?,?,?,       ?,?,?,?)
Actual SQL: ds1 ::: insert into `order_2`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time,received_time,cancel_time,delete_status, id) values             (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) ::: [2025-02-18 08:09:49.0, 6964861732010644788, 2814532415868973489, 1000, 10, Unreceive, null, null, null, null, Normal, 1098520890347356163, 2025-02-18 08:09:49.0, 8207136565814235543, 1265662605470267171, 1000, 10, Undelivery, null, null, null, null, Normal, 1098520890347356161, 2025-02-18 08:09:49.0, 1689313875273878826, 962377927175726351, 1000, 10, Canceled, null, null, null, null, Normal, 1098520890343161857]
Actual SQL: ds1 ::: insert into `order_1`(create_time,user_id,merchant_id,total_amount,total_count,status,pay_time,delivery_time,received_time,cancel_time,delete_status, id) values             (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?), (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?) ::: [2025-02-18 08:09:49.0, 4233041090170371398, 518184872115252607, 1000, 10, Unpay, null, null, null, null, Deleted, 1098520890347356162, 2025-02-18 08:09:49.0, 3533249187271280003, 503543136409760317, 1000, 10, Undelivery, null, null, null, null, Normal, 1098520890347356160]
```



#### 没有 where 条件的查询

OrderMapper 代码如下：

```java
@Select("select * from `order`")
List<Order> listAll();
```

SQL 转换过程如下：

```
Logic SQL: select * from `order`
Actual SQL: ds1 ::: select * from `order_1`
Actual SQL: ds1 ::: select * from `order_2`
```



### 水平分库

#### 介绍

Sharding-JDBC水平分库是一种数据库分片技术，旨在通过横向拆分数据库来提高系统的扩展性和性能。以下是对Sharding-JDBC水平分库的详细解释：

一、基本概念

- **水平分库**：又称为横向拆分，是指将一个数据库中的数据按照某种规则（如用户ID、订单ID等）分散到多个数据库中。每个数据库中的数据只是原数据库数据的一部分，但数据库的结构与原数据库相同。
- **Sharding-JDBC**：是一个开源的数据库分片中间件，它基于JDBC，提供了分库分表、读写分离、分布式事务等功能。Sharding-JDBC可以在客户端对SQL语句进行解析、路由和改写，然后将改写后的SQL语句发送到对应的数据源执行。

二、实现原理

Sharding-JDBC水平分库的实现原理主要包括以下几个方面：

1. **数据源配置**：在Sharding-JDBC中，需要配置多个数据源，每个数据源对应一个物理数据库。这些数据源可以是不同类型的数据库，但通常是同构的，即具有相同的表结构和数据类型。
2. **分片规则**：根据业务需求，定义数据分片的规则。分片规则决定了如何将数据分散到多个数据库中。常见的分片规则包括哈希分片、范围分片、列表分片等。
3. **SQL解析与改写**：当应用程序执行SQL语句时，Sharding-JDBC会对SQL语句进行解析，识别出表名、字段名、条件等关键信息。然后，根据分片规则，将SQL语句改写为多个子查询，每个子查询对应一个数据源。
4. **路由与执行**：Sharding-JDBC会根据改写后的SQL语句，将查询请求路由到相应的数据源。然后，在每个数据源上执行子查询，并将结果集返回给应用程序。
5. **结果归并**：如果查询请求涉及多个数据源，Sharding-JDBC会对返回的结果集进行归并处理，得到最终的结果集。结果归并算法包括遍历归并、排序归并、分组归并等。

三、配置与实现

Sharding-JDBC水平分库的配置与实现通常包括以下几个步骤：

1. **引入Maven依赖**：在项目的pom.xml文件中添加Sharding-JDBC的依赖。
2. **配置数据源**：在配置文件（如application.yml或application.properties）中配置多个数据源，包括数据库的连接信息、用户名、密码等。
3. **定义分片规则**：在配置文件中定义分片规则，包括分片字段、分片策略、分片算法等。
4. **编写代码**：在代码中配置Sharding-JDBC的分片上下文，并编写业务逻辑代码。Sharding-JDBC会根据分片规则自动将数据路由到相应的数据源。

四、优点与限制

Sharding-JDBC水平分库的优点主要包括：

1. **提高系统扩展性**：通过水平分库，可以将数据分散到多个数据库中，从而提高系统的存储能力和处理能力。
2. **提高查询性能**：由于数据被分散到多个数据库中，查询时可以并行处理，从而提高查询性能。
3. **简化数据库维护**：通过水平分库，可以将大数据库拆分成小数据库，便于管理和维护。

然而，Sharding-JDBC水平分库也存在一些限制：

1. **分片规则设计复杂**：需要根据业务需求设计合理的分片规则，否则可能导致数据分布不均或查询性能下降。
2. **跨库事务处理困难**：由于数据被分散到多个数据库中，跨库事务的处理变得复杂且性能较低。
3. **数据迁移和备份困难**：水平分库后，数据的迁移和备份需要考虑到多个数据库之间的数据同步和一致性。

综上所述，Sharding-JDBC水平分库是一种有效的数据库分片技术，可以提高系统的扩展性和查询性能。但在使用时需要充分考虑分片规则的设计、跨库事务的处理以及数据迁移和备份等限制因素。



#### 配置

application.properties 配置如下：

```properties
spring.shardingsphere.datasource.names=ds1,ds2
spring.shardingsphere.datasource.ds1.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds1.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds1.jdbc-url=jdbc:mariadb://localhost:3306/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds1.username=root
spring.shardingsphere.datasource.ds1.password=123456

spring.shardingsphere.datasource.ds2.type=com.zaxxer.hikari.HikariDataSource
spring.shardingsphere.datasource.ds2.driver-class-name=org.mariadb.jdbc.Driver
spring.shardingsphere.datasource.ds2.jdbc-url=jdbc:mariadb://localhost:3307/demo?allowMultiQueries=true
spring.shardingsphere.datasource.ds2.username=root
spring.shardingsphere.datasource.ds2.password=123456

# 配置order逻辑表的分库策略
spring.shardingsphere.sharding.tables.order.database-strategy.inline.sharding-column=user_id
spring.shardingsphere.sharding.tables.order.database-strategy.inline.algorithm-expression=ds$->{user_id % 2 + 1}

# 指定order表的主键生成策略为SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.column=id
spring.shardingsphere.sharding.tables.order.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.order.key-generator.props.worker.id=1
# 指定order表的数据分布情况，配置数据节点
# 操作所有表的 SQL 需要根据此信息生成实际 SQL，例如：truncate SQL等
spring.shardingsphere.sharding.tables.order.actual-data-nodes=ds$->{1..2}.order_$->{1..2}
# order表的分片策略，分片策略包括分片键和分片算法
spring.shardingsphere.sharding.tables.order.table-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.order.table-strategy.inline.algorithm-expression=order_$->{id % 2 + 1}
```

预先分别运行两个数据库实例分别监听 3306 和 3307 并且都创建表 order_1 和 order_2

```sql
CREATE DATABASE IF NOT EXISTS demo DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;

USE demo;

CREATE TABLE IF NOT EXISTS order_1(
    id BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT '订单ID' ,
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    merchant_id BIGINT NOT NULL COMMENT '商家ID',
    total_amount DECIMAL(15, 2) NOT NULL COMMENT '金额总数',
    total_count INT NOT NULL COMMENT '商品总数',
    `status` ENUM('Unpay','Undelivery','Unreceive','Received','Canceled') NOT NULL COMMENT '订单状态：未支付、未发货、未收货、已签收、买家取消',
    pay_time DATETIME DEFAULT NULL COMMENT '付款时间',
    delivery_time DATETIME DEFAULT NULL COMMENT '发货时间',
    received_time DATETIME DEFAULT NULL COMMENT '签收时间',
    cancel_time DATETIME DEFAULT NULL COMMENT '取消时间',
    delete_status ENUM('Normal','Deleted') NOT NULL COMMENT '订单删除状态',
    INDEX idx_order1_user_id(user_id) USING BTREE,
    INDEX idx_order1_merchant_id(merchant_id) USING BTREE,
    INDEX idx_order1_user_id_and_status_and_delete_status_and_create_time(user_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order1_user_id_and_delete_status_and_create_time(user_id,delete_status,create_time) USING BTREE,
    INDEX idx_order1_merchantId_and_status_and_deleteStatus_and_createTime(merchant_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order1_merchantId_and_deleteStatus_and_createTime(merchant_id,delete_status,create_time) USING BTREE
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

CREATE TABLE IF NOT EXISTS order_2(
    id BIGINT UNSIGNED NOT NULL PRIMARY KEY COMMENT '订单ID' ,
    create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
    user_id BIGINT NOT NULL COMMENT '用户ID',
    merchant_id BIGINT NOT NULL COMMENT '商家ID',
    total_amount DECIMAL(15, 2) NOT NULL COMMENT '金额总数',
    total_count INT NOT NULL COMMENT '商品总数',
    `status` ENUM('Unpay','Undelivery','Unreceive','Received','Canceled') NOT NULL COMMENT '订单状态：未支付、未发货、未收货、已签收、买家取消',
    pay_time DATETIME DEFAULT NULL COMMENT '付款时间',
    delivery_time DATETIME DEFAULT NULL COMMENT '发货时间',
    received_time DATETIME DEFAULT NULL COMMENT '签收时间',
    cancel_time DATETIME DEFAULT NULL COMMENT '取消时间',
    delete_status ENUM('Normal','Deleted') NOT NULL COMMENT '订单删除状态',
    INDEX idx_order2_user_id(user_id) USING BTREE,
    INDEX idx_order2_merchant_id(merchant_id) USING BTREE,
    INDEX idx_order2_user_id_and_status_and_delete_status_and_create_time(user_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order2_user_id_and_delete_status_and_create_time(user_id,delete_status,create_time) USING BTREE,
    INDEX idx_order2_merchantId_and_status_and_deleteStatus_and_createTime(merchant_id,status,delete_status,create_time) USING BTREE,
    INDEX idx_order2_merchantId_and_deleteStatus_and_createTime(merchant_id,delete_status,create_time) USING BTREE
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
```



#### 各种情况的插入、查询

各种情况的插入、查询、truncate 和水平分表分析方法一致，运行示例 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc` 通过日志分析其逻辑 SQL 和实际 SQL。



### 垂直分库

#### 介绍

Sharding-JDBC是ShardingSphere的其中一个模块，是一个轻量级Java框架，在Java的JDBC层提供额外服务。它使用客户端直连数据库，以jar包形式提供服务，无需额外部署和依赖，可理解为增强版的JDBC驱动，完全兼容JDBC和各种ORM框架。通过Sharding-JDBC，应用可以透明地使用JDBC访问已经分库分表、读写分离的多个数据源，而不用关心数据源的数量以及数据如何分布。

垂直分库是指按照业务将表进行分类，分别存放在不同的数据库中，这些库可以分布在不同的服务器，从而使访问压力被分摊在多个服务器，这样不仅能提高性能，同时能提高整体架构的业务清晰度。以下是使用Sharding-JDBC实现垂直分库的步骤：

1. **需求分析**：明确垂直分库的需求和目标，确定哪些表需要被分到不同的数据库中。
2. **创建数据库和表**：根据需求分析的结果，在相应的服务器上创建数据库和表。
3. **编写代码**：
   - 创建实体类和对应的Mapper、Controller、Service等。
   - 配置Sharding-JDBC的分片策略。在配置文件中，指定数据源名称、数据库连接池、数据库驱动类名、数据库URL连接、数据库用户名和密码等信息。
   - 配置垂直分库策略，包括指定逻辑表、实际数据节点、分片列和分片算法等。
4. **测试**：编写测试代码，验证垂直分库是否成功。可以通过插入数据并查询来验证分片策略是否正确。

需要注意，垂直分库虽然能提高性能和业务清晰度，但也会带来一些复杂问题，如跨库事务、数据一致性等。因此，在实现垂直分库时，需要充分考虑这些问题，并采取相应的措施来解决。

此外，Sharding-JDBC的版本更新较快，不同版本之间可能存在一些差异。因此，在实现垂直分库时，需要参考当前版本的Sharding-JDBC文档和示例代码，以确保正确实现和配置。

总的来说，使用Sharding-JDBC实现垂直分库是一个复杂但有效的过程，需要充分考虑业务需求和技术实现等因素。通过合理配置和测试，可以实现性能的提升和业务清晰度的提高。



#### 配置

application.properties 配置如下：

```properties
# 逻辑表user在数据源ds1的物理表user中
spring.shardingsphere.sharding.tables.user.actual-data-nodes=ds1.user
```

预先在数据库中创建 user 表

```sql
CREATE DATABASE IF NOT EXISTS demo DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;

USE demo;

CREATE TABLE IF NOT EXISTS `user`(
     id BIGINT UNSIGNED NOT NULL PRIMARY KEY AUTO_INCREMENT COMMENT '订单ID' ,
     create_time DATETIME NOT NULL DEFAULT CURRENT_TIMESTAMP COMMENT '创建时间',
     `name` VARCHAR(128) NOT NULL COMMENT '用户名称'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
```



#### 业务 SQL 编写

业务 SQL 编写和没有使用 Sharding-JDBC 时编写规则一致。



### 垂直分表

#### 介绍

Sharding-JDBC中的垂直分表是一种数据库优化技术，主要用于解决单表数据量过大、字段过多导致的数据库性能下降问题。以下是对Sharding-JDBC垂直分表的详细解释：

一、定义

垂直分表是指将一张宽表（包含较多字段的表）按照字段进行拆分，拆分成多张窄表（包含较少字段的表）。这些窄表在逻辑上仍然属于同一张表，但在物理上被存储在不同的数据库表中。

二、优势

1. **提高性能**：通过将热点字段和冷字段分开存储，可以减少I/O争抢，提高数据库性能。同时，由于每张窄表只包含部分字段，查询时可以更快地定位到所需的数据，减少不必要的字段扫描。
2. **优化资源使用**：垂直分表可以将数据分散到多个表中，从而优化数据库服务器的资源使用。例如，可以将经常访问的字段放在同一个表中，以减少磁盘I/O和内存使用。
3. **业务清晰度提升**：通过垂直分表，可以将不同业务逻辑的字段分开存储，使得数据库结构更加清晰，便于维护和扩展。

三、原则

1. **冷热数据分离**：将经常访问的字段（热点数据）和不常访问的字段（冷数据）分开存储。
2. **大字段拆分**：将大文本、图片、视频等大字段拆分出来单独存储，以减少对数据库性能的影响。
3. **组合查询优化**：将经常组合查询的字段放在同一张表中，以避免多表查询带来的性能开销。

四、实现步骤

1. **创建数据库和表**：首先，需要在数据库中创建多个窄表，这些窄表将存储拆分后的字段。
2. **配置Sharding-JDBC**：在Sharding-JDBC的配置文件中，指定垂直分表的策略，包括分片键、分片算法等。
3. **编写SQL语句**：在编写SQL语句时，需要注意使用逻辑表名而不是物理表名。Sharding-JDBC会根据配置的策略将逻辑表名映射到实际的物理表名上。

五、注意事项

1. **避免联查**：在垂直分表后，尽量避免跨表查询，因为跨表查询会带来额外的性能开销。如果必须跨表查询，可以考虑使用数据库视图或中间层来优化查询性能。
2. **数据一致性**：在垂直分表后，需要确保不同表之间的数据一致性。这可以通过事务管理、数据校验等方式来实现。
3. **分片策略选择**：在选择分片策略时，需要根据业务需求和数据库性能进行权衡。例如，可以根据字段的访问频次、数据分布等因素来选择合适的分片键和分片算法。

综上所述，Sharding-JDBC的垂直分表技术是一种有效的数据库优化手段，可以显著提高数据库性能和资源使用效率。但在实际应用中，需要根据业务需求和数据库性能进行权衡和选择。



#### 实验

垂直分表可以参考绑定表章节，它们本质是同一个事情。



### 公共表

#### 介绍

Sharding-JDBC中的公共表（也称为广播表）是一个重要的概念，尤其在处理分库分表的场景中。以下是对Sharding-JDBC公共表的详细解析：

一、定义与特点

公共表是指存储固定数据、数据很少发生变化且经常进行关联查询的表。这类表通常包括参数表、数据字典表等。在Sharding-JDBC中，公共表需要在每个分片数据源中都存在，且表结构和表中的数据在每个数据库中都完全一致。

二、实现方式

1. **创建公共表**：首先，需要在每个数据库中手动创建出结构相同的公共表。
2. **配置公共表**：在Sharding-JDBC的配置文件中，需要指定哪些表是公共表。例如，在application.properties或application.yml配置文件中，可以通过设置`spring.shardingsphere.sharding.broadcast-tables`属性来指定公共表。

三、使用场景与优势

1. **使用场景**：公共表通常用于存储一些全局的、不经常变动的数据，如配置信息、数据字典等。这些数据需要在多个分片之间进行共享和关联查询。
2. **优势**：
   - **简化查询**：通过将公共表复制到每个分片中，可以简化跨分片的关联查询，提高查询效率。
   - **数据一致性**：由于公共表在每个分片中都存在且数据一致，因此可以确保在不同分片上进行查询时得到相同的结果。

四、注意事项

1. **数据更新**：对公共表的更新操作需要同时发送到所有分片执行，以确保数据的一致性。这可能会增加一些额外的开销和复杂性。
2. **表结构变更**：如果需要对公共表的结构进行变更（如添加列、修改数据类型等），需要在所有分片中同时执行相应的DDL操作。

五、示例配置

以下是一个简单的示例配置，展示了如何在Sharding-JDBC中配置公共表：

```properties
# 指定t_dict为公共表
spring.shardingsphere.sharding.broadcast-tables=t_dict

# 定义数据源（多个数据源名为m0, m1, m2等）
spring.shardingsphere.datasource.names=m0,m1,m2

# 配置数据源m0（以mysql为例）
spring.shardingsphere.datasource.m0.type=com.alibaba.druid.pool.DruidDataSource
spring.shardingsphere.datasource.m0.driver-class-name=com.mysql.cj.jdbc.Driver
spring.shardingsphere.datasource.m0.url=jdbc:mysql://localhost:3306/user_db?useUnicode=true&characterEncoding=UTF-8&serverTimezone=UTC
spring.shardingsphere.datasource.m0.username=root
spring.shardingsphere.datasource.m0.password=yourpassword

# （类似地配置数据源m1和m2...）
```

在上面的配置中，`t_dict`被指定为公共表，它将在所有分片数据源（m0、m1、m2等）中都存在。

综上所述，Sharding-JDBC中的公共表是一个用于存储固定数据、支持跨分片关联查询的重要概念。通过正确配置和使用公共表，可以简化查询逻辑、提高查询效率并确保数据的一致性。



#### 配置

application.properties 配置如下：

```properties
spring.shardingsphere.sharding.broadcast-tables=dict
```

分别在各个数据库创建 dict 表 SQL 脚本如下：

```sql
CREATE TABLE IF NOT EXISTS dict (
    id INT NOT NULL PRIMARY KEY COMMENT '字典ID',
    `name` VARCHAR(256) NOT NULL COMMENT '字典记录名称',
    `value` VARCHAR(256) NOT NULL COMMENT '字典记录值'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
```



#### 业务 SQL 编写

业务 SQL 编写和没有使用 Sharding-JDBC 时编写规则一致。



### 读写分离

>注意：项目中未用到此特性，所以暂时不作研究。



#### 介绍

Sharding-JDBC 是一个轻量级的 Java 框架，它在 Java 的 JDBC 层提供额外服务，使用客户端直连数据库，并以 jar 包形式提供服务，无需额外部署和依赖，可理解为增强版的 JDBC 驱动，完全兼容 JDBC 和各种 ORM 框架。Sharding-JDBC 读写分离是根据 SQL 语义的分析，将读操作和写操作分别路由至主库与从库，从而提升系统性能。以下是对 Sharding-JDBC 读写分离的详细介绍：

一、读写分离的背景与原理

1. **背景**：
   - 面对日益增加的系统访问量，数据库的吞吐量面临着巨大瓶颈。
   - 对于同一时刻有大量并发读操作和较少写操作类型的应用系统，将数据库拆分为主库和从库，主库负责处理事务性的增删改操作，从库负责处理查询操作，能够避免由数据更新导致的行锁，从而提升系统的查询性能。
2. **原理**：
   - 数据库主从复制技术：把数据复制到多个节点中，分散读多个库以支持高并发的读，而写只在主库上。
   - Sharding-JDBC 通过简单的开发，实现读写分离技术。它提供了一主多从的读写分离配置，可独立使用，也可配合分库分表使用。

二、Sharding-JDBC 读写分离的配置与实现

1. **Maven 依赖**：

   需要在项目的 Maven 配置文件（pom.xml）中添加 Sharding-JDBC 的相关依赖。例如：

   ```xml
   <dependency>
       <groupId>org.apache.shardingsphere</groupId>
       <artifactId>sharding-jdbc-spring-boot-starter</artifactId>
       <version>4.x.x</version> <!-- 使用具体的版本号 -->
   </dependency>
   ```

2. **配置文件**：

   在 Spring Boot 的配置文件（如 application.yml）中配置数据源和读写分离规则。例如：

   ```yaml
   spring:
     shardingsphere:
       props:
         sql:
           show: true
       datasource:
         names: ds-master, ds-slave1, ds-slave2
         ds-master:
           type: com.alibaba.druid.pool.DruidDataSource
           driver-class-name: com.mysql.cj.jdbc.Driver
           url: jdbc:mysql://localhost:3307/student?useUnicode=true&characterEncoding=utf8&tinyInt1isBit=false&useSSL=false&serverTimezone=GMT
           username: root
           password: 123456
         ds-slave1:
           # 从库一的配置
         ds-slave2:
           # 从库二的配置
       master-slave-rules:
         ds_0:
           master-data-source-name: ds-master
           slave-data-source-names: ds-slave1, ds-slave2
   ```

3. **Java 代码配置**：

   在 Java 代码中配置对应的主从数据源和读写分离规则。例如：

   ```java
   @Configuration
   public class MasterSlaveDataSourceConfig {
    
       @Value("${spring.datasource.type}")
       private Class<? extends DataSource> dataSourceType;
    
       // 其他数据源配置属性
    
       @Bean("masterDataSource")
       @ConfigurationProperties(prefix = "spring.datasource.master")
       public DataSource masterDataSource() {
           DruidDataSource druidDataSource = (DruidDataSource) DataSourceBuilder.create().type(dataSourceType).build();
           // 配置 Druid 数据源
           return druidDataSource;
       }
    
       @Bean("slaveDataSource")
       @ConfigurationProperties(prefix = "spring.datasource.slave")
       public DataSource slaveDataSource() {
           // 注意：这里通常会有多个从库配置，需要遍历配置
           DruidDataSource druidDataSource = (DruidDataSource) DataSourceBuilder.create().type(dataSourceType).build();
           // 配置 Druid 数据源
           return druidDataSource;
       }
    
       // 配置 Sharding-JDBC 的读写分离规则
       @Bean
       public MasterSlaveRuleConfiguration masterSlaveRuleConfiguration() {
           MasterSlaveRuleConfiguration masterSlaveRuleConfig = new MasterSlaveRuleConfiguration();
           masterSlaveRuleConfig.setName("ds_0");
           masterSlaveRuleConfig.setMasterDataSourceName("masterDataSource");
           List<String> slaveDataSourceNames = new ArrayList<>();
           slaveDataSourceNames.add("slaveDataSource");
           // 如果有多个从库，继续添加
           masterSlaveRuleConfig.setSlaveDataSourceNames(slaveDataSourceNames);
           return masterSlaveRuleConfig;
       }
    
       // 配置 ShardingDataSource
       @Bean
       public DataSource shardingDataSource() throws SQLException {
           Map<String, DataSource> dataSourceMap = new HashMap<>();
           dataSourceMap.put("masterDataSource", masterDataSource());
           dataSourceMap.put("slaveDataSource", slaveDataSource());
           // 配置其他数据源
    
           ShardingRuleConfiguration shardingRuleConfig = new ShardingRuleConfiguration();
           shardingRuleConfig.getMasterSlaveRuleConfigs().add(masterSlaveRuleConfiguration());
           // 配置分片规则（如果有）
    
           return ShardingDataSourceFactory.createDataSource(dataSourceMap, Collections.singleton(shardingRuleConfig), new Properties());
       }
   }
   ```

三、读写分离的效果与注意事项

1. **效果**：
   - 通过读写分离，可以将查询请求均匀地分散到多个数据副本，进一步提升系统的处理能力。
   - 使用多主多从的方式，不仅能提升系统的吞吐量，还能提升系统的可用性，确保在任何一个数据库宕机或磁盘物理损坏的情况下，系统仍能正常运行。
2. **注意事项**：
   - 主从节点数据同步延迟可能导致的数据不一致问题。对于时效性比较高的查询，可以强制路由到主节点查询。
   - Sharding-JDBC 不支持类似主库双写或多写这样的特性，需要确保写操作只发生在主库上。

综上所述，Sharding-JDBC 读写分离是一种有效的数据库性能优化手段，适用于读多写少的应用场景。通过合理的配置和实现，可以显著提升系统的查询性能和可用性。



### 绑定表

#### 介绍

Sharding-JDBC中的绑定表（也称为关联表）是指分片规则一致的主表和子表。以下是对Sharding-JDBC绑定表的详细解释：

一、定义与概念

绑定表是指两张或多张表之间因为分片规则相同而建立的关联关系。在Sharding-JDBC中，如果两张表互为绑定表关系，那么它们在进行多表关联查询时，不会出现笛卡尔积关联，从而可以大大提升关联查询的效率。

二、应用场景

绑定表通常应用于具有主从关系或父子关系的表结构中，例如订单表和订单项表。假设有一个订单表（t_order）和一个订单项表（t_order_item），它们都按照订单ID（order_id）进行分片。在这种情况下，可以将这两张表设置为绑定表关系，以便在进行订单和订单项的关联查询时，能够高效地获取数据。

三、配置方法

在Sharding-JDBC中配置绑定表关系，通常需要在配置文件（如properties文件或yml文件）中进行设置。以下是一个示例配置：

```yaml
spring:
  shardingsphere:
    datasource:
      names: ds0,ds1
      ds0:
        # 数据源配置信息
      ds1:
        # 数据源配置信息
    sharding:
      tables:
        t_order:
          # 分片规则配置
        t_order_item:
          # 分片规则配置，与t_order表相同
      binding-tables:
        - t_order,t_order_item
```

在上述配置中，`binding-tables`部分指定了t_order和t_order_item为绑定表关系。这意味着在进行这两张表的关联查询时，Sharding-JDBC将会按照绑定表的规则进行路由和查询。

四、注意事项

1. **分片键要相同**：绑定表之间的分片键必须完全相同，否则无法进行绑定。
2. **主表策略**：在绑定表关系中，ShardingSphere将会以主表（即在FROM子句中最左侧的表）作为整个绑定表的主表。所有路由计算都只会使用主表的策略。
3. **性能提升**：配置绑定表关系后，可以显著提升多表关联查询的性能，避免产生笛卡尔积关联。

五、示例

假设有一个订单系统，其中订单表（t_order）和订单项表（t_order_item）都按照订单ID（order_id）进行分片。以下是一个简单的示例，展示了如何在Sharding-JDBC中配置和使用绑定表：

1. **创建数据库和表**：在数据库中创建订单表和订单项表，并设置相同的分片键。
2. **配置Sharding-JDBC**：在Sharding-JDBC的配置文件中，将订单表和订单项表设置为绑定表关系。
3. **执行关联查询**：在执行订单和订单项的关联查询时，Sharding-JDBC将会按照绑定表的规则进行路由和查询，从而提升查询性能。

综上所述，Sharding-JDBC的绑定表功能是一种高效处理多表关联查询的机制。通过合理配置绑定表关系，可以显著提升查询性能并优化数据库分片策略。



#### 演示

使用商品主表和商品描述子表演示绑定表用法。

在数据库中创建 product 主表和 product_description 子表如下：

```sql
-- 用于协助演示绑定表关系
CREATE TABLE IF NOT EXISTS product_1 (
    id BIGINT NOT NULL PRIMARY KEY COMMENT '商品ID',
    `name` VARCHAR(512) NOT NULL COMMENT '商品名称',
    create_time DATETIME NOT NULL COMMENT '创建时间'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

CREATE TABLE IF NOT EXISTS product_description_1 (
   id BIGINT NOT NULL PRIMARY KEY COMMENT '商品描述ID',
   product_id BIGINT NOT NULL COMMENT '商品ID',
   `description` TEXT COMMENT '商品描述'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

CREATE TABLE IF NOT EXISTS product_2 (
    id BIGINT NOT NULL PRIMARY KEY COMMENT '商品ID',
    `name` VARCHAR(512) NOT NULL COMMENT '商品名称',
    create_time DATETIME NOT NULL COMMENT '创建时间'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;

CREATE TABLE IF NOT EXISTS product_description_2 (
     id BIGINT NOT NULL PRIMARY KEY COMMENT '商品描述ID',
     product_id BIGINT NOT NULL COMMENT '商品ID',
     `description` TEXT COMMENT '商品描述'
) ENGINE=INNODB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_general_ci;
```

application.properties 绑定表配置如下：

```properties
spring.shardingsphere.sharding.tables.product.key-generator.column=id
spring.shardingsphere.sharding.tables.product.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.product.key-generator.props.worker.id=1
spring.shardingsphere.sharding.tables.product.actual-data-nodes=ds1.product_$->{1..2}
spring.shardingsphere.sharding.tables.product.table-strategy.inline.sharding-column=id
spring.shardingsphere.sharding.tables.product.table-strategy.inline.algorithm-expression=product_$->{id % 2 + 1}

spring.shardingsphere.sharding.tables.product_description.key-generator.column=id
spring.shardingsphere.sharding.tables.product_description.key-generator.type=SNOWFLAKE
spring.shardingsphere.sharding.tables.product_description.key-generator.props.worker.id=1
spring.shardingsphere.sharding.tables.product_description.actual-data-nodes=ds1.product_description_$->{1..2}
spring.shardingsphere.sharding.tables.product_description.table-strategy.inline.sharding-column=product_id
spring.shardingsphere.sharding.tables.product_description.table-strategy.inline.algorithm-expression=product_description_$->{product_id % 2 + 1}
# 绑定表关键配置
spring.shardingsphere.sharding.binding-tables[0]=product,product_description
```

product 和 product_description 在查询 join 时不会发生迪卡尔积（product_1 和 product_description_1 join、product_2 和 product_description_2 join）

```java
Logic SQL: select p.id,p.name,p.create_time,pd.id as description_id,pd.description from product p join product_description pd on p.id=pd.product_id where p.id=?
Actual SQL: ds1 ::: select p.id,p.name,p.create_time,pd.id as description_id,pd.description from product_2 p join product_description_2 pd on p.id=pd.product_id where p.id=? ::: [1098738066564059137]
Logic SQL: select p.id,p.name,p.create_time,pd.id as description_id,pd.description from product p   join product_description pd on p.id=pd.product_id   where p.id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ) order by p.id asc
Actual SQL: ds1 ::: select p.id,p.name,p.create_time,pd.id as description_id,pd.description from product_1 p   join product_description_1 pd on p.id=pd.product_id   where p.id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ) order by p.id asc ::: [1098738065595174912, 1098738065859416065, 1098738065943302144, 1098738066081714177, 1098738066173988864, 1098738066295623681, 1098738066358538240, 1098738066429841409, 1098738066501144576, 1098738066564059137]
Actual SQL: ds1 ::: select p.id,p.name,p.create_time,pd.id as description_id,pd.description from product_2 p   join product_description_2 pd on p.id=pd.product_id   where p.id in(            ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ,        ?    ) order by p.id asc ::: [1098738065595174912, 1098738065859416065, 1098738065943302144, 1098738066081714177, 1098738066173988864, 1098738066295623681, 1098738066358538240, 1098738066429841409, 1098738066501144576, 1098738066564059137]
```



### 基准测试

#### 插入

详细用法请参考 `https://gitee.com/dexterleslie/demonstration/tree/master/demo-mysql-n-mariadb/demo-sharding-jdbc-benchmark`

测试配置：

- CPU 架构 Intel(R) Xeon(R) Platinum 8269CY CPU @ 2.50GHz
- 5台 2核4G 的 centOS8 主机运行数据库服务，数据库 InnoDB 内存为 2G
- 7台 4核6G 的 centOS8 主机运行 Sharding-JDBC 基准测试应用充当压力机

测试结果：

- 压力机最长耗时为 6 秒

测试结论：

- Sharding-JDBC 能够水平扩展数据库的写入数据性能。
