# TiDB



## ä»‹ç»

TiDB æ˜¯ä¸€ä¸ªå¼€æºçš„**åˆ†å¸ƒå¼å…³ç³»å‹æ•°æ®åº“**ï¼Œç”± PingCAP å…¬å¸å¼€å‘å¹¶ç»´æŠ¤ï¼Œç»“åˆäº†ä¼ ç»Ÿå…³ç³»å‹æ•°æ®åº“ï¼ˆå¦‚ MySQLï¼‰çš„æ˜“ç”¨æ€§å’Œ NoSQL æ•°æ®åº“çš„å¯æ‰©å±•æ€§ï¼Œä¸“ä¸ºå¤§è§„æ¨¡æ•°æ®å¤„ç†å’Œé«˜å¹¶å‘åœºæ™¯è®¾è®¡ã€‚ä»¥ä¸‹æ˜¯å…¶æ ¸å¿ƒç‰¹æ€§å’Œåº”ç”¨åœºæ™¯çš„è¯¦ç»†ä»‹ç»ï¼š

------

### **æ ¸å¿ƒç‰¹æ€§**

1. æ°´å¹³æ‰©å±•æ€§
   - é€šè¿‡ **TiKV**ï¼ˆåˆ†å¸ƒå¼å­˜å‚¨å¼•æ“ï¼‰å’Œ **PD**ï¼ˆPlacement Driverï¼Œå…ƒæ•°æ®ç®¡ç†ç»„ä»¶ï¼‰å®ç°æ•°æ®åˆ†ç‰‡å’ŒåŠ¨æ€æ‰©å®¹ï¼Œæ”¯æŒä»å•èŠ‚ç‚¹æ‰©å±•åˆ°æ•°åƒèŠ‚ç‚¹ï¼Œè½»æ¾åº”å¯¹ PB çº§æ•°æ®ã€‚
   - è®¡ç®—ä¸å­˜å‚¨åˆ†ç¦»æ¶æ„ï¼Œå¯ç‹¬ç«‹æ‰©å±•è®¡ç®—ï¼ˆTiDB Serverï¼‰æˆ–å­˜å‚¨ï¼ˆTiKVï¼‰èµ„æºã€‚
2. MySQL å…¼å®¹æ€§
   - æ”¯æŒ **MySQL 5.7 åè®®**å’Œå¤§éƒ¨åˆ†è¯­æ³•ï¼Œç°æœ‰ MySQL åº”ç”¨å¯æ— ç¼è¿ç§»ï¼ˆéœ€å°‘é‡é€‚é…ï¼‰ã€‚
   - æä¾›å…¼å®¹çš„ **JDBC/ODBC é©±åŠ¨**å’Œ **ORM å·¥å…·æ”¯æŒ**ï¼ˆå¦‚ Hibernateã€MyBatisï¼‰ã€‚
3. é«˜å¯ç”¨ä¸å®¹ç¾
   - åŸºäº **Raft åè®®**çš„å¤šå‰¯æœ¬å¤åˆ¶ï¼Œç¡®ä¿æ•°æ®å¼ºä¸€è‡´æ€§ï¼ˆé»˜è®¤ 3 å‰¯æœ¬ï¼‰ã€‚
   - æ”¯æŒè·¨æ•°æ®ä¸­å¿ƒéƒ¨ç½²ï¼ˆå¦‚ä¸‰åœ°äº”ä¸­å¿ƒï¼‰ï¼Œæ»¡è¶³é‡‘èçº§å®¹ç¾éœ€æ±‚ã€‚
4. åˆ†å¸ƒå¼äº‹åŠ¡
   - é‡‡ç”¨ **Percolator æ¨¡å‹**å®ç°è·¨åˆ†ç‰‡äº‹åŠ¡ï¼Œæ”¯æŒ ACIDï¼Œç¡®ä¿å¤æ‚ä¸šåŠ¡é€»è¾‘çš„ä¸€è‡´æ€§ã€‚
5. å®æ—¶ HTAP èƒ½åŠ›
   - é€šè¿‡ **TiFlash**ï¼ˆåˆ—å¼å­˜å‚¨å¼•æ“ï¼‰å®ç°å®æ—¶åˆ†ææŸ¥è¯¢ï¼Œæ— éœ€ ETL å³å¯åŒæ—¶å¤„ç†äº‹åŠ¡å’Œåˆ†æè´Ÿè½½ã€‚
6. äº‘åŸç”Ÿä¸å¤šäº‘éƒ¨ç½²
   - æ”¯æŒ **Kubernetes å®¹å™¨åŒ–éƒ¨ç½²**ï¼Œé€‚é…å…¬æœ‰äº‘ï¼ˆAWSã€Azureã€GCPï¼‰å’Œç§æœ‰äº‘ç¯å¢ƒã€‚
   - æä¾› **TiDB Operator** ç®€åŒ–é›†ç¾¤ç®¡ç†ã€‚

------

### **åº”ç”¨åœºæ™¯**

1. æµ·é‡æ•°æ®å­˜å‚¨ä¸é«˜å¹¶å‘ OLTP
   - ç”µå•†ã€é‡‘èã€ç‰©è”ç½‘ç­‰åœºæ™¯ä¸­ï¼Œéœ€å¤„ç†æ¯ç§’æ•°ä¸‡æ¬¡äº¤æ˜“æˆ–è®¾å¤‡æ•°æ®å†™å…¥ã€‚
2. å®æ—¶æ•°æ®åˆ†æï¼ˆHTAPï¼‰
   - ä¾‹å¦‚å®æ—¶é£æ§ã€ç”¨æˆ·è¡Œä¸ºåˆ†æï¼Œé¿å…ä¼ ç»Ÿ Lambda æ¶æ„çš„å»¶è¿Ÿå’Œå¤æ‚æ€§ã€‚
3. æ··åˆè´Ÿè½½ç³»ç»Ÿ
   - åŒä¸€é›†ç¾¤åŒæ—¶æ‰¿è½½è®¢å•ç³»ç»Ÿï¼ˆOLTPï¼‰å’ŒæŠ¥è¡¨æŸ¥è¯¢ï¼ˆOLAPï¼‰ï¼Œé™ä½æ¶æ„å¤æ‚åº¦ã€‚
4. äº‘åŸç”Ÿåº”ç”¨
   - å¾®æœåŠ¡æ¶æ„ä¸‹ï¼Œä½œä¸ºæœ‰çŠ¶æ€æœåŠ¡çš„æŒä¹…åŒ–å­˜å‚¨å±‚ï¼Œæ”¯æŒå¼¹æ€§ä¼¸ç¼©ã€‚

------

### **æ¶æ„ç»„ä»¶**

- **TiDB Server**ï¼šè®¡ç®—èŠ‚ç‚¹ï¼Œå¤„ç† SQL è¯·æ±‚ï¼Œæ— çŠ¶æ€å¯æ°´å¹³æ‰©å±•ã€‚
- **PD (Placement Driver)**ï¼šå…ƒæ•°æ®ç®¡ç†å’Œè°ƒåº¦èŠ‚ç‚¹ï¼Œç®¡ç†é›†ç¾¤æ‹“æ‰‘å’Œè´Ÿè½½å‡è¡¡ã€‚
- **TiKV**ï¼šåˆ†å¸ƒå¼é”®å€¼å­˜å‚¨å¼•æ“ï¼ŒåŸºäº Raft åè®®å®ç°æ•°æ®åˆ†ç‰‡å’Œå¼ºä¸€è‡´ã€‚
- **TiFlash**ï¼šåˆ—å¼å­˜å‚¨å¼•æ“ï¼Œä¸ºåˆ†ææŸ¥è¯¢åŠ é€Ÿã€‚
- **TiSpark**ï¼šé€šè¿‡ Spark è¿æ¥ TiDBï¼Œæ”¯æŒå¤æ‚åˆ†æä»»åŠ¡ã€‚

------

### **ä¸åŒç±»æ•°æ®åº“å¯¹æ¯”**



| **ç‰¹æ€§**      | **TiDB**                   | **CockroachDB**             | **YugabyteDB**           |
| ------------- | -------------------------- | --------------------------- | ------------------------ |
| **åè®®å…¼å®¹**  | MySQL                      | PostgreSQL                  | PostgreSQL/Cassandra     |
| **äº‹åŠ¡æ¨¡å‹**  | Percolatorï¼ˆä¹è§‚ï¼‰         | Optimistic/Pessimistic æ··åˆ | HBase é£æ ¼ï¼ˆæ— å…¨å±€æ—¶é’Ÿï¼‰ |
| **HTAP æ”¯æŒ** | åŸç”Ÿæ”¯æŒï¼ˆTiFlashï¼‰        | éœ€å¤–éƒ¨å·¥å…·                  | éœ€å¤–éƒ¨å·¥å…·               |
| **ç”Ÿæ€å·¥å…·**  | ä¸°å¯Œï¼ˆTiDB Dashboardã€BRï¼‰ | è¾ƒç®€å•                      | ä¾èµ– PostgreSQL ç”Ÿæ€     |



------

### **å­¦ä¹ ä¸ä½¿ç”¨å»ºè®®**

1. å¿«é€Ÿä¸Šæ‰‹
   - éƒ¨ç½²æœ¬åœ°æµ‹è¯•ç¯å¢ƒï¼šä½¿ç”¨ `tiup playground` ä¸€é”®å¯åŠ¨å•èŠ‚ç‚¹é›†ç¾¤ã€‚
   - å®˜æ–¹æ–‡æ¡£ï¼šhttps://docs.pingcap.com/
2. æ€§èƒ½è°ƒä¼˜
   - åˆç†é…ç½®åˆ†ç‰‡é”®ï¼ˆé¿å…çƒ­ç‚¹ï¼‰ã€‚
   - é’ˆå¯¹åˆ†æåœºæ™¯ï¼Œä½¿ç”¨ `TiFlash` å‰¯æœ¬ã€‚
3. ç›‘æ§ä¸è¿ç»´
   - å†…ç½® Prometheus + Grafana ç›‘æ§é¢æ¿ã€‚
   - æ”¯æŒ **BR (Backup & Restore)** å·¥å…·å®ç°å…¨é‡/å¢é‡å¤‡ä»½ã€‚

------

### **å…¸å‹ç”¨æˆ·æ¡ˆä¾‹**

- **Shopee**ï¼šä¸œå—äºšç”µå•†å¹³å°ï¼Œä½¿ç”¨ TiDB å¤„ç†æ¯ç§’ 300 ä¸‡æ¬¡è®¢å•å†™å…¥ã€‚
- **çŸ¥ä¹**ï¼šæ”¯æ’‘é—®ç­”ç¤¾åŒºçš„é«˜å¹¶å‘è¯»å†™å’Œå®æ—¶æ•°æ®åˆ†æã€‚
- **å¾®ä¼—é“¶è¡Œ**ï¼šé‡‘èçº§åˆ†å¸ƒå¼æ ¸å¿ƒç³»ç»Ÿï¼Œæ»¡è¶³å¼ºä¸€è‡´æ€§å’Œå®¹ç¾éœ€æ±‚ã€‚

------

TiDB çš„è®¾è®¡ç†å¿µæ˜¯â€œè®©æ•°æ®åº“åƒäº‘æœåŠ¡ä¸€æ ·ç®€å•â€ï¼Œé€‚åˆéœ€è¦**å¤§è§„æ¨¡æ•°æ®ã€é«˜å¹¶å‘ã€å¼ºä¸€è‡´æ€§**ä¸”å¸Œæœ›**é™ä½è¿ç»´å¤æ‚åº¦**çš„åœºæ™¯ã€‚å¦‚æœæ‚¨çš„ä¸šåŠ¡æœ‰ç±»ä¼¼éœ€æ±‚ï¼ŒTiDB æ˜¯ä¸€ä¸ªå€¼å¾—è€ƒè™‘çš„é€‰é¡¹ã€‚



## æ•´ä½“æ¶æ„

TiDBåˆ†å¸ƒå¼æ•°æ®åº“çš„æ•´ä½“æ¶æ„ç”±è®¡ç®—å±‚ã€å­˜å‚¨å±‚å’Œåè°ƒå±‚ä¸‰å¤§æ ¸å¿ƒç»„ä»¶æ„æˆï¼Œå„ç»„ä»¶é€šè¿‡é«˜æ•ˆåä½œå®ç°æ°´å¹³æ‰©å±•ã€é«˜å¯ç”¨å’Œå®æ—¶HTAPèƒ½åŠ›ï¼Œå…·ä½“æ¶æ„å¦‚ä¸‹ï¼š

### **ä¸€ã€è®¡ç®—å±‚ï¼ˆTiDB Serverï¼‰**

- **åŠŸèƒ½**ï¼šä½œä¸ºæ— çŠ¶æ€çš„SQLå±‚ï¼ŒTiDB Serverè´Ÿè´£è§£æSQLã€ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ï¼Œå¹¶ä¸å­˜å‚¨å±‚äº¤äº’è·å–æ•°æ®ã€‚
- ç‰¹æ€§ï¼š
  - æ”¯æŒMySQLåè®®å’Œè¯­æ³•ï¼Œå…¼å®¹æ€§æé«˜ï¼Œå¯æ— ç¼è¿ç§»ç°æœ‰åº”ç”¨ã€‚
  - æ°´å¹³æ‰©å±•èƒ½åŠ›å¼ºï¼Œé€šè¿‡è´Ÿè½½å‡è¡¡ç»„ä»¶ï¼ˆå¦‚LVSã€HAProxyï¼‰å®ç°å¤šå®ä¾‹éƒ¨ç½²ï¼Œæå‡å¹¶å‘å¤„ç†èƒ½åŠ›ã€‚
- **ä½œç”¨**ï¼šå°†SQLè¯·æ±‚è½¬æ¢ä¸ºå¯¹å­˜å‚¨å±‚çš„é”®å€¼æ“ä½œï¼Œæ˜¯ç³»ç»Ÿçš„å…¥å£å’Œè®¡ç®—æ ¸å¿ƒã€‚

### **äºŒã€å­˜å‚¨å±‚**

#### **1. TiKVï¼ˆè¡Œå­˜å‚¨å¼•æ“ï¼‰**

- **åŠŸèƒ½**ï¼šè´Ÿè´£OLTPæ•°æ®çš„å­˜å‚¨ï¼Œé‡‡ç”¨è¡Œå­˜å‚¨æ ¼å¼ï¼Œæ”¯æŒäº‹åŠ¡æœºåˆ¶ã€‚
- ç‰¹æ€§ï¼š
  - **Regionåˆ†ç‰‡**ï¼šæ•°æ®æŒ‰Key Rangeåˆ†ç‰‡ä¸ºRegionï¼Œæ¯ä¸ªRegioné»˜è®¤çº¦96MB-140MBï¼Œè¶…è¿‡é˜ˆå€¼è‡ªåŠ¨åˆ†è£‚ã€‚
  - **å¤šå‰¯æœ¬å¼ºä¸€è‡´**ï¼šé»˜è®¤3å‰¯æœ¬ï¼ŒåŸºäºRaftåè®®å®ç°å¼ºä¸€è‡´æ€§ï¼Œæ”¯æŒè‡ªåŠ¨æ•…éšœè½¬ç§»ã€‚
  - **MVCCå¹¶å‘æ§åˆ¶**ï¼šå®ç°å¤šç‰ˆæœ¬å¹¶å‘æ§åˆ¶ï¼Œé¿å…è¯»å†™å†²çªã€‚
- **ä½œç”¨**ï¼šæä¾›é«˜å¯ç”¨çš„OLTPå­˜å‚¨èƒ½åŠ›ï¼Œç¡®ä¿æ•°æ®å¼ºä¸€è‡´æ€§å’Œäº‹åŠ¡æ”¯æŒã€‚

#### **2. TiFlashï¼ˆåˆ—å­˜å‚¨å¼•æ“ï¼‰**

- **åŠŸèƒ½**ï¼šä¸“é—¨ç”¨äºOLAPåˆ†æåœºæ™¯ï¼Œæä¾›åˆ—å¼å­˜å‚¨ã€‚
- ç‰¹æ€§ï¼š
  - **å¼‚æ­¥å¤åˆ¶**ï¼šå®æ—¶ä»TiKVå¤åˆ¶æ•°æ®ï¼Œä¿è¯ä¸TiKVçš„ä¸€è‡´æ€§è¯»å–ã€‚
  - **é«˜æ•ˆåˆ†ææŸ¥è¯¢**ï¼šåˆ—å¼å­˜å‚¨æå‡åˆ†ææŸ¥è¯¢æ•ˆç‡ï¼Œé€‚åˆå¤§è§„æ¨¡æ•°æ®åˆ†æã€‚
- **ä½œç”¨**ï¼šå®ç°å®æ—¶HTAPèƒ½åŠ›ï¼Œåœ¨åŒä¸€é›†ç¾¤ä¸­åŒæ—¶æ”¯æŒäº‹åŠ¡å’Œåˆ†æè´Ÿè½½ã€‚

### **ä¸‰ã€åè°ƒå±‚ï¼ˆPlacement Driverï¼ŒPDï¼‰**

- **åŠŸèƒ½**ï¼šä½œä¸ºé›†ç¾¤çš„â€œå¤§è„‘â€ï¼Œè´Ÿè´£å…ƒæ•°æ®ç®¡ç†ã€è°ƒåº¦å’Œè´Ÿè½½å‡è¡¡ã€‚
- ç‰¹æ€§ï¼š
  - **å…ƒæ•°æ®å­˜å‚¨**ï¼šå­˜å‚¨æ¯ä¸ªTiKVèŠ‚ç‚¹çš„å®æ—¶æ•°æ®åˆ†å¸ƒæƒ…å†µå’Œé›†ç¾¤æ‹“æ‰‘ç»“æ„ã€‚
  - **è°ƒåº¦å’Œè´Ÿè½½å‡è¡¡**ï¼šæ ¹æ®æ•°æ®åˆ†å¸ƒçŠ¶æ€ï¼Œä¸‹å‘è°ƒåº¦å‘½ä»¤ï¼Œç¡®ä¿æ•°æ®å‡åŒ€åˆ†å¸ƒå’Œè´Ÿè½½å‡è¡¡ã€‚
  - **äº‹åŠ¡IDåˆ†é…**ï¼šä¸ºåˆ†å¸ƒå¼äº‹åŠ¡åˆ†é…å…¨å±€å”¯ä¸€ä¸”é€’å¢çš„äº‹åŠ¡IDã€‚
  - **é«˜å¯ç”¨æ€§**ï¼šè‡³å°‘3ä¸ªèŠ‚ç‚¹æ„æˆï¼Œæ”¯æŒè‡ªåŠ¨æ•…éšœåˆ‡æ¢ã€‚
- **ä½œç”¨**ï¼šç¡®ä¿é›†ç¾¤çš„é«˜å¯ç”¨æ€§ã€æ•°æ®ä¸€è‡´æ€§å’Œæ€§èƒ½ä¼˜åŒ–ã€‚

### **å››ã€æ¶æ„åä½œæµç¨‹**

1. **SQLè¯·æ±‚å¤„ç†**ï¼šå®¢æˆ·ç«¯å‘é€SQLè¯·æ±‚åˆ°TiDB Serverï¼ŒTiDB Serverè§£æSQLå¹¶ç”Ÿæˆæ‰§è¡Œè®¡åˆ’ã€‚
2. **æ•°æ®å®šä½**ï¼šTiDB Serveré€šè¿‡PDè·å–æ•°æ®å­˜å‚¨ä½ç½®ï¼ˆTiKVæˆ–TiFlashï¼‰ã€‚
3. æ•°æ®è¯»å–ä¸è®¡ç®—ï¼š
   - å¯¹äºOLTPè¯·æ±‚ï¼ŒTiDB Serverå°†è¯·æ±‚è½¬å‘åˆ°TiKVæ‰§è¡Œã€‚
   - å¯¹äºOLAPè¯·æ±‚ï¼ŒTiDB Serverå¯æ ¹æ®ä¼˜åŒ–å™¨é€‰æ‹©TiKVæˆ–TiFlashæ‰§è¡Œã€‚
4. **ç»“æœè¿”å›**ï¼šTiDB Serverå°†æ‰§è¡Œç»“æœè¿”å›ç»™å®¢æˆ·ç«¯ã€‚

### **äº”ã€æ¶æ„ä¼˜åŠ¿**

1. **æ°´å¹³æ‰©å±•æ€§**ï¼šé€šè¿‡å¢åŠ TiKVæˆ–TiFlashèŠ‚ç‚¹ï¼Œè½»æ¾æ‰©å±•å­˜å‚¨å’Œè®¡ç®—èƒ½åŠ›ã€‚
2. **é«˜å¯ç”¨æ€§**ï¼šå¤šå‰¯æœ¬å’Œè‡ªåŠ¨æ•…éšœè½¬ç§»æœºåˆ¶ç¡®ä¿ç³»ç»Ÿåœ¨èŠ‚ç‚¹æ•…éšœæ—¶ä»èƒ½æ­£å¸¸è¿è¡Œã€‚
3. **å®æ—¶HTAPèƒ½åŠ›**ï¼šTiDBå’ŒTiFlashçš„ç»“åˆï¼Œå®ç°äº‹åŠ¡å’Œåˆ†æè´Ÿè½½çš„å®æ—¶å¤„ç†ï¼Œé¿å…æ•°æ®åŒæ­¥å»¶è¿Ÿã€‚
4. **MySQLå…¼å®¹æ€§**ï¼šæ— ç¼è¿ç§»ç°æœ‰MySQLåº”ç”¨ï¼Œé™ä½è¿ç§»æˆæœ¬ã€‚



## éƒ¨ç½²

>[å‚è€ƒå®˜æ–¹æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/quick-start-with-tidb)



### éƒ¨ç½²æœ¬åœ°æµ‹è¯•é›†ç¾¤

>æ³¨æ„ï¼šTiUP Playground é»˜è®¤ç›‘å¬ `127.0.0.1`ï¼ŒæœåŠ¡ä»…æœ¬åœ°å¯è®¿é—®ã€‚è‹¥éœ€è¦ä½¿æœåŠ¡å¯è¢«å¤–éƒ¨è®¿é—®ï¼Œå¯ä½¿ç”¨ `--host` å‚æ•°æŒ‡å®šç›‘å¬ç½‘å¡ç»‘å®šå¤–éƒ¨å¯è®¿é—®çš„ IPã€‚

æœ¬èŠ‚ä»‹ç»å¦‚ä½•åˆ©ç”¨æœ¬åœ° macOS æˆ–è€…å•æœº Linux ç¯å¢ƒå¿«é€Ÿéƒ¨ç½² TiDB æµ‹è¯•é›†ç¾¤ã€‚é€šè¿‡éƒ¨ç½² TiDB é›†ç¾¤ï¼Œä½ å¯ä»¥äº†è§£ TiDB çš„åŸºæœ¬æ¶æ„ï¼Œä»¥åŠ TiDBã€TiKVã€PDã€ç›‘æ§ç­‰åŸºç¡€ç»„ä»¶çš„è¿è¡Œã€‚

TiDB æ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿã€‚æœ€åŸºç¡€çš„ TiDB æµ‹è¯•é›†ç¾¤é€šå¸¸ç”± 2 ä¸ª TiDB å®ä¾‹ã€3 ä¸ª TiKV å®ä¾‹ã€3 ä¸ª PD å®ä¾‹å’Œå¯é€‰çš„ TiFlash å®ä¾‹æ„æˆã€‚é€šè¿‡ TiUP Playgroundï¼Œå¯ä»¥å¿«é€Ÿæ­å»ºå‡ºä¸Šè¿°çš„ä¸€å¥—åŸºç¡€æµ‹è¯•é›†ç¾¤ï¼Œæ­¥éª¤å¦‚ä¸‹ï¼š

1. ä¸‹è½½å¹¶å®‰è£… TiUPã€‚

   ```bash
   $ curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh
     % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current
                                    Dload  Upload   Total   Spent    Left  Speed
   100 5180k  100 5180k    0     0  9774k      0 --:--:-- --:--:-- --:--:-- 9774k
   Successfully set mirror to https://tiup-mirrors.pingcap.com
   Detected shell: bash
   Shell profile:  /root/.bashrc
   /root/.bashrc has been modified to add tiup to PATH
   open a new terminal or source /root/.bashrc to use it
   Installed path: /root/.tiup/bin/tiup
   ===============================================
   Have a try:     tiup playground
   ===============================================
   
   ```

2. åŠ è½½æœ€æ–°çš„ /root/.bashrc ä»¥ä½¿ç”¨ tiup å‘½ä»¤

   ```bash
   source /root/.bashrc
   ```

3. æ£€æŸ¥ tiup å‘½ä»¤

   ```bash
   $ tiup --version
   1.16.2 v1.16.2-nightly-7
   Go Version: go1.21.13
   Git Ref: master
   GitHash: 2a6bd3144e8d3ed8329e035f2580d3800b02f4be
   ```

4. åœ¨å½“å‰ session æ‰§è¡Œä»¥ä¸‹å‘½ä»¤å¯åŠ¨é›†ç¾¤ã€‚

   >æ³¨æ„ï¼š
   >
   >- å¦‚æœæŒ‰ä»¥ä¸‹æ–¹å¼æ‰§è¡Œ playgroundï¼Œåœ¨ç»“æŸéƒ¨ç½²æµ‹è¯•åï¼ŒTiUP ä¼šè‡ªåŠ¨æ¸…ç†æ‰åŸé›†ç¾¤æ•°æ®ï¼Œé‡æ–°æ‰§è¡Œå‘½ä»¤ä¼šå¾—åˆ°ä¸€ä¸ªå…¨æ–°çš„é›†ç¾¤ã€‚
   >
   >- å¦‚æœå¸Œæœ›æŒä¹…åŒ–æ•°æ®ï¼Œéœ€è¦åœ¨å¯åŠ¨é›†ç¾¤æ—¶æ·»åŠ  TiUP çš„ `--tag` å‚æ•°ï¼Œè¯¦è§ [å¯åŠ¨é›†ç¾¤æ—¶æŒ‡å®š `tag` ä»¥ä¿ç•™æ•°æ®](https://docs.pingcap.com/zh/tidb/stable/tiup-playground/#å¯åŠ¨é›†ç¾¤æ—¶æŒ‡å®š-tag-ä»¥ä¿ç•™æ•°æ®)ã€‚
   >
   >  ```bash
   >  tiup playground --tag ${tag_name}
   >  ```
   >
   >  

   - ç›´æ¥è¿è¡Œ `tiup playground` å‘½ä»¤ä¼šè¿è¡Œæœ€æ–°ç‰ˆæœ¬çš„ TiDB é›†ç¾¤ï¼Œå…¶ä¸­ TiDBã€TiKVã€PD å’Œ TiFlash å®ä¾‹å„ 1 ä¸ªï¼š

     ```bash
     $ tiup playground
     Checking updates for component playground... 
     A new version of playground is available:  -> v1.16.2
     
         To update this component:   tiup update playground
         To update all components:   tiup update --all
     
     The component `playground` version  is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/playground-v1.16.2-linux-amd64.tar.gz 8.20 MiB / 8.20 MiB 100.00% 64.31 MiB/s                                                                                            
     
     Note: Version constraint  is resolved to v8.5.1. If you'd like to use other versions:
     
         Use exact version:      tiup playground v7.1.0
         Use version range:      tiup playground ^5
         Use nightly:            tiup playground nightly
     
     The component `pd` version v8.5.1 is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/pd-v8.5.1-linux-amd64.tar.gz 54.32 MiB / 54.32 MiB 100.00% 18.41 MiB/s                                                                                                   
     Start pd instance: v8.5.1
     The component `tikv` version v8.5.1 is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/tikv-v8.5.1-linux-amd64.tar.gz 364.63 MiB / 364.63 MiB 100.00% 18.53 MiB/s                                                                                               
     Start tikv instance: v8.5.1
     The component `tidb` version v8.5.1 is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/tidb-v8.5.1-linux-amd64.tar.gz 91.70 MiB / 91.70 MiB 100.00% 21.57 MiB/s                                                                                                 
     Start tidb instance: v8.5.1
     Waiting for tidb instances ready
     - TiDB: 127.0.0.1:4000 ... Done
     The component `prometheus` version v8.5.1 is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/prometheus-v8.5.1-linux-amd64.tar.gz 122.53 MiB / 122.53 MiB 100.00% 11.92 MiB/s                                                                                         
     download https://tiup-mirrors.pingcap.com/grafana-v8.5.1-linux-amd64.tar.gz 50.18 MiB / 50.18 MiB 100.00% 27.01 MiB/s                                                                                              
     The component `tiflash` version v8.5.1 is not installed; downloading from repository.
     download https://tiup-mirrors.pingcap.com/tiflash-v8.5.1-linux-amd64.tar.gz 509.42 MiB / 509.42 MiB 100.00% 12.61 MiB/s                                                                                            
     Start tiflash instance: v8.5.1
     Waiting for tiflash instances ready
     - TiFlash: 127.0.0.1:3930 ... Done
     
     ğŸ‰ TiDB Playground Cluster is started, enjoy!
     
     Connect TiDB:    mysql --comments --host 127.0.0.1 --port 4000 -u root
     TiDB Dashboard:  http://127.0.0.1:2379/dashboard
     Grafana:         http://127.0.0.1:3000
     
     ```

   - æˆ–è€…æŒ‡å®š TiDB ç‰ˆæœ¬ä»¥åŠå„ç»„ä»¶å®ä¾‹ä¸ªæ•°ï¼Œå‘½ä»¤ç±»ä¼¼äºï¼š

     ```bash
     tiup playground v8.5.1 --db 2 --pd 3 --kv 3
     ```

     å¦‚æœè¦æŸ¥çœ‹å½“å‰æ”¯æŒéƒ¨ç½²çš„æ‰€æœ‰ TiDB ç‰ˆæœ¬ï¼Œæ‰§è¡Œ `tiup list tidb`ã€‚

5. æ–°å¼€å¯ä¸€ä¸ª session ä»¥è®¿é—® TiDB æ•°æ®åº“å’Œé›†ç¾¤ç«¯ç‚¹ã€‚

   - è¿æ¥ TiDB æ•°æ®åº“ï¼š

     - ä½¿ç”¨ TiUP `client` è¿æ¥ TiDBï¼š

       ```bash
       tiup client
       ```

     - æˆ–è€…ä½¿ç”¨ MySQL å®¢æˆ·ç«¯è¿æ¥ TiDBï¼š

       ```bash
       mysql --host 127.0.0.1 --port 4000 -u root
       ```

   - è®¿é—® Prometheus ç®¡ç†ç•Œé¢ï¼š[http://127.0.0.1:9090](http://127.0.0.1:9090/)ã€‚

   - è®¿é—® [TiDB Dashboard](https://docs.pingcap.com/zh/tidb/stable/dashboard-intro/) é¡µé¢ï¼šhttp://127.0.0.1:2379/dashboardï¼Œé»˜è®¤ç”¨æˆ·åä¸º `root`ï¼Œå¯†ç ä¸ºç©ºã€‚

   - è®¿é—® Grafana ç•Œé¢ï¼š[http://127.0.0.1:3000](http://127.0.0.1:3000/)ï¼Œé»˜è®¤ç”¨æˆ·åå’Œå¯†ç éƒ½ä¸º `admin`ã€‚

6. æµ‹è¯•å®Œæˆä¹‹åï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ¥æ¸…ç†é›†ç¾¤ï¼š

   - æŒ‰ä¸‹ Control+C é”®åœæ‰ä¸Šè¿°å¯ç”¨çš„ TiDB æœåŠ¡ã€‚

   - ç­‰å¾…æœåŠ¡é€€å‡ºæ“ä½œå®Œæˆåï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

     ```bash
     tiup clean --all
     ```

     æ¸…ç†æ‰€æœ‰é€šè¿‡ TiUP å®‰è£…çš„ç»„ä»¶åŠå…¶ç›¸å…³æ•°æ®ï¼Œå½»åº•åˆ é™¤ TiUP ç®¡ç†çš„æ‰€æœ‰ç»„ä»¶ï¼ˆå¦‚ TiDBã€PDã€TiKVã€TiDB Dashboard ç­‰ï¼‰åŠå…¶è¿è¡Œæ—¶äº§ç”Ÿçš„æ•°æ®ï¼ˆå¦‚æ—¥å¿—ã€ä¸´æ—¶æ–‡ä»¶ç­‰ï¼‰ã€‚



### åœ¨å•æœºä¸Šæ¨¡æ‹Ÿéƒ¨ç½²ç”Ÿäº§ç¯å¢ƒé›†ç¾¤

æœ¬èŠ‚ä»‹ç»å¦‚ä½•åœ¨å•å° Linux æœåŠ¡å™¨ä¸Šä½“éªŒ TiDB æœ€å°çš„å®Œæ•´æ‹“æ‰‘çš„é›†ç¾¤ï¼Œå¹¶æ¨¡æ‹Ÿç”Ÿäº§ç¯å¢ƒä¸‹çš„éƒ¨ç½²æ­¥éª¤ã€‚

ä¸‹æ–‡å°†å‚ç…§ TiUP æœ€å°æ‹“æ‰‘çš„ä¸€ä¸ª YAML æ–‡ä»¶éƒ¨ç½² TiDB é›†ç¾¤ã€‚

1. ä¸‹è½½å¹¶å®‰è£… TiUPï¼š

   ```bash
   curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh
   ```

2. åŠ è½½æœ€æ–°çš„ /root/.bashrc ä»¥ä½¿ç”¨ tiup å‘½ä»¤

   ```bash
   source /root/.bashrc
   ```

3. æ£€æŸ¥ tiup å‘½ä»¤

   ```bash
   $ tiup --version
   1.16.2 v1.16.2-nightly-7
   Go Version: go1.21.13
   Git Ref: master
   GitHash: 2a6bd3144e8d3ed8329e035f2580d3800b02f4be
   ```

4. å®‰è£… TiUP çš„ cluster ç»„ä»¶ï¼š

   ```bash
   tiup cluster
   ```

5. å¦‚æœæœºå™¨å·²ç»å®‰è£… TiUP clusterï¼Œéœ€è¦æ›´æ–°è½¯ä»¶ç‰ˆæœ¬ï¼š

   ```bash
   tiup update --self && tiup update cluster
   ```

6. ç”±äºæ¨¡æ‹Ÿå¤šæœºéƒ¨ç½²ï¼Œéœ€è¦é€šè¿‡ root ç”¨æˆ·è°ƒå¤§ sshd æœåŠ¡çš„è¿æ¥æ•°é™åˆ¶ï¼š

   - ä¿®æ”¹ `/etc/ssh/sshd_config` å°† `MaxSessions` è°ƒè‡³ 20ã€‚

   - é‡å¯ sshd æœåŠ¡ï¼š

     ```bash
     service sshd restart
     ```

7. åˆ›å»ºå¹¶å¯åŠ¨é›†ç¾¤ï¼š

   æŒ‰ä¸‹é¢çš„é…ç½®æ¨¡æ¿ï¼Œåˆ›å»ºå¹¶ç¼–è¾‘ [æ‹“æ‰‘é…ç½®æ–‡ä»¶](https://docs.pingcap.com/zh/tidb/stable/tiup-cluster-topology-reference/)ï¼Œå‘½åä¸º `topo.yaml`ã€‚å…¶ä¸­ï¼š

   - `user: "tidb"`ï¼šè¡¨ç¤ºé€šè¿‡ `tidb` ç³»ç»Ÿç”¨æˆ·ï¼ˆéƒ¨ç½²ä¼šè‡ªåŠ¨åˆ›å»ºï¼‰æ¥åšé›†ç¾¤çš„å†…éƒ¨ç®¡ç†ï¼Œé»˜è®¤ä½¿ç”¨ 22 ç«¯å£é€šè¿‡ ssh ç™»å½•ç›®æ ‡æœºå™¨
   - `replication.enable-placement-rules`ï¼šè®¾ç½®è¿™ä¸ª PD å‚æ•°æ¥ç¡®ä¿ TiFlash æ­£å¸¸è¿è¡Œ
   - `host`ï¼šè®¾ç½®ä¸ºæœ¬éƒ¨ç½²ä¸»æœºçš„ IP

   é…ç½®æ¨¡æ¿å¦‚ä¸‹ï¼š

   ```yaml
   # # Global variables are applied to all deployments and used as the default value of
   # # the deployments if a specific deployment value is missing.
   global:
    user: "tidb"
    ssh_port: 22
    deploy_dir: "/tidb-deploy"
    data_dir: "/tidb-data"
   
   # # Monitored variables are applied to all the machines.
   monitored:
    node_exporter_port: 9100
    blackbox_exporter_port: 9115
   
   server_configs:
    tidb:
      instance.tidb_slow_log_threshold: 300
    tikv:
      readpool.storage.use-unified-pool: false
      readpool.coprocessor.use-unified-pool: true
    pd:
      replication.enable-placement-rules: true
      replication.location-labels: ["host"]
    tiflash:
      logger.level: "info"
   
   pd_servers:
    - host: 192.168.235.156
   
   tidb_servers:
    - host: 192.168.235.156
   
   tikv_servers:
    - host: 192.168.235.156
      port: 20160
      status_port: 20180
      config:
        server.labels: { host: "logic-host-1" }
   
    - host: 192.168.235.156
      port: 20161
      status_port: 20181
      config:
        server.labels: { host: "logic-host-2" }
   
    - host: 192.168.235.156
      port: 20162
      status_port: 20182
      config:
        server.labels: { host: "logic-host-3" }
   
   tiflash_servers:
    - host: 192.168.235.156
   
   monitoring_servers:
    - host: 192.168.235.156
   
   grafana_servers:
    - host: 192.168.235.156
   ```

8. æ‰§è¡Œé›†ç¾¤éƒ¨ç½²å‘½ä»¤ï¼š

   ```bash
   tiup cluster deploy <cluster-name> <version> ./topo.yaml --user root -p
   ```

   - å‚æ•° `<cluster-name>` è¡¨ç¤ºè®¾ç½®é›†ç¾¤åç§°
   - å‚æ•° `<version>` è¡¨ç¤ºè®¾ç½®é›†ç¾¤ç‰ˆæœ¬ï¼Œä¾‹å¦‚ `v8.5.1`ã€‚å¯ä»¥é€šè¿‡ `tiup list tidb` å‘½ä»¤æ¥æŸ¥çœ‹å½“å‰æ”¯æŒéƒ¨ç½²çš„ TiDB ç‰ˆæœ¬
   - å‚æ•° `--user` è¡¨ç¤ºåˆå§‹åŒ–ç¯å¢ƒçš„ç”¨æˆ·
   - å‚æ•° `-p` è¡¨ç¤ºåœ¨è¿æ¥ç›®æ ‡æœºå™¨æ—¶ä½¿ç”¨å¯†ç ç™»å½•

   >æ³¨æ„ï¼šå¦‚æœä¸»æœºé€šè¿‡å¯†é’¥è¿›è¡Œ SSH è®¤è¯ï¼Œè¯·ä½¿ç”¨ `-i` å‚æ•°æŒ‡å®šå¯†é’¥æ–‡ä»¶è·¯å¾„ï¼Œ`-i` ä¸ `-p` ä¸å¯åŒæ—¶ä½¿ç”¨ã€‚

   æŒ‰ç…§å¼•å¯¼ï¼Œè¾“å…¥â€yâ€åŠ root å¯†ç ï¼Œæ¥å®Œæˆéƒ¨ç½²ï¼š

   ```bash
   Do you want to continue? [y/N]:  y
   Input SSH password:
   ```

9. å¯åŠ¨é›†ç¾¤ï¼š

   ```bash
   tiup cluster start <cluster-name>
   ```

10. è®¿é—®é›†ç¾¤ç«¯ç‚¹ï¼š

    - å®‰è£… MySQL å®¢æˆ·ç«¯ã€‚å¦‚æœå·²å®‰è£…ï¼Œåˆ™è·³è¿‡è¿™ä¸€æ­¥éª¤ã€‚

      ```bash
      yum -y install mysql
      ```

    - ä½¿ç”¨ MySQL å®¢æˆ·ç«¯è®¿é—® TiDB æ•°æ®åº“ï¼Œå¯†ç ä¸ºç©ºï¼š

      ```bash
      mysql -h 192.168.235.156 -P 4000 -u root
      ```

    - è®¿é—® Grafana ç›‘æ§é¡µé¢ï¼š[http://{grafana-ip}:3000](http://{grafana-ip}:3000/)ï¼Œé»˜è®¤ç”¨æˆ·åå’Œå¯†ç å‡ä¸º `admin`ã€‚

    - è®¿é—®é›†ç¾¤ [TiDB Dashboard](https://docs.pingcap.com/zh/tidb/stable/dashboard-intro/) ç›‘æ§é¡µé¢ï¼šhttp://{pd-ip}:2379/dashboardï¼Œé»˜è®¤ç”¨æˆ·åä¸º `root`ï¼Œå¯†ç ä¸ºç©ºã€‚

11. ï¼ˆå¯é€‰ï¼‰æŸ¥çœ‹é›†ç¾¤åˆ—è¡¨å’Œæ‹“æ‰‘ç»“æ„ï¼š

    - æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ç¡®è®¤å½“å‰å·²ç»éƒ¨ç½²çš„é›†ç¾¤åˆ—è¡¨ï¼š

      ```bash
      tiup cluster list
      ```

    - æ‰§è¡Œä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹é›†ç¾¤çš„æ‹“æ‰‘ç»“æ„å’ŒçŠ¶æ€ï¼š

      ```bash
      tiup cluster display <cluster-name>
      ```

12. æµ‹è¯•å®Œæˆä¹‹åï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œä»¥ä¸‹æ­¥éª¤æ¥æ¸…ç†é›†ç¾¤ï¼š

    - åœæ­¢é›†ç¾¤ã€‚

      ```bash
      tiup cluster stop <cluster-name>
      ```
    
    - åˆ é™¤é›†ç¾¤çš„æ‰€æœ‰æ•°æ®ï¼ˆä½†ä¸åˆ é™¤é›†ç¾¤ï¼‰ï¼Œæ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š
    
      ```bash
      tiup cluster clean <cluster-name> --all
      ```
      
    - åˆ é™¤é›†ç¾¤
    
      ```bash
      tiup cluster destroy <cluster-name>
      ```
    
      

### éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒé›†ç¾¤

>[å‚è€ƒå®˜æ–¹æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/production-deployment-using-tiup/)

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ä½¿ç”¨ [TiUP](https://github.com/pingcap/tiup) éƒ¨ç½² TiDB é›†ç¾¤ã€‚

TiUP æ˜¯åœ¨ TiDB v4.0 ä¸­å¼•å…¥çš„é›†ç¾¤è¿ç»´å·¥å…·ï¼Œæä¾›äº†ä½¿ç”¨ Golang ç¼–å†™çš„é›†ç¾¤ç®¡ç†ç»„ä»¶ [TiUP cluster](https://github.com/pingcap/tiup/tree/master/components/cluster)ã€‚é€šè¿‡ä½¿ç”¨ TiUP cluster ç»„ä»¶ï¼Œä½ å¯ä»¥è½»æ¾æ‰§è¡Œæ—¥å¸¸çš„æ•°æ®åº“è¿ç»´æ“ä½œï¼ŒåŒ…æ‹¬éƒ¨ç½²ã€å¯åŠ¨ã€å…³é—­ã€é”€æ¯ã€å¼¹æ€§æ‰©ç¼©å®¹ã€å‡çº§ TiDB é›†ç¾¤ï¼Œä»¥åŠç®¡ç† TiDB é›†ç¾¤å‚æ•°ã€‚

TiUP è¿˜æ”¯æŒéƒ¨ç½² TiDBã€TiFlashã€TiCDC ä»¥åŠç›‘æ§ç³»ç»Ÿã€‚æœ¬æŒ‡å—ä»‹ç»äº†å¦‚ä½•éƒ¨ç½²ä¸åŒæ‹“æ‰‘çš„ TiDB é›†ç¾¤ã€‚

#### è½¯ç¡¬ä»¶ç¯å¢ƒéœ€æ±‚åŠå‰ç½®æ£€æŸ¥

åŠ¡å¿…é˜…è¯»ä»¥ä¸‹æ–‡æ¡£ï¼š

- [è½¯ç¡¬ä»¶ç¯å¢ƒéœ€æ±‚](https://docs.pingcap.com/zh/tidb/stable/hardware-and-software-requirements/)
- [ç¯å¢ƒä¸ç³»ç»Ÿé…ç½®æ£€æŸ¥](https://docs.pingcap.com/zh/tidb/stable/check-before-deployment/)

æ­¤å¤–ï¼Œå»ºè®®é˜…è¯»äº†è§£ [TiDB å®‰å…¨é…ç½®æœ€ä½³å®è·µ](https://docs.pingcap.com/zh/tidb/stable/best-practices-for-security-configuration/)ã€‚

TiDB æ”¯æŒéƒ¨ç½²å’Œè¿è¡Œåœ¨ Intel x86-64 æ¶æ„çš„ 64 ä½é€šç”¨ç¡¬ä»¶æœåŠ¡å™¨å¹³å°æˆ–è€… ARM æ¶æ„çš„ç¡¬ä»¶æœåŠ¡å™¨å¹³å°ã€‚å¯¹äºå¼€å‘ã€æµ‹è¯•åŠç”Ÿäº§ç¯å¢ƒçš„æœåŠ¡å™¨ç¡¬ä»¶é…ç½®ï¼ˆä¸åŒ…å«æ“ä½œç³»ç»Ÿ OS æœ¬èº«çš„å ç”¨ï¼‰æœ‰ä»¥ä¸‹è¦æ±‚å’Œå»ºè®®ï¼š

##### å¼€å‘åŠæµ‹è¯•ç¯å¢ƒ

| **ç»„ä»¶** | **CPU** | **å†…å­˜** | **æœ¬åœ°å­˜å‚¨**                                                 | **ç½‘ç»œ** | **å®ä¾‹æ•°é‡(æœ€ä½è¦æ±‚)** |
| :------- | :------ | :------- | :----------------------------------------------------------- | :------- | :--------------------- |
| TiDB     | 8 æ ¸+   | 16 GB+   | [ç£ç›˜ç©ºé—´è¦æ±‚](https://docs.pingcap.com/zh/tidb/stable/hardware-and-software-requirements/#ç£ç›˜ç©ºé—´è¦æ±‚) | åƒå…†ç½‘å¡ | 1ï¼ˆå¯ä¸ PD åŒæœºå™¨ï¼‰    |
| PD       | 4 æ ¸+   | 8 GB+    | SAS, 200 GB+                                                 | åƒå…†ç½‘å¡ | 1ï¼ˆå¯ä¸ TiDB åŒæœºå™¨ï¼‰  |
| TiKV     | 8 æ ¸+   | 32 GB+   | SSD, 200 GB+                                                 | åƒå…†ç½‘å¡ | 3                      |
| TiFlash  | 32 æ ¸+  | 64 GB+   | SSD, 200 GB+                                                 | åƒå…†ç½‘å¡ | 1                      |
| TiCDC    | 8 æ ¸+   | 16 GB+   | SAS, 200 GB+                                                 | åƒå…†ç½‘å¡ | 1                      |

>æ³¨æ„
>
>- éªŒè¯æµ‹è¯•ç¯å¢ƒä¸­çš„ TiDB å’Œ PD å¯ä»¥éƒ¨ç½²åœ¨åŒä¸€å°æœåŠ¡å™¨ä¸Šã€‚
>- å¦‚è¿›è¡Œæ€§èƒ½ç›¸å…³çš„æµ‹è¯•ï¼Œé¿å…é‡‡ç”¨ä½æ€§èƒ½å­˜å‚¨å’Œç½‘ç»œç¡¬ä»¶é…ç½®ï¼Œé˜²æ­¢å¯¹æµ‹è¯•ç»“æœçš„æ­£ç¡®æ€§äº§ç”Ÿå¹²æ‰°ã€‚
>- TiKV çš„ SSD ç›˜æ¨èä½¿ç”¨ NVME æ¥å£ä»¥ä¿è¯è¯»å†™æ›´å¿«ã€‚
>- å¦‚æœä»…éªŒè¯åŠŸèƒ½ï¼Œå»ºè®®ä½¿ç”¨ [TiDB æ•°æ®åº“å¿«é€Ÿä¸Šæ‰‹æŒ‡å—](https://docs.pingcap.com/zh/tidb/stable/quick-start-with-tidb/)è¿›è¡Œå•æœºåŠŸèƒ½æµ‹è¯•ã€‚
>- ä» v6.3.0 å¼€å§‹ï¼Œåœ¨ Linux AMD64 æ¶æ„çš„ç¡¬ä»¶å¹³å°éƒ¨ç½² TiFlash æ—¶ï¼ŒCPU å¿…é¡»æ”¯æŒ AVX2 æŒ‡ä»¤é›†ã€‚ç¡®ä¿å‘½ä»¤ `grep avx2 /proc/cpuinfo` æœ‰è¾“å‡ºã€‚è€Œåœ¨ Linux ARM64 æ¶æ„çš„ç¡¬ä»¶å¹³å°éƒ¨ç½² TiFlash æ—¶ï¼ŒCPU å¿…é¡»æ”¯æŒ ARMv8 æ¶æ„ã€‚ç¡®ä¿å‘½ä»¤ `grep 'crc32' /proc/cpuinfo | grep 'asimd'` æœ‰è¾“å‡ºã€‚é€šè¿‡ä½¿ç”¨å‘é‡æ‰©å±•æŒ‡ä»¤é›†ï¼ŒTiFlash çš„å‘é‡åŒ–å¼•æ“èƒ½æä¾›æ›´å¥½çš„æ€§èƒ½ã€‚

##### ç”Ÿäº§ç¯å¢ƒ

| **ç»„ä»¶** | **CPU** | **å†…å­˜** | **ç¡¬ç›˜ç±»å‹**   | **ç½‘ç»œ**             | **å®ä¾‹æ•°é‡(æœ€ä½è¦æ±‚)** |
| :------- | :------ | :------- | :------------- | :------------------- | :--------------------- |
| TiDB     | 16 æ ¸+  | 48 GB+   | SSD            | ä¸‡å…†ç½‘å¡ï¼ˆ2 å—æœ€ä½³ï¼‰ | 2                      |
| PD       | 8 æ ¸+   | 16 GB+   | SSD            | ä¸‡å…†ç½‘å¡ï¼ˆ2 å—æœ€ä½³ï¼‰ | 3                      |
| TiKV     | 16 æ ¸+  | 64 GB+   | SSD            | ä¸‡å…†ç½‘å¡ï¼ˆ2 å—æœ€ä½³ï¼‰ | 3                      |
| TiFlash  | 48 æ ¸+  | 128 GB+  | 1 or more SSDs | ä¸‡å…†ç½‘å¡ï¼ˆ2 å—æœ€ä½³ï¼‰ | 2                      |
| TiCDC    | 16 æ ¸+  | 64 GB+   | SSD            | ä¸‡å…†ç½‘å¡ï¼ˆ2 å—æœ€ä½³ï¼‰ | 2                      |
| ç›‘æ§     | 8 æ ¸+   | 16 GB+   | SAS            | åƒå…†ç½‘å¡             | 1                      |

>æ³¨æ„
>
>- ç”Ÿäº§ç¯å¢ƒä¸­çš„ TiDB å’Œ PD å¯ä»¥éƒ¨ç½²å’Œè¿è¡Œåœ¨åŒä¸€å°æœåŠ¡å™¨ä¸Šï¼Œå¦‚å¯¹æ€§èƒ½å’Œå¯é æ€§æœ‰æ›´é«˜çš„è¦æ±‚ï¼Œåº”å°½å¯èƒ½åˆ†å¼€éƒ¨ç½²ã€‚
>- å¼ºçƒˆå»ºè®®åˆ†åˆ«ä¸ºç”Ÿäº§ç¯å¢ƒä¸­çš„ TiDBã€TiKV å’Œ TiFlash é…ç½®è‡³å°‘ 8 æ ¸çš„ CPUã€‚å¼ºçƒˆæ¨èä½¿ç”¨æ›´é«˜çš„é…ç½®ï¼Œä»¥è·å¾—æ›´å¥½çš„æ€§èƒ½ã€‚
>- TiKV ç¡¬ç›˜å¤§å°é…ç½®å»ºè®® PCIe SSD ä¸è¶…è¿‡ 4 TBï¼Œæ™®é€š SSD ä¸è¶…è¿‡ 1.5 TBã€‚
>- å¦‚æœä½ åœ¨äº‘æœåŠ¡å•†ï¼ˆå¦‚ AWSã€Google Cloud æˆ– Azureï¼‰ä¸Šéƒ¨ç½² TiDB é›†ç¾¤ï¼Œå»ºè®® TiKV èŠ‚ç‚¹ä½¿ç”¨äº‘ç›˜ã€‚åœ¨äº‘ç¯å¢ƒä¸­ï¼ŒTiKV å®ä¾‹å´©æºƒæ—¶ï¼Œæœ¬åœ°ç£ç›˜ä¸Šçš„æ•°æ®å¯èƒ½ä¼šä¸¢å¤±ã€‚

##### æœ¬ç«™å®éªŒç¯å¢ƒé…ç½®

| **ç»„ä»¶** | **CPU** | **å†…å­˜** | **ç¡¬ç›˜ç±»å‹** | **ç½‘ç»œ**         | **å®ä¾‹æ•°é‡** |
| :------- | :------ | :------- | :----------- | :--------------- | :----------- |
| TiProxy  | 8 æ ¸    | 6 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |
| TiDB     | 8 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 3            |
| PD       | 4 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |
| TiKV     | 8 æ ¸    | 32 GB    | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 3            |
| ç›‘æ§     | 4 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |

- TiDB å’Œ TiKV æ¯”è¾ƒæ¶ˆè€— CPUã€‚

#### è®¾ç½® root ç”¨æˆ·ç»Ÿä¸€ç™»å½•

åœ¨å„ä¸ªå®ä¾‹ä¸­è®¾ç½® root ç»Ÿä¸€å¯†ç æˆ–è€…ç»Ÿä¸€çš„å…å¯†ç ç™»å½•ï¼Œå› ä¸ºç¨å tiup å‘½ä»¤ä½¿ç”¨ root ç”¨æˆ·ç™»å½•å„ä¸ªå®ä¾‹ã€‚

#### åœ¨ä¸­æ§æœºä¸Šéƒ¨ç½² TiUP ç»„ä»¶

åœ¨ä¸­æ§æœºä¸Šéƒ¨ç½² TiUP ç»„ä»¶æœ‰ä¸¤ç§æ–¹å¼ï¼šåœ¨çº¿éƒ¨ç½²å’Œç¦»çº¿éƒ¨ç½²ã€‚

##### åœ¨çº¿éƒ¨ç½²

ä»¥æ™®é€šç”¨æˆ·èº«ä»½ç™»å½•ä¸­æ§æœºã€‚ä»¥ `tidb` ç”¨æˆ·ä¸ºä¾‹ï¼Œåç»­å®‰è£… TiUP åŠé›†ç¾¤ç®¡ç†æ“ä½œå‡é€šè¿‡è¯¥ç”¨æˆ·å®Œæˆï¼š

1. æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤å®‰è£… TiUP å·¥å…·ï¼š

   ```bash
   curl --proto '=https' --tlsv1.2 -sSf https://tiup-mirrors.pingcap.com/install.sh | sh
   ```

2. æŒ‰å¦‚ä¸‹æ­¥éª¤è®¾ç½® TiUP ç¯å¢ƒå˜é‡ï¼š

   - é‡æ–°å£°æ˜å…¨å±€ç¯å¢ƒå˜é‡ï¼š

     ```bash
     source /root/.bashrc
     ```

   - ç¡®è®¤ TiUP å·¥å…·æ˜¯å¦å®‰è£…ï¼š

     ```bash
     which tiup
     ```

3. å®‰è£… TiUP é›†ç¾¤ç»„ä»¶ï¼š

   ```bash
   tiup cluster
   ```

4. å¦‚æœå·²ç»å®‰è£…ï¼Œåˆ™æ›´æ–° TiUP é›†ç¾¤ç»„ä»¶è‡³æœ€æ–°ç‰ˆæœ¬ï¼š

   ```bash
   tiup update --self && tiup update cluster
   ```

   é¢„æœŸè¾“å‡º `â€œUpdated successfully!â€` å­—æ ·ã€‚

5. éªŒè¯å½“å‰ TiUP é›†ç¾¤ç‰ˆæœ¬ä¿¡æ¯ã€‚æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æŸ¥çœ‹ TiUP é›†ç¾¤ç»„ä»¶ç‰ˆæœ¬ï¼š

   ```bash
   tiup --binary cluster
   ```

#### åˆå§‹åŒ–é›†ç¾¤æ‹“æ‰‘æ–‡ä»¶

æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤ï¼Œç”Ÿæˆé›†ç¾¤åˆå§‹åŒ–é…ç½®æ–‡ä»¶ï¼š

```bash
tiup cluster template > topology.yaml
```

é’ˆå¯¹ä¸¤ç§å¸¸ç”¨çš„éƒ¨ç½²åœºæ™¯ï¼Œä¹Ÿå¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤ç”Ÿæˆå»ºè®®çš„æ‹“æ‰‘æ¨¡æ¿ï¼š

- æ··åˆéƒ¨ç½²åœºæ™¯ï¼šå•å°æœºå™¨éƒ¨ç½²å¤šä¸ªå®ä¾‹ï¼Œè¯¦æƒ…å‚è§ [æ··åˆéƒ¨ç½²æ‹“æ‰‘æ¶æ„](https://docs.pingcap.com/zh/tidb/stable/hybrid-deployment-topology/)ã€‚

  ```sh
  tiup cluster template --full > topology.yaml
  ```

- è·¨æœºæˆ¿éƒ¨ç½²åœºæ™¯ï¼šè·¨æœºæˆ¿éƒ¨ç½² TiDB é›†ç¾¤ï¼Œè¯¦æƒ…å‚è§ [è·¨æœºæˆ¿éƒ¨ç½²æ‹“æ‰‘æ¶æ„](https://docs.pingcap.com/zh/tidb/stable/geo-distributed-deployment-topology/)ã€‚

  ```sh
  tiup cluster template --multi-dc > topology.yaml
  ```

æ ¹æ®æ³¨é‡Šç¼–è¾‘ topology.yaml ç›¸å…³å†…å®¹ï¼Œæœ¬ç«™å®éªŒç¯å¢ƒé…ç½®ç¤ºä¾‹ï¼š

```yaml
# # Global variables are applied to all deployments and used as the default value of
# # the deployments if a specific deployment value is missing.
global:
  # # The user who runs the tidb cluster.
  user: "tidb"
  # # group is used to specify the group name the user belong to if it's not the same as user.
  # group: "tidb"
  # # systemd_mode is used to select whether to use sudo permissions. When its value is set to user, there is no need to add global.user to sudoers. The default value is system.
  # systemd_mode: "system"
  # # SSH port of servers in the managed cluster.
  ssh_port: 22
  # # Storage directory for cluster deployment files, startup scripts, and configuration files.
  deploy_dir: "/tidb-deploy"
  # # TiDB Cluster data storage directory
  data_dir: "/tidb-data"
  # # default listen_host for all components
  listen_host: 0.0.0.0
  # # Supported values: "amd64", "arm64" (default: "amd64")
  arch: "amd64"
  # # Resource Control is used to limit the resource of an instance.
  # # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html
  # # Supports using instance-level `resource_control` to override global `resource_control`.
  # resource_control:
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#MemoryLimit=bytes
  #   memory_limit: "2G"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#CPUQuota=
  #   # The percentage specifies how much CPU time the unit shall get at maximum, relative to the total CPU time available on one CPU. Use values > 100% for allotting CPU time on more than one CPU.
  #   # Example: CPUQuota=200% ensures that the executed processes will never get more than two CPU time.
  #   cpu_quota: "200%"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#IOReadBandwidthMax=device%20bytes
  #   io_read_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"
  #   io_write_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"

server_configs:
  tidb:
    log.level: "error"
    # åˆ›å»ºå¸¦æœ‰ TiProxy çš„é›†ç¾¤æ—¶é¿å… TiDB server ä¸‹çº¿æ—¶å®¢æˆ·ç«¯è¿æ¥ä¸­æ–­
    # https://docs.pingcap.com/zh/tidb/stable/tiproxy-overview/#%E5%88%9B%E5%BB%BA%E5%B8%A6%E6%9C%89-tiproxy-%E7%9A%84%E9%9B%86%E7%BE%A4
    graceful-wait-before-shutdown: 15
  tikv:
    log-level: "error"
  pd:
    log-level: "error"

# # Monitored variables are applied to all the machines.
monitored:
  # # The communication port for reporting system information of each node in the TiDB cluster.
  node_exporter_port: 9100
  # # Blackbox_exporter communication port, used for TiDB cluster port monitoring.
  blackbox_exporter_port: 9115
  # # Storage directory for deployment files, startup scripts, and configuration files of monitoring components.
  # deploy_dir: "/tidb-deploy/monitored-9100"
  # # Data storage directory of monitoring components.
  # data_dir: "/tidb-data/monitored-9100"
  # # Log storage directory of the monitoring component.
  # log_dir: "/tidb-deploy/monitored-9100/log"

# # Server configs are used to specify the runtime configuration of TiDB components.
# # All configuration items can be found in TiDB docs:
# # - TiDB: https://docs.pingcap.com/tidb/stable/tidb-configuration-file
# # - TiKV: https://docs.pingcap.com/tidb/stable/tikv-configuration-file
# # - PD: https://docs.pingcap.com/tidb/stable/pd-configuration-file
# # - TiFlash: https://docs.pingcap.com/tidb/stable/tiflash-configuration
# #
# # All configuration items use points to represent the hierarchy, e.g:
# #   readpool.storage.use-unified-pool
# #           ^       ^
# # - example: https://github.com/pingcap/tiup/blob/master/examples/topology.example.yaml.
# # You can overwrite this configuration via the instance-level `config` field.
# server_configs:
  # tidb:
  # tikv:
  # pd:
  # tiflash:
  # tiflash-learner:
  #

tiproxy_servers:
  - host: 192.168.1.88
    deploy_dir: "/tiproxy-deploy"
    port: 6000
    status_port: 3080

# # Server configs are used to specify the configuration of PD Servers.
pd_servers:
  # # The ip address of the PD Server.
  - host: 192.168.1.92
    # # SSH port of the server.
    # ssh_port: 22
    # # PD Server name
    # name: "pd-1"
    # # communication port for TiDB Servers to connect.
    # client_port: 2379
    # # Communication port among PD Server nodes.
    # peer_port: 2380
    # # PD Server deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/pd-2379"
    # # PD Server data storage directory.
    # data_dir: "/tidb-data/pd-2379"
    # # PD Server log file storage directory.
    # log_dir: "/tidb-deploy/pd-2379/log"
    # # numa node bindings.
    # numa_node: "0,1"
    # # The following configs are used to overwrite the `server_configs.pd` values.
    # config:
    #   schedule.max-merge-region-size: 20
    #   schedule.max-merge-region-keys: 200000

# # Server configs are used to specify the configuration of TiDB Servers.
tidb_servers:
  # # The ip address of the TiDB Server.
  - host: 192.168.1.90
    # # SSH port of the server.
    # ssh_port: 22
    # # The port for clients to access the TiDB cluster.
    # port: 4000
    # # TiDB Server status API port.
    # status_port: 10080
    # # TiDB Server deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/tidb-4000"
    # # TiDB Server log file storage directory.
    # log_dir: "/tidb-deploy/tidb-4000/log"
  # # The ip address of the TiDB Server.
  - host: 192.168.1.91
    # ssh_port: 22
    # port: 4000
    # status_port: 10080
    # deploy_dir: "/tidb-deploy/tidb-4000"
    # log_dir: "/tidb-deploy/tidb-4000/log"
  # # The ip address of the TiDB Server.
  - host: 192.168.1.87
    # ssh_port: 22
    # port: 4000
    # status_port: 10080
    # deploy_dir: "/tidb-deploy/tidb-4000"
    # log_dir: "/tidb-deploy/tidb-4000/log"

# # Server configs are used to specify the configuration of TiKV Servers.
tikv_servers:
  # # The ip address of the TiKV Server.
  - host: 192.168.1.95
    # # SSH port of the server.
    # ssh_port: 22
    # # TiKV Server communication port.
    # port: 20160
    # # TiKV Server status API port.
    # status_port: 20180
    # # TiKV Server deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/tikv-20160"
    # # TiKV Server data storage directory.
    # data_dir: "/tidb-data/tikv-20160"
    # # TiKV Server log file storage directory.
    # log_dir: "/tidb-deploy/tikv-20160/log"
    # # The following configs are used to overwrite the `server_configs.tikv` values.
    # config:
    #   log.level: warn
  # # The ip address of the TiKV Server.
  - host: 192.168.1.96
    # ssh_port: 22
    # port: 20160
    # status_port: 20180
    # deploy_dir: "/tidb-deploy/tikv-20160"
    # data_dir: "/tidb-data/tikv-20160"
    # log_dir: "/tidb-deploy/tikv-20160/log"
    # config:
    #   log.level: warn
  - host: 192.168.1.97
    # ssh_port: 22
    # port: 20160
    # status_port: 20180
    # deploy_dir: "/tidb-deploy/tikv-20160"
    # data_dir: "/tidb-data/tikv-20160"
    # log_dir: "/tidb-deploy/tikv-20160/log"
    # config:
    #   log.level: warn

# # Server configs are used to specify the configuration of Prometheus Server.  
monitoring_servers:
  # # The ip address of the Monitoring Server.
  - host: 192.168.1.98
    # # SSH port of the server.
    # ssh_port: 22
    # # Prometheus Service communication port.
    # port: 9090
    # # ng-monitoring servive communication port
    # ng_port: 12020
    # # Prometheus deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/prometheus-8249"
    # # Prometheus data storage directory.
    # data_dir: "/tidb-data/prometheus-8249"
    # # Prometheus log file storage directory.
    # log_dir: "/tidb-deploy/prometheus-8249/log"

# # Server configs are used to specify the configuration of Grafana Servers.  
grafana_servers:
  # # The ip address of the Grafana Server.
  - host: 192.168.1.98
    # # Grafana web port (browser access)
    # port: 3000
    # # Grafana deployment file, startup script, configuration file storage directory.
    # deploy_dir: /tidb-deploy/grafana-3000

# # Server configs are used to specify the configuration of Alertmanager Servers.  
alertmanager_servers:
  # # The ip address of the Alertmanager Server.
  - host: 192.168.1.98
    # # SSH port of the server.
    # ssh_port: 22
    # # Alertmanager web service port.
    # web_port: 9093
    # # Alertmanager communication port.
    # cluster_port: 9094
    # # Alertmanager deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/alertmanager-9093"
    # # Alertmanager data storage directory.
    # data_dir: "/tidb-data/alertmanager-9093"
    # # Alertmanager log file storage directory.
    # log_dir: "/tidb-deploy/alertmanager-9093/log"

```

æ›´å¤šå‚æ•°è¯´æ˜ï¼Œè¯·å‚è€ƒï¼š

- [TiDB `config.toml.example`](https://github.com/pingcap/tidb/blob/release-8.5/pkg/config/config.toml.example)
- [TiKV `config.toml.example`](https://github.com/tikv/tikv/blob/release-8.5/etc/config-template.toml)
- [PD `config.toml.example`](https://github.com/tikv/pd/blob/release-8.5/conf/config.toml)
- [TiFlash `config.toml.example`](https://github.com/pingcap/tiflash/blob/release-8.5/etc/config-template.toml)

#### æ‰§è¡Œéƒ¨ç½²å‘½ä»¤

>æ³¨æ„
>
>é€šè¿‡ TiUP éƒ¨ç½²é›†ç¾¤æ—¶ç”¨äºåˆå§‹åŒ–çš„ç”¨æˆ·ï¼ˆé€šè¿‡ `--user` æŒ‡å®šï¼‰ï¼Œå¯ä»¥ä½¿ç”¨å¯†é’¥æˆ–è€…äº¤äº’å¯†ç çš„æ–¹å¼è¿›è¡Œå®‰å…¨è®¤è¯ï¼š
>
>- å¦‚æœä½¿ç”¨å¯†é’¥æ–¹å¼ï¼Œå¯ä»¥é€šè¿‡ `-i` æˆ–è€… `--identity_file` æŒ‡å®šå¯†é’¥çš„è·¯å¾„ã€‚
>- å¦‚æœä½¿ç”¨å¯†ç æ–¹å¼ï¼Œå¯ä»¥é€šè¿‡ `-p` è¿›å…¥å¯†ç äº¤äº’çª—å£ã€‚
>- å¦‚æœå·²ç»é…ç½®å…å¯†ç™»å½•ç›®æ ‡æœºï¼Œåˆ™ä¸éœ€å¡«å†™è®¤è¯ã€‚
>
>TiUP ç”¨äºå®é™…æ‰§è¡Œç›¸å…³è¿›ç¨‹çš„ç”¨æˆ·å’Œç»„ï¼ˆé€šè¿‡ `topology.yaml` æŒ‡å®šï¼Œé»˜è®¤å€¼ä¸º `tidb`ï¼‰ï¼Œä¸€èˆ¬æƒ…å†µä¸‹ä¼šåœ¨ç›®æ ‡æœºå™¨ä¸Šè‡ªåŠ¨åˆ›å»ºï¼Œä½†ä»¥ä¸‹æƒ…å†µä¾‹å¤–ï¼š
>
>- `topology.yaml` ä¸­è®¾ç½®çš„ç”¨æˆ·ååœ¨ç›®æ ‡æœºå™¨ä¸Šå·²å­˜åœ¨ã€‚
>- åœ¨å‘½ä»¤è¡Œä¸Šä½¿ç”¨äº†å‚æ•° `--skip-create-user` æ˜ç¡®æŒ‡å®šè·³è¿‡åˆ›å»ºç”¨æˆ·çš„æ­¥éª¤ã€‚
>
>æ— è®º `topology.yaml` ä¸­çº¦å®šçš„ç”¨æˆ·å’Œç»„æ˜¯å¦è¢«è‡ªåŠ¨åˆ›å»ºï¼ŒTiUP éƒ½ä¼šè‡ªåŠ¨ç”Ÿæˆä¸€å¯¹ ssh keyï¼Œå¹¶ä¸ºæ¯å°æœºå™¨çš„è¯¥ç”¨æˆ·è®¾ç½®å…å¯†ç™»å½•ã€‚åœ¨æ­¤åçš„æ“ä½œä¸­éƒ½ä¼šä½¿ç”¨è¿™ä¸ªç”¨æˆ·å’Œ ssh key å»ç®¡ç†æœºå™¨ï¼Œè€Œç”¨äºåˆå§‹åŒ–çš„ç”¨æˆ·å’Œå¯†ç åœ¨éƒ¨å±å®Œæˆåä¸å†è¢«ä½¿ç”¨ã€‚

æ‰§è¡Œéƒ¨ç½²å‘½ä»¤å‰ï¼Œå…ˆä½¿ç”¨ `check` åŠ `check --apply` å‘½ä»¤æ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

1. æ£€æŸ¥é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

   ```bash
   tiup cluster check ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

2. è‡ªåŠ¨ä¿®å¤é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

   ```bash
   tiup cluster check ./topology.yaml --apply --user root [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

   ä¸èƒ½è‡ªåŠ¨ä¿®å¤é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©è¯·å‚è€ƒä»¥ä¸‹ï¼š

   - `numactl not usable, bash: numactl: command not found`

     ```bash
     sudo apt install numactl
     ```

   - `THP is enabled, please disable it for best performance`

     é€šè¿‡`systemd`æœåŠ¡ã€‚

     åˆ›å»ºæœåŠ¡æ–‡ä»¶ï¼š

     ```bash
     sudo vim /etc/systemd/system/disable-thp.service
     ```

     æ·»åŠ ä»¥ä¸‹å†…å®¹ï¼š

     ```properties
     [Unit]
     Description=Disable Transparent Huge Pages (THP)
     
     [Service]
     Type=simple
     ExecStart=/bin/sh -c "echo 'never' > /sys/kernel/mm/transparent_hugepage/enabled && echo 'never' > /sys/kernel/mm/transparent_hugepage/defrag"
     
     [Install]
     WantedBy=multi-user.target
     ```

     ä¿å­˜æ–‡ä»¶åï¼Œé‡æ–°åŠ è½½`systemd`å®ˆæŠ¤è¿›ç¨‹å¹¶å¯ç”¨æœåŠ¡ï¼š

     ```bash
     sudo systemctl daemon-reload
     sudo systemctl enable disable-thp.service
     sudo systemctl start disable-thp.service
     ```

     éªŒè¯ THP çŠ¶æ€

     ```bash
     cat /sys/kernel/mm/transparent_hugepage/enabled
     cat /sys/kernel/mm/transparent_hugepage/defrag
     ```

     - ç¡®ä¿è¾“å‡ºä¸º`[never]`ï¼Œè¡¨ç¤ºTHPå·²æˆåŠŸç¦ç”¨ã€‚

   - `mount point / does not have 'nodelalloc' option set`

     è¦æ°¸ä¹…ç¦ç”¨å»¶è¿Ÿåˆ†é…ï¼Œéœ€è¦ç¼–è¾‘ `/etc/fstab` æ–‡ä»¶ï¼Œä¿®æ”¹æ ¹æ–‡ä»¶ç³»ç»Ÿçš„æŒ‚è½½é€‰é¡¹ã€‚

     ```bash
     sudo vim /etc/fstab
     ```

     æ‰¾åˆ°æ ¹æ–‡ä»¶ç³»ç»Ÿçš„è¡Œï¼Œå¹¶æ·»åŠ  `nodelalloc` é€‰é¡¹ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæ‚¨çš„æŒ‚è½½è¡Œå¦‚ä¸‹ï¼š

     ```
     UUID=1234-5678 / ext4 defaults 0 1
     ```

     ä¿®æ”¹ä¸ºï¼š

     ```plaintext
     UUID=1234-5678 / ext4 defaults,nodelalloc 0 1
     ```

     é‡å¯æ“ä½œç³»ç»Ÿã€‚

     

3. éƒ¨ç½² TiDB é›†ç¾¤ï¼š

   ```bash
   tiup cluster deploy tidb-test v8.5.1 ./topology.yaml --user root [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

ä»¥ä¸Šéƒ¨ç½²ç¤ºä¾‹ä¸­ï¼š

- `tidb-test` ä¸ºéƒ¨ç½²çš„é›†ç¾¤åç§°ã€‚
- `v8.5.1` ä¸ºéƒ¨ç½²çš„é›†ç¾¤ç‰ˆæœ¬ï¼Œå¯ä»¥é€šè¿‡æ‰§è¡Œ `tiup list tidb` æ¥æŸ¥çœ‹ TiUP æ”¯æŒçš„æœ€æ–°å¯ç”¨ç‰ˆæœ¬ã€‚
- åˆå§‹åŒ–é…ç½®æ–‡ä»¶ä¸º `topology.yaml`ã€‚
- `--user root` è¡¨ç¤ºé€šè¿‡ root ç”¨æˆ·ç™»å½•åˆ°ç›®æ ‡ä¸»æœºå®Œæˆé›†ç¾¤éƒ¨ç½²ï¼Œè¯¥ç”¨æˆ·éœ€è¦æœ‰ ssh åˆ°ç›®æ ‡æœºå™¨çš„æƒé™ï¼Œå¹¶ä¸”åœ¨ç›®æ ‡æœºå™¨æœ‰ sudo æƒé™ã€‚ä¹Ÿå¯ä»¥ç”¨å…¶ä»–æœ‰ ssh å’Œ sudo æƒé™çš„ç”¨æˆ·å®Œæˆéƒ¨ç½²ã€‚
- [-i] åŠ [-p] ä¸ºå¯é€‰é¡¹ï¼Œå¦‚æœå·²ç»é…ç½®å…å¯†ç™»å½•ç›®æ ‡æœºï¼Œåˆ™ä¸éœ€å¡«å†™ã€‚å¦åˆ™é€‰æ‹©å…¶ä¸€å³å¯ï¼Œ[-i] ä¸ºå¯ç™»å½•åˆ°ç›®æ ‡æœºçš„ root ç”¨æˆ·ï¼ˆæˆ– `--user` æŒ‡å®šçš„å…¶ä»–ç”¨æˆ·ï¼‰çš„ç§é’¥ï¼Œä¹Ÿå¯ä½¿ç”¨ [-p] äº¤äº’å¼è¾“å…¥è¯¥ç”¨æˆ·çš„å¯†ç ã€‚

é¢„æœŸæ—¥å¿—ç»“å°¾è¾“å‡º `Deployed cluster `tidb-test` successfully` å…³é”®è¯ï¼Œè¡¨ç¤ºéƒ¨ç½²æˆåŠŸã€‚

#### æŸ¥çœ‹ TiUP ç®¡ç†çš„é›†ç¾¤æƒ…å†µ

```bash
tiup cluster list
```

TiUP æ”¯æŒç®¡ç†å¤šä¸ª TiDB é›†ç¾¤ï¼Œè¯¥å‘½ä»¤ä¼šè¾“å‡ºå½“å‰é€šè¿‡ TiUP cluster ç®¡ç†çš„æ‰€æœ‰é›†ç¾¤ä¿¡æ¯ï¼ŒåŒ…æ‹¬é›†ç¾¤åç§°ã€éƒ¨ç½²ç”¨æˆ·ã€ç‰ˆæœ¬ã€å¯†é’¥ä¿¡æ¯ç­‰ã€‚

#### æ£€æŸ¥éƒ¨ç½²çš„ TiDB é›†ç¾¤æƒ…å†µ

ä¾‹å¦‚ï¼Œæ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ£€æŸ¥ `tidb-test` é›†ç¾¤æƒ…å†µï¼š

```bash
tiup cluster display tidb-test
```

é¢„æœŸè¾“å‡ºåŒ…æ‹¬ `tidb-test` é›†ç¾¤ä¸­å®ä¾‹ IDã€è§’è‰²ã€ä¸»æœºã€ç›‘å¬ç«¯å£å’ŒçŠ¶æ€ï¼ˆç”±äºè¿˜æœªå¯åŠ¨ï¼Œæ‰€ä»¥çŠ¶æ€ä¸º Down/inactiveï¼‰ã€ç›®å½•ä¿¡æ¯ã€‚

#### å¯åŠ¨é›†ç¾¤

å®‰å…¨å¯åŠ¨æ˜¯ TiUP cluster ä» v1.9.0 èµ·å¼•å…¥çš„ä¸€ç§æ–°çš„å¯åŠ¨æ–¹å¼ï¼Œé‡‡ç”¨è¯¥æ–¹å¼å¯åŠ¨æ•°æ®åº“å¯ä»¥æé«˜æ•°æ®åº“å®‰å…¨æ€§ã€‚æ¨èä½¿ç”¨å®‰å…¨å¯åŠ¨ã€‚

å®‰å…¨å¯åŠ¨åï¼ŒTiUP ä¼šè‡ªåŠ¨ç”Ÿæˆ TiDB root ç”¨æˆ·çš„å¯†ç ï¼Œå¹¶åœ¨å‘½ä»¤è¡Œç•Œé¢è¿”å›å¯†ç ã€‚

>æ³¨æ„
>
>- ä½¿ç”¨å®‰å…¨å¯åŠ¨æ–¹å¼åï¼Œä¸èƒ½é€šè¿‡æ— å¯†ç çš„ root ç”¨æˆ·ç™»å½•æ•°æ®åº“ï¼Œä½ éœ€è¦è®°å½•å‘½ä»¤è¡Œè¿”å›çš„å¯†ç è¿›è¡Œåç»­æ“ä½œã€‚
>- è¯¥è‡ªåŠ¨ç”Ÿæˆçš„å¯†ç åªä¼šè¿”å›ä¸€æ¬¡ï¼Œå¦‚æœæ²¡æœ‰è®°å½•æˆ–è€…å¿˜è®°è¯¥å¯†ç ï¼Œè¯·å‚ç…§[å¿˜è®° root å¯†ç ](https://docs.pingcap.com/zh/tidb/stable/user-account-management/#å¿˜è®°-root-å¯†ç )ä¿®æ”¹å¯†ç ã€‚

##### å®‰å…¨å¯åŠ¨

```bash
tiup cluster start tidb-test --init
```

é¢„æœŸç»“æœå¦‚ä¸‹ï¼Œè¡¨ç¤ºå¯åŠ¨æˆåŠŸã€‚

```bash
Started cluster `tidb-test` successfully.
The root password of TiDB database has been changed.
The new password is: 'y_+3Hwp=*AWz8971s6'.
Copy and record it to somewhere safe, it is only displayed once, and will not be stored.
The generated password can NOT be got again in future.
```

##### æ™®é€šå¯åŠ¨

```bash
tiup cluster start tidb-test
```

é¢„æœŸç»“æœè¾“å‡º `Started cluster `tidb-test` successfully`ï¼Œè¡¨ç¤ºå¯åŠ¨æˆåŠŸã€‚ä½¿ç”¨æ™®é€šå¯åŠ¨æ–¹å¼åï¼Œå¯é€šè¿‡æ— å¯†ç çš„ root ç”¨æˆ·ç™»å½•æ•°æ®åº“ã€‚

å‚è€ƒæœ¬ç«™ <a href="/tidb/README.html#ä¿®æ”¹-root-å¯†ç " target="_blank">é“¾æ¥</a> ä¿®æ”¹ root å¯†ç ã€‚

#### éªŒè¯é›†ç¾¤è¿è¡ŒçŠ¶æ€

```bash
tiup cluster display tidb-test
```

é¢„æœŸç»“æœè¾“å‡ºï¼šå„èŠ‚ç‚¹ Status çŠ¶æ€ä¿¡æ¯ä¸º `Up` è¯´æ˜é›†ç¾¤çŠ¶æ€æ­£å¸¸ã€‚

è®¿é—® Grafana ç›‘æ§é¡µé¢ï¼š[http://{grafana-ip}:3000](http://{grafana-ip}:3000/)ï¼Œé»˜è®¤ç”¨æˆ·åå’Œå¯†ç å‡ä¸º `admin`ã€‚

è®¿é—®é›†ç¾¤ [TiDB Dashboard](https://docs.pingcap.com/zh/tidb/stable/dashboard-intro/) ç›‘æ§é¡µé¢ï¼šhttp://{pd-ip}:2379/dashboardï¼Œé»˜è®¤ç”¨æˆ·åä¸º `root`ï¼Œå¯†ç ä¸ºä¿®æ”¹åçš„ root å¯†ç ã€‚



## ä¼˜åŒ–



### TiDB é…ç½®

å‡é«˜æ—¥å¿—çº§åˆ«ï¼Œå¯ä»¥å‡å°‘æ‰“å°æ—¥å¿—æ•°é‡ï¼Œå¯¹ TiDB çš„æ€§èƒ½æœ‰ç§¯æå½±å“ã€‚å…·ä½“åœ¨ TiUP é…ç½®æ–‡ä»¶ï¼ˆtopology.yaml æ–‡ä»¶ï¼‰ä¸­åŠ å…¥ï¼š

```yaml
server_configs:
  tidb:
    log.level: "error"
```

å‚è€ƒæœ¬ç«™ <a href="/tidb/README.html#ä¿®æ”¹é…ç½®å‚æ•°" target="_blank">é“¾æ¥</a> ä¿®æ”¹é…ç½®ã€‚



## åœ¨çº¿ä¿®æ”¹é›†ç¾¤é…ç½®

>[å‚è€ƒå®˜æ–¹æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/dynamic-config/#%E5%9C%A8%E7%BA%BF%E4%BF%AE%E6%94%B9%E9%9B%86%E7%BE%A4%E9%85%8D%E7%BD%AE)

åœ¨çº¿é…ç½®å˜æ›´ä¸»è¦æ˜¯é€šè¿‡åˆ©ç”¨ SQL å¯¹åŒ…æ‹¬ TiDBã€TiKV ä»¥åŠ PD åœ¨å†…çš„å„ç»„ä»¶çš„é…ç½®è¿›è¡Œåœ¨çº¿æ›´æ–°ã€‚ç”¨æˆ·å¯ä»¥é€šè¿‡åœ¨çº¿é…ç½®å˜æ›´å¯¹å„ç»„ä»¶è¿›è¡Œæ€§èƒ½è°ƒä¼˜è€Œæ— éœ€é‡å¯é›†ç¾¤ç»„ä»¶ã€‚ä½†ç›®å‰åœ¨çº¿ä¿®æ”¹ TiDB å®ä¾‹é…ç½®çš„æ–¹å¼å’Œä¿®æ”¹å…¶ä»–ç»„ä»¶ (TiKV, PD) çš„æœ‰æ‰€ä¸åŒã€‚



### æŸ¥çœ‹å®ä¾‹é…ç½®

å¯ä»¥é€šè¿‡ SQL è¯­å¥ `show config` æ¥ç›´æ¥æŸ¥çœ‹é›†ç¾¤æ‰€æœ‰å®ä¾‹çš„é…ç½®ä¿¡æ¯ï¼Œç»“æœå¦‚ä¸‹ï¼š

```sql
show config;
```

è¿˜å¯ä»¥æ ¹æ®å¯¹åº”çš„å­—æ®µè¿›è¡Œè¿‡æ»¤ï¼Œå¦‚ï¼š

```sql
show config where type='tidb'
show config where instance in (...)
show config where name like '%log%'
show config where type='tikv' and name='log.level'
```



### åœ¨çº¿ä¿®æ”¹ TiKV é…ç½®

>æ³¨æ„ï¼šåœ¨çº¿ä¿®æ”¹ TiKV é…ç½®é¡¹åï¼ŒåŒæ—¶ä¼šè‡ªåŠ¨ä¿®æ”¹ TiKV çš„é…ç½®æ–‡ä»¶ã€‚ä½†è¿˜éœ€è¦ä½¿ç”¨ `tiup edit-config` å‘½ä»¤æ¥ä¿®æ”¹å¯¹åº”çš„é…ç½®é¡¹ï¼Œå¦åˆ™ `upgrade` å’Œ `reload` ç­‰è¿ç»´æ“ä½œä¼šå°†åœ¨çº¿ä¿®æ”¹é…ç½®åçš„ç»“æœè¦†ç›–ã€‚ä¿®æ”¹é…ç½®çš„æ“ä½œè¯·å‚è€ƒï¼š[ä½¿ç”¨ TiUP ä¿®æ”¹é…ç½®](https://docs.pingcap.com/zh/tidb/stable/maintain-tidb-using-tiup/#ä¿®æ”¹é…ç½®å‚æ•°)ã€‚æ‰§è¡Œ `tiup edit-config` åä¸éœ€è¦æ‰§è¡Œ `tiup reload` æ“ä½œã€‚

æ‰§è¡Œ SQL è¯­å¥ `set config`ï¼Œå¯ä»¥ç»“åˆå®ä¾‹åœ°å€æˆ–ç»„ä»¶ç±»å‹æ¥ä¿®æ”¹å•ä¸ªå®ä¾‹é…ç½®æˆ–å…¨éƒ¨å®ä¾‹é…ç½®ï¼Œå¦‚ï¼š

- ä¿®æ”¹å…¨éƒ¨ TiKV å®ä¾‹é…ç½®ï¼š

  >æ³¨æ„ï¼šå»ºè®®ä½¿ç”¨åå¼•å·åŒ…è£¹å˜é‡åç§°ã€‚

  ```sql
  set config tikv `split.qps-threshold`=1000
  ```

- ä¿®æ”¹å•ä¸ª TiKV å®ä¾‹é…ç½®ï¼š

  ```sql
  set config "127.0.0.1:20180" `split.qps-threshold`=1000
  ```

è®¾ç½®æˆåŠŸä¼šè¿”å› `Query OK`ï¼š

```sql
Query OK, 0 rows affected (0.01 sec)
```

åœ¨æ‰¹é‡ä¿®æ”¹æ—¶å¦‚æœæœ‰é”™è¯¯å‘ç”Ÿï¼Œä¼šä»¥ warning çš„å½¢å¼è¿”å›ï¼š

```sql
set config tikv `log-level`='warn';
```

```sql
Query OK, 0 rows affected, 1 warning (0.04 sec)
```

```sql
show warnings;
```

```sql
+---------+------+---------------------------------------------------------------------------------------------------------------+
| Level   | Code | Message                                                                                                       |
+---------+------+---------------------------------------------------------------------------------------------------------------+
| Warning | 1105 | bad request to http://127.0.0.1:20180/config: fail to update, error: "config log-level can not be changed" |
+---------+------+---------------------------------------------------------------------------------------------------------------+
1 row in set (0.00 sec)
```

æ‰¹é‡ä¿®æ”¹é…ç½®ä¸ä¿è¯åŸå­æ€§ï¼Œå¯èƒ½å‡ºç°æŸäº›å®ä¾‹æˆåŠŸï¼Œè€ŒæŸäº›å¤±è´¥çš„æƒ…å†µã€‚å¦‚ä½¿ç”¨ `set tikv key=val` å‘½ä»¤ä¿®æ”¹æ•´ä¸ª TiKV é›†ç¾¤é…ç½®æ—¶ï¼Œå¯èƒ½æœ‰éƒ¨åˆ†å®ä¾‹å¤±è´¥ï¼Œè¯·æ‰§è¡Œ `show warnings` è¿›è¡ŒæŸ¥çœ‹ã€‚

å¦‚é‡åˆ°éƒ¨åˆ†ä¿®æ”¹å¤±è´¥çš„æƒ…å†µï¼Œéœ€è¦é‡æ–°æ‰§è¡Œå¯¹åº”çš„ä¿®æ”¹è¯­å¥ï¼Œæˆ–é€šè¿‡ä¿®æ”¹å•ä¸ªå®ä¾‹çš„æ–¹å¼å®Œæˆä¿®æ”¹ã€‚å¦‚æœå› ç½‘ç»œæˆ–è€…æœºå™¨æ•…éšœç­‰åŸå› æ— æ³•è®¿é—®åˆ°çš„ TiKVï¼Œéœ€è¦ç­‰åˆ°æ¢å¤åå†æ¬¡è¿›è¡Œä¿®æ”¹ã€‚

é’ˆå¯¹ TiKV å¯åœ¨çº¿ä¿®æ”¹çš„é…ç½®é¡¹ï¼Œå¦‚æœæˆåŠŸä¿®æ”¹åï¼Œä¿®æ”¹çš„ç»“æœä¼šè¢«æŒä¹…åŒ–åˆ°é…ç½®æ–‡ä»¶ä¸­ï¼Œåç»­ä»¥é…ç½®æ–‡ä»¶ä¸­çš„é…ç½®ä¸ºå‡†ã€‚æŸäº›é…ç½®é¡¹åç§°å¯èƒ½å’Œ TiDB é¢„ç•™å…³é”®å­—å†²çªï¼Œå¦‚ `limit`ã€`key` ç­‰ï¼Œå¯¹äºæ­¤ç±»é…ç½®é¡¹ï¼Œéœ€è¦ç”¨åå¼•å· ``` åŒ…è£¹èµ·æ¥ï¼Œå¦‚ ``raftstore.raft-log-gc-size-limit``ã€‚

æ”¯æŒçš„é…ç½®é¡¹åˆ—è¡¨å¦‚ä¸‹ï¼š

| é…ç½®é¡¹                                                   | ç®€ä»‹                                                         |
| :------------------------------------------------------- | :----------------------------------------------------------- |
| log.level                                                | æ—¥å¿—ç­‰çº§                                                     |
| raftstore.raft-max-inflight-msgs                         | å¾…ç¡®è®¤çš„æ—¥å¿—ä¸ªæ•°ï¼Œå¦‚æœè¶…è¿‡è¿™ä¸ªæ•°é‡ï¼ŒRaft çŠ¶æ€æœºä¼šå‡ç¼“å‘é€æ—¥å¿—çš„é€Ÿåº¦ |
| raftstore.raft-log-gc-tick-interval                      | åˆ é™¤ Raft æ—¥å¿—çš„è½®è¯¢ä»»åŠ¡è°ƒåº¦é—´éš”æ—¶é—´                         |
| raftstore.raft-log-gc-threshold                          | å…è®¸æ®‹ä½™çš„ Raft æ—¥å¿—ä¸ªæ•°ï¼Œè½¯é™åˆ¶                             |
| raftstore.raft-log-gc-count-limit                        | å…è®¸æ®‹ä½™çš„ Raft æ—¥å¿—ä¸ªæ•°ï¼Œç¡¬é™åˆ¶                             |
| raftstore.raft-log-gc-size-limit                         | å…è®¸æ®‹ä½™çš„ Raft æ—¥å¿—å¤§å°ï¼Œç¡¬é™åˆ¶                             |
| raftstore.raft-max-size-per-msg                          | å…è®¸ç”Ÿæˆçš„å•ä¸ªæ¶ˆæ¯åŒ…çš„å¤§å°ï¼Œè½¯é™åˆ¶                           |
| raftstore.raft-entry-max-size                            | å•ä¸ª Raft æ—¥å¿—æœ€å¤§å¤§å°ï¼Œç¡¬é™åˆ¶                               |
| raftstore.raft-entry-cache-life-time                     | å†…å­˜ä¸­æ—¥å¿— cache å…è®¸çš„æœ€é•¿æ®‹ç•™æ—¶é—´                          |
| raftstore.max-apply-unpersisted-log-limit                | å…è®¸ apply å·² commit ä½†å°šæœªæŒä¹…åŒ–çš„ Raft æ—¥å¿—çš„æœ€å¤§æ•°é‡      |
| raftstore.split-region-check-tick-interval               | æ£€æŸ¥ Region æ˜¯å¦éœ€è¦åˆ†è£‚çš„æ—¶é—´é—´éš”                           |
| raftstore.region-split-check-diff                        | å…è®¸ Region æ•°æ®è¶…è¿‡æŒ‡å®šå¤§å°çš„æœ€å¤§å€¼                         |
| raftstore.region-compact-check-interval                  | æ£€æŸ¥æ˜¯å¦éœ€è¦äººå·¥è§¦å‘ RocksDB compaction çš„æ—¶é—´é—´éš”           |
| raftstore.region-compact-check-step                      | æ¯è½®æ ¡éªŒäººå·¥ compaction æ—¶ï¼Œä¸€æ¬¡æ€§æ£€æŸ¥çš„ Region ä¸ªæ•°         |
| raftstore.region-compact-min-tombstones                  | è§¦å‘ RocksDB compaction éœ€è¦çš„ tombstone ä¸ªæ•°                |
| raftstore.region-compact-tombstones-percent              | è§¦å‘ RocksDB compaction éœ€è¦çš„ tombstone æ‰€å æ¯”ä¾‹            |
| raftstore.pd-heartbeat-tick-interval                     | è§¦å‘ Region å¯¹ PD å¿ƒè·³çš„æ—¶é—´é—´éš”                             |
| raftstore.pd-store-heartbeat-tick-interval               | è§¦å‘ store å¯¹ PD å¿ƒè·³çš„æ—¶é—´é—´éš”                              |
| raftstore.snap-mgr-gc-tick-interval                      | è§¦å‘å›æ”¶è¿‡æœŸ snapshot æ–‡ä»¶çš„æ—¶é—´é—´éš”                         |
| raftstore.snap-gc-timeout                                | snapshot æ–‡ä»¶çš„æœ€é•¿ä¿å­˜æ—¶é—´                                  |
| raftstore.lock-cf-compact-interval                       | è§¦å‘å¯¹ lock CF compact æ£€æŸ¥çš„æ—¶é—´é—´éš”                        |
| raftstore.lock-cf-compact-bytes-threshold                | è§¦å‘å¯¹ lock CF è¿›è¡Œ compact çš„å¤§å°                           |
| raftstore.messages-per-tick                              | æ¯è½®å¤„ç†çš„æ¶ˆæ¯æœ€å¤§ä¸ªæ•°                                       |
| raftstore.max-peer-down-duration                         | å‰¯æœ¬å…è®¸çš„æœ€é•¿æœªå“åº”æ—¶é—´                                     |
| raftstore.max-leader-missing-duration                    | å…è®¸å‰¯æœ¬å¤„äºæ— ä¸»çŠ¶æ€çš„æœ€é•¿æ—¶é—´ï¼Œè¶…è¿‡å°†ä¼šå‘ PD æ ¡éªŒè‡ªå·±æ˜¯å¦å·²ç»è¢«åˆ é™¤ |
| raftstore.abnormal-leader-missing-duration               | å…è®¸å‰¯æœ¬å¤„äºæ— ä¸»çŠ¶æ€çš„æ—¶é—´ï¼Œè¶…è¿‡å°†è§†ä¸ºå¼‚å¸¸ï¼Œæ ‡è®°åœ¨ metrics å’Œæ—¥å¿—ä¸­ |
| raftstore.peer-stale-state-check-interval                | è§¦å‘æ£€éªŒå‰¯æœ¬æ˜¯å¦å¤„äºæ— ä¸»çŠ¶æ€çš„æ—¶é—´é—´éš”                       |
| raftstore.consistency-check-interval                     | è§¦å‘ä¸€è‡´æ€§æ£€æŸ¥çš„æ—¶é—´é—´éš”ï¼ˆä¸å»ºè®®ä½¿ç”¨è¯¥é…ç½®é¡¹ï¼Œå› ä¸ºä¸ TiDB GC æ“ä½œä¸å…¼å®¹ï¼‰ |
| raftstore.raft-store-max-leader-lease                    | Region ä¸»å¯ä¿¡ä»»æœŸçš„æœ€é•¿æ—¶é—´                                  |
| raftstore.merge-check-tick-interval                      | è§¦å‘ Merge å®Œæˆæ£€æŸ¥çš„æ—¶é—´é—´éš”                                |
| raftstore.cleanup-import-sst-interval                    | è§¦å‘æ£€æŸ¥è¿‡æœŸ SST æ–‡ä»¶çš„æ—¶é—´é—´éš”                              |
| raftstore.local-read-batch-size                          | ä¸€è½®å¤„ç†è¯»è¯·æ±‚çš„æœ€å¤§ä¸ªæ•°                                     |
| raftstore.apply-yield-write-size                         | Apply çº¿ç¨‹æ¯ä¸€è½®å¤„ç†å•ä¸ªçŠ¶æ€æœºå†™å…¥çš„æœ€å¤§æ•°æ®é‡               |
| raftstore.hibernate-timeout                              | å¯åŠ¨åè¿›å…¥é™é»˜çŠ¶æ€å‰éœ€è¦ç­‰å¾…çš„æœ€çŸ­æ—¶é—´ï¼Œåœ¨è¯¥æ—¶é—´æ®µå†…ä¸ä¼šè¿›å…¥é™é»˜çŠ¶æ€ï¼ˆæœª releaseï¼‰ |
| raftstore.apply-pool-size                                | å¤„ç†æŠŠæ•°æ®è½ç›˜è‡³ç£ç›˜çš„çº¿ç¨‹æ± ä¸­çº¿ç¨‹çš„æ•°é‡ï¼Œå³ Apply çº¿ç¨‹æ± å¤§å° |
| raftstore.store-pool-size                                | å¤„ç† Raft çš„çº¿ç¨‹æ± ä¸­çº¿ç¨‹çš„æ•°é‡ï¼Œå³ Raftstore çº¿ç¨‹æ± çš„å¤§å°    |
| raftstore.apply-max-batch-size                           | Raft çŠ¶æ€æœºç”± BatchSystem æ‰¹é‡æ‰§è¡Œæ•°æ®å†™å…¥è¯·æ±‚ï¼Œè¯¥é…ç½®é¡¹æŒ‡å®šæ¯æ‰¹å¯æ‰§è¡Œè¯·æ±‚çš„æœ€å¤š Raft çŠ¶æ€æœºä¸ªæ•°ã€‚ |
| raftstore.store-max-batch-size                           | Raft çŠ¶æ€æœºç”± BatchSystem æ‰¹é‡æ‰§è¡ŒæŠŠæ—¥å¿—è½ç›˜è‡³ç£ç›˜çš„è¯·æ±‚ï¼Œè¯¥é…ç½®é¡¹æŒ‡å®šæ¯æ‰¹å¯æ‰§è¡Œè¯·æ±‚çš„æœ€å¤š Raft çŠ¶æ€æœºä¸ªæ•°ã€‚ |
| raftstore.store-io-pool-size                             | å¤„ç† Raft I/O ä»»åŠ¡çš„çº¿ç¨‹æ± ä¸­çº¿ç¨‹çš„æ•°é‡ï¼Œå³ StoreWriter çº¿ç¨‹æ± çš„å¤§å°ï¼ˆä¸æ”¯æŒå°†è¯¥é…ç½®é¡¹ç”±éé›¶å€¼è°ƒæ•´ä¸º 0ï¼Œæˆ–è€…ä» 0 è°ƒæ•´ä¸ºéé›¶å€¼ï¼‰ |
| raftstore.periodic-full-compact-start-max-cpu            | æ§åˆ¶ TiKV æ‰§è¡Œå‘¨æœŸæ€§å…¨é‡æ•°æ®æ•´ç†æ—¶çš„ CPU ä½¿ç”¨ç‡é˜ˆå€¼          |
| readpool.unified.max-thread-count                        | ç»Ÿä¸€å¤„ç†è¯»è¯·æ±‚çš„çº¿ç¨‹æ± æœ€å¤šçš„çº¿ç¨‹æ•°é‡ï¼Œå³ UnifyReadPool çº¿ç¨‹æ± å¤§å° |
| readpool.unified.max-tasks-per-worker                    | ç»Ÿä¸€å¤„ç†è¯»è¯·æ±‚çš„çº¿ç¨‹æ± ä¸­å•ä¸ªçº¿ç¨‹å…è®¸ç§¯å‹çš„æœ€å¤§ä»»åŠ¡æ•°é‡ï¼Œè¶…å‡ºåä¼šè¿”å› Server Is Busyã€‚ |
| readpool.unified.auto-adjust-pool-size                   | æ˜¯å¦å¼€å¯è‡ªé€‚åº”è°ƒæ•´ UnifyReadPool çš„å¤§å°                      |
| resource-control.priority-ctl-strategy                   | é…ç½®ä½ä¼˜å…ˆçº§ä»»åŠ¡çš„æµé‡ç®¡æ§ç­–ç•¥ã€‚                             |
| coprocessor.split-region-on-table                        | å¼€å¯æŒ‰ table åˆ†è£‚ Region çš„å¼€å…³                              |
| coprocessor.batch-split-limit                            | æ‰¹é‡åˆ†è£‚ Region çš„é˜ˆå€¼                                       |
| coprocessor.region-max-size                              | Region å®¹é‡ç©ºé—´çš„æœ€å¤§å€¼                                      |
| coprocessor.region-split-size                            | åˆ†è£‚åæ–° Region çš„å¤§å°                                       |
| coprocessor.region-max-keys                              | Region æœ€å¤šå…è®¸çš„ key çš„ä¸ªæ•°                                 |
| coprocessor.region-split-keys                            | åˆ†è£‚åæ–° Region çš„ key çš„ä¸ªæ•°                                |
| pessimistic-txn.wait-for-lock-timeout                    | æ‚²è§‚äº‹åŠ¡é‡åˆ°é”åçš„æœ€é•¿ç­‰å¾…æ—¶é—´                               |
| pessimistic-txn.wake-up-delay-duration                   | æ‚²è§‚äº‹åŠ¡è¢«é‡æ–°å”¤é†’çš„æ—¶é—´                                     |
| pessimistic-txn.pipelined                                | æ˜¯å¦å¼€å¯æµæ°´çº¿å¼åŠ æ‚²è§‚é”æµç¨‹                                 |
| pessimistic-txn.in-memory                                | æ˜¯å¦å¼€å¯å†…å­˜æ‚²è§‚é”åŠŸèƒ½                                       |
| pessimistic-txn.in-memory-peer-size-limit                | æ§åˆ¶å•ä¸ª Region å†…å­˜æ‚²è§‚é”çš„å†…å­˜ä½¿ç”¨ä¸Šé™                     |
| pessimistic-txn.in-memory-instance-size-limit            | æ§åˆ¶å•ä¸ª TiKV å®ä¾‹å†…å­˜æ‚²è§‚é”çš„å†…å­˜ä½¿ç”¨ä¸Šé™                   |
| quota.foreground-cpu-time                                | é™åˆ¶å¤„ç† TiKV å‰å°è¯»å†™è¯·æ±‚æ‰€ä½¿ç”¨çš„ CPU èµ„æºä½¿ç”¨é‡ï¼Œè½¯é™åˆ¶    |
| quota.foreground-write-bandwidth                         | é™åˆ¶å‰å°äº‹åŠ¡å†™å…¥çš„å¸¦å®½ï¼Œè½¯é™åˆ¶                               |
| quota.foreground-read-bandwidth                          | é™åˆ¶å‰å°äº‹åŠ¡è¯»å–æ•°æ®å’Œ Coprocessor è¯»å–æ•°æ®çš„å¸¦å®½ï¼Œè½¯é™åˆ¶    |
| quota.background-cpu-time                                | é™åˆ¶å¤„ç† TiKV åå°è¯»å†™è¯·æ±‚æ‰€ä½¿ç”¨çš„ CPU èµ„æºä½¿ç”¨é‡ï¼Œè½¯é™åˆ¶    |
| quota.background-write-bandwidth                         | é™åˆ¶åå°äº‹åŠ¡å†™å…¥çš„å¸¦å®½ï¼Œè½¯é™åˆ¶ï¼Œæš‚æœªç”Ÿæ•ˆ                     |
| quota.background-read-bandwidth                          | é™åˆ¶åå°äº‹åŠ¡è¯»å–æ•°æ®å’Œ Coprocessor è¯»å–æ•°æ®çš„å¸¦å®½ï¼Œè½¯é™åˆ¶ï¼Œæš‚æœªç”Ÿæ•ˆ |
| quota.enable-auto-tune                                   | æ˜¯å¦æ”¯æŒ quota åŠ¨æ€è°ƒæ•´ã€‚å¦‚æœæ‰“å¼€è¯¥é…ç½®é¡¹ï¼ŒTiKV ä¼šæ ¹æ® TiKV å®ä¾‹çš„è´Ÿè½½æƒ…å†µåŠ¨æ€è°ƒæ•´å¯¹åå°è¯·æ±‚çš„é™åˆ¶ quota |
| quota.max-delay-duration                                 | å•æ¬¡è¯»å†™è¯·æ±‚è¢«å¼ºåˆ¶ç­‰å¾…çš„æœ€å¤§æ—¶é—´                             |
| gc.ratio-threshold                                       | è·³è¿‡ Region GC çš„é˜ˆå€¼ï¼ˆGC ç‰ˆæœ¬ä¸ªæ•°/key ä¸ªæ•°ï¼‰                |
| gc.batch-keys                                            | ä¸€è½®å¤„ç† key çš„ä¸ªæ•°                                          |
| gc.max-write-bytes-per-sec                               | ä¸€ç§’å¯å†™å…¥ RocksDB çš„æœ€å¤§å­—èŠ‚æ•°                              |
| gc.enable-compaction-filter                              | æ˜¯å¦ä½¿ç”¨ compaction filter                                   |
| gc.compaction-filter-skip-version-check                  | æ˜¯å¦è·³è¿‡ compaction filter çš„é›†ç¾¤ç‰ˆæœ¬æ£€æŸ¥ï¼ˆæœª releaseï¼‰      |
| {db-name}.max-total-wal-size                             | WAL æ€»å¤§å°é™åˆ¶                                               |
| {db-name}.max-background-jobs                            | RocksDB åå°çº¿ç¨‹ä¸ªæ•°                                         |
| {db-name}.max-background-flushes                         | RocksDB flush çº¿ç¨‹ä¸ªæ•°                                       |
| {db-name}.max-open-files                                 | RocksDB å¯ä»¥æ‰“å¼€çš„æ–‡ä»¶æ€»æ•°                                   |
| {db-name}.compaction-readahead-size                      | Compaction æ—¶å€™ readahead çš„å¤§å°                             |
| {db-name}.bytes-per-sync                                 | å¼‚æ­¥åŒæ­¥çš„é™é€Ÿé€Ÿç‡                                           |
| {db-name}.wal-bytes-per-sync                             | WAL åŒæ­¥çš„é™é€Ÿé€Ÿç‡                                           |
| {db-name}.writable-file-max-buffer-size                  | WritableFileWrite æ‰€ä½¿ç”¨çš„æœ€å¤§çš„ buffer å¤§å°                 |
| {db-name}.{cf-name}.block-cache-size                     | block cache size å¤§å°                                        |
| {db-name}.{cf-name}.write-buffer-size                    | memtable å¤§å°                                                |
| {db-name}.{cf-name}.max-write-buffer-number              | æœ€å¤§ memtable ä¸ªæ•°                                           |
| {db-name}.{cf-name}.max-bytes-for-level-base             | base level (L1) æœ€å¤§å­—èŠ‚æ•°                                   |
| {db-name}.{cf-name}.target-file-size-base                | base level çš„ç›®æ ‡æ–‡ä»¶å¤§å°                                    |
| {db-name}.{cf-name}.level0-file-num-compaction-trigger   | è§¦å‘ compaction çš„ L0 æ–‡ä»¶æœ€å¤§ä¸ªæ•°                           |
| {db-name}.{cf-name}.level0-slowdown-writes-trigger       | è§¦å‘ write stall çš„ L0 æ–‡ä»¶æœ€å¤§ä¸ªæ•°                          |
| {db-name}.{cf-name}.level0-stop-writes-trigger           | å®Œå…¨é˜»åœå†™å…¥çš„ L0 æ–‡ä»¶æœ€å¤§ä¸ªæ•°                               |
| {db-name}.{cf-name}.max-compaction-bytes                 | ä¸€æ¬¡ compaction æœ€å¤§å†™å…¥å­—èŠ‚æ•°                               |
| {db-name}.{cf-name}.max-bytes-for-level-multiplier       | æ¯ä¸€å±‚çš„é»˜è®¤æ”¾å¤§å€æ•°                                         |
| {db-name}.{cf-name}.disable-auto-compactions             | è‡ªåŠ¨ compaction çš„å¼€å…³                                       |
| {db-name}.{cf-name}.soft-pending-compaction-bytes-limit  | pending compaction bytes çš„è½¯é™åˆ¶                            |
| {db-name}.{cf-name}.hard-pending-compaction-bytes-limit  | pending compaction bytes çš„ç¡¬é™åˆ¶                            |
| {db-name}.{cf-name}.titan.blob-run-mode                  | å¤„ç† blob æ–‡ä»¶çš„æ¨¡å¼                                         |
| {db-name}.{cf-name}.titan.min-blob-size                  | æ•°æ®å­˜å‚¨åœ¨ Titan çš„é˜ˆå€¼ï¼Œå½“æ•°æ®çš„ value è¾¾åˆ°è¯¥é˜ˆå€¼æ—¶å°†å­˜å‚¨åœ¨ Titan çš„ Blob æ–‡ä»¶ä¸­ |
| {db-name}.{cf-name}.titan.blob-file-compression          | Titan çš„ Blob æ–‡ä»¶æ‰€ä½¿ç”¨çš„å‹ç¼©ç®—æ³•                           |
| {db-name}.{cf-name}.titan.discardable-ratio              | Titan æ•°æ®æ–‡ä»¶ GC çš„åƒåœ¾æ•°æ®æ¯”ä¾‹é˜ˆå€¼ï¼Œå½“ä¸€ä¸ª Blob æ–‡ä»¶ä¸­æ— ç”¨æ•°æ®çš„æ¯”ä¾‹è¶…è¿‡è¯¥é˜ˆå€¼æ—¶å°†ä¼šè§¦å‘ Titan GC |
| server.grpc-memory-pool-quota                            | gRPC å¯ä½¿ç”¨çš„å†…å­˜å¤§å°é™åˆ¶                                    |
| server.max-grpc-send-msg-len                             | gRPC å¯å‘é€çš„æœ€å¤§æ¶ˆæ¯é•¿åº¦                                    |
| server.raft-msg-max-batch-size                           | å•ä¸ª gRPC æ¶ˆæ¯å¯åŒ…å«çš„æœ€å¤§ Raft æ¶ˆæ¯ä¸ªæ•°                     |
| server.simplify-metrics                                  | ç²¾ç®€ç›‘æ§é‡‡æ ·æ•°æ®çš„å¼€å…³                                       |
| server.snap-io-max-bytes-per-sec                         | å¤„ç† snapshot æ—¶æœ€å¤§å…è®¸ä½¿ç”¨çš„ç£ç›˜å¸¦å®½                       |
| server.concurrent-send-snap-limit                        | åŒæ—¶å‘é€ snapshot çš„æœ€å¤§ä¸ªæ•°                                 |
| server.concurrent-recv-snap-limit                        | åŒæ—¶æ¥å— snapshot çš„æœ€å¤§ä¸ªæ•°                                 |
| storage.block-cache.capacity                             | å…±äº« block cache çš„å¤§å°ï¼ˆè‡ª v4.0.3 èµ·æ”¯æŒï¼‰                  |
| storage.flow-control.enable                              | æ˜¯å¦å¼€å¯æµé‡æ§åˆ¶æœºåˆ¶                                         |
| storage.flow-control.memtables-threshold                 | è§¦å‘æµé‡æ§åˆ¶çš„ KvDB memtable æ•°é‡é˜ˆå€¼                        |
| storage.flow-control.l0-files-threshold                  | è§¦å‘æµé‡æ§åˆ¶çš„ KvDB L0 æ–‡ä»¶æ•°é‡é˜ˆå€¼                          |
| storage.flow-control.soft-pending-compaction-bytes-limit | è§¦å‘æµæ§æœºåˆ¶å¼€å§‹æ‹’ç»éƒ¨åˆ†å†™å…¥è¯·æ±‚çš„ KvDB pending compaction bytes é˜ˆå€¼ |
| storage.flow-control.hard-pending-compaction-bytes-limit | è§¦å‘æµæ§æœºåˆ¶æ‹’ç»æ‰€æœ‰æ–°å†™å…¥è¯·æ±‚çš„ KvDB pending compaction bytes é˜ˆå€¼ |
| storage.scheduler-worker-pool-size                       | Scheduler çº¿ç¨‹æ± ä¸­çº¿ç¨‹çš„æ•°é‡                                 |
| import.num-threads                                       | å¤„ç†æ¢å¤æˆ–å¯¼å…¥ RPC è¯·æ±‚çš„çº¿ç¨‹æ•°é‡ï¼ˆè‡ª v8.1.2 èµ·æ”¯æŒåœ¨çº¿ä¿®æ”¹ï¼‰ |
| backup.num-threads                                       | backup çº¿ç¨‹çš„æ•°é‡ï¼ˆè‡ª v4.0.3 èµ·æ”¯æŒï¼‰                        |
| split.qps-threshold                                      | å¯¹ Region æ‰§è¡Œ load-base-split çš„é˜ˆå€¼ã€‚å¦‚æœè¿ç»­ 10s å†…ï¼ŒæŸä¸ª Region çš„è¯»è¯·æ±‚çš„ QPS è¶…è¿‡ qps-thresholdï¼Œåˆ™å°è¯•åˆ‡åˆ†è¯¥ Region |
| split.byte-threshold                                     | å¯¹ Region æ‰§è¡Œ load-base-split çš„é˜ˆå€¼ã€‚å¦‚æœè¿ç»­ 10s å†…ï¼ŒæŸä¸ª Region çš„è¯»è¯·æ±‚çš„æµé‡è¶…è¿‡ byte-thresholdï¼Œåˆ™å°è¯•åˆ‡åˆ†è¯¥ Region |
| split.region-cpu-overload-threshold-ratio                | å¯¹ Region æ‰§è¡Œ load-base-split çš„é˜ˆå€¼ã€‚å¦‚æœè¿ç»­ 10s å†…ï¼ŒæŸä¸ª Region çš„ Unified Read Pool CPU ä½¿ç”¨æ—¶é—´å æ¯”è¶…è¿‡äº† region-cpu-overload-threshold-ratioï¼Œåˆ™å°è¯•åˆ‡åˆ†è¯¥ Regionï¼ˆè‡ª v6.2.0 èµ·æ”¯æŒï¼‰ |
| split.split-balance-score                                | load-base-split çš„æ§åˆ¶å‚æ•°ï¼Œç¡®ä¿ Region åˆ‡åˆ†åå·¦å³è®¿é—®å°½é‡å‡åŒ€ï¼Œæ•°å€¼è¶Šå°è¶Šå‡åŒ€ï¼Œä½†ä¹Ÿå¯èƒ½å¯¼è‡´æ— æ³•åˆ‡åˆ† |
| split.split-contained-score                              | load-base-split çš„æ§åˆ¶å‚æ•°ï¼Œæ•°å€¼è¶Šå°ï¼ŒRegion åˆ‡åˆ†åè·¨ Region çš„è®¿é—®è¶Šå°‘ |
| cdc.min-ts-interval                                      | å®šæœŸæ¨è¿› Resolved TS çš„æ—¶é—´é—´éš”                              |
| cdc.old-value-cache-memory-quota                         | ç¼“å­˜åœ¨å†…å­˜ä¸­çš„ TiCDC Old Value çš„æ¡ç›®å ç”¨å†…å­˜çš„ä¸Šé™          |
| cdc.sink-memory-quota                                    | ç¼“å­˜åœ¨å†…å­˜ä¸­çš„ TiCDC æ•°æ®å˜æ›´äº‹ä»¶å ç”¨å†…å­˜çš„ä¸Šé™              |
| cdc.incremental-scan-speed-limit                         | å¢é‡æ‰«æå†å²æ•°æ®çš„é€Ÿåº¦ä¸Šé™                                   |
| cdc.incremental-scan-concurrency                         | å¢é‡æ‰«æå†å²æ•°æ®ä»»åŠ¡çš„æœ€å¤§å¹¶å‘æ‰§è¡Œä¸ªæ•°                       |

ä¸Šè¿°å‰ç¼€ä¸º `{db-name}` æˆ– `{db-name}.{cf-name}` çš„æ˜¯ RocksDB ç›¸å…³çš„é…ç½®é¡¹ã€‚`db-name` çš„å–å€¼å¯ä¸º `rocksdb` æˆ– `raftdb`ã€‚

- å½“ `db-name` ä¸º `rocksdb` æ—¶ï¼Œ`cf-name` çš„å¯å–å€¼æœ‰ï¼š`defaultcf`ã€`writecf`ã€`lockcf`ã€`raftcf`ï¼›
- å½“ `db-name` ä¸º `raftdb` æ—¶ï¼Œ`cf-name` çš„å¯å–å€¼æœ‰ï¼š`defaultcf`ã€‚

å…·ä½“é…ç½®é¡¹çš„æ„ä¹‰å¯å‚è€ƒ [TiKV é…ç½®æ–‡ä»¶æè¿°](https://docs.pingcap.com/zh/tidb/stable/tikv-configuration-file/)



### åœ¨çº¿ä¿®æ”¹ PD é…ç½®

PD æš‚ä¸æ”¯æŒå•ä¸ªå®ä¾‹æ‹¥æœ‰ç‹¬ç«‹é…ç½®ã€‚æ‰€æœ‰å®ä¾‹å…±äº«ä¸€ä»½é…ç½®ï¼Œå¯ä»¥é€šè¿‡ä¸‹åˆ—æ–¹å¼ä¿®æ”¹ PD çš„é…ç½®é¡¹ï¼š

```sql
set config pd `log.level`='info'
```

è®¾ç½®æˆåŠŸä¼šè¿”å› `Query OK`ï¼š

```sql
Query OK, 0 rows affected (0.01 sec)
```

é’ˆå¯¹ PD å¯åœ¨çº¿ä¿®æ”¹çš„é…ç½®é¡¹ï¼ŒæˆåŠŸä¿®æ”¹ååˆ™ä¼šæŒä¹…åŒ–åˆ° etcd ä¸­ï¼Œä¸ä¼šå¯¹é…ç½®æ–‡ä»¶è¿›è¡ŒæŒä¹…åŒ–ï¼Œåç»­ä»¥ etcd ä¸­çš„é…ç½®ä¸ºå‡†ã€‚åŒä¸Šï¼Œè‹¥å’Œ TiDB é¢„ç•™å…³é”®å­—å†²çªï¼Œéœ€è¦ç”¨åå¼•å· ``` åŒ…è£¹æ­¤ç±»é…ç½®é¡¹ï¼Œä¾‹å¦‚ ``schedule.leader-schedule-limit``ã€‚

æ”¯æŒé…ç½®é¡¹åˆ—è¡¨å¦‚ä¸‹ï¼š

| é…ç½®é¡¹                                   | ç®€ä»‹                                                        |
| :--------------------------------------- | :---------------------------------------------------------- |
| log.level                                | æ—¥å¿—çº§åˆ«                                                    |
| cluster-version                          | é›†ç¾¤çš„ç‰ˆæœ¬                                                  |
| schedule.max-merge-region-size           | æ§åˆ¶ Region Merge çš„ size ä¸Šé™ï¼ˆå•ä½æ˜¯ MiBï¼‰                |
| schedule.max-merge-region-keys           | æ§åˆ¶ Region Merge çš„ key æ•°é‡ä¸Šé™                           |
| schedule.patrol-region-interval          | æ§åˆ¶ checker æ£€æŸ¥ Region å¥åº·çŠ¶æ€çš„è¿è¡Œé¢‘ç‡                 |
| scheduler.patrol-region-worker-count     | æ§åˆ¶ checker æ£€æŸ¥ Region å¥åº·çŠ¶æ€æ—¶ï¼Œåˆ›å»º operator çš„å¹¶å‘æ•° |
| schedule.split-merge-interval            | æ§åˆ¶å¯¹åŒä¸€ä¸ª Region åš split å’Œ merge æ“ä½œçš„é—´éš”            |
| schedule.max-snapshot-count              | æ§åˆ¶å•ä¸ª store æœ€å¤šåŒæ—¶æ¥æ”¶æˆ–å‘é€çš„ snapshot æ•°é‡           |
| schedule.max-pending-peer-count          | æ§åˆ¶å•ä¸ª store çš„ pending peer ä¸Šé™                         |
| schedule.max-store-down-time             | PD è®¤ä¸ºå¤±è” store æ— æ³•æ¢å¤çš„æ—¶é—´                            |
| schedule.leader-schedule-policy          | ç”¨äºæ§åˆ¶ leader è°ƒåº¦çš„ç­–ç•¥                                  |
| schedule.leader-schedule-limit           | å¯ä»¥æ§åˆ¶åŒæ—¶è¿›è¡Œ leader è°ƒåº¦çš„ä»»åŠ¡ä¸ªæ•°                      |
| schedule.region-schedule-limit           | å¯ä»¥æ§åˆ¶åŒæ—¶è¿›è¡Œ Region è°ƒåº¦çš„ä»»åŠ¡ä¸ªæ•°                      |
| schedule.replica-schedule-limit          | å¯ä»¥æ§åˆ¶åŒæ—¶è¿›è¡Œ replica è°ƒåº¦çš„ä»»åŠ¡ä¸ªæ•°                     |
| schedule.merge-schedule-limit            | æ§åˆ¶åŒæ—¶è¿›è¡Œçš„ Region Merge è°ƒåº¦çš„ä»»åŠ¡                      |
| schedule.hot-region-schedule-limit       | å¯ä»¥æ§åˆ¶åŒæ—¶è¿›è¡Œçš„çƒ­ç‚¹è°ƒåº¦çš„ä»»åŠ¡ä¸ªæ•°                        |
| schedule.hot-region-cache-hits-threshold | ç”¨äºè®¾ç½® Region è¢«è§†ä¸ºçƒ­ç‚¹çš„é˜ˆå€¼                            |
| schedule.high-space-ratio                | ç”¨äºè®¾ç½® store ç©ºé—´å……è£•çš„é˜ˆå€¼                               |
| schedule.low-space-ratio                 | ç”¨äºè®¾ç½® store ç©ºé—´ä¸è¶³çš„é˜ˆå€¼                               |
| schedule.tolerant-size-ratio             | æ§åˆ¶ balance ç¼“å†²åŒºå¤§å°                                     |
| schedule.enable-remove-down-replica      | ç”¨äºå¼€å¯è‡ªåŠ¨åˆ é™¤ DownReplica çš„ç‰¹æ€§                         |
| schedule.enable-replace-offline-replica  | ç”¨äºå¼€å¯è¿ç§» OfflineReplica çš„ç‰¹æ€§                          |
| schedule.enable-make-up-replica          | ç”¨äºå¼€å¯è¡¥å……å‰¯æœ¬çš„ç‰¹æ€§                                      |
| schedule.enable-remove-extra-replica     | ç”¨äºå¼€å¯åˆ é™¤å¤šä½™å‰¯æœ¬çš„ç‰¹æ€§                                  |
| schedule.enable-location-replacement     | ç”¨äºå¼€å¯éš”ç¦»çº§åˆ«æ£€æŸ¥                                        |
| schedule.enable-cross-table-merge        | ç”¨äºå¼€å¯è·¨è¡¨ Merge                                          |
| schedule.enable-one-way-merge            | ç”¨äºå¼€å¯å•å‘ Mergeï¼ˆåªå…è®¸å’Œä¸‹ä¸€ä¸ªç›¸é‚»çš„ Region Mergeï¼‰     |
| replication.max-replicas                 | ç”¨äºè®¾ç½®å‰¯æœ¬çš„æ•°é‡                                          |
| replication.location-labels              | ç”¨äºè®¾ç½® TiKV é›†ç¾¤çš„æ‹“æ‰‘ä¿¡æ¯                                |
| replication.enable-placement-rules       | å¼€å¯ Placement Rules                                        |
| replication.strictly-match-label         | å¼€å¯ label æ£€æŸ¥                                             |
| pd-server.use-region-storage             | å¼€å¯ç‹¬ç«‹çš„ Region å­˜å‚¨                                      |
| pd-server.max-gap-reset-ts               | ç”¨äºè®¾ç½®æœ€å¤§çš„é‡ç½® timestamp çš„é—´éš”ï¼ˆBRï¼‰                   |
| pd-server.key-type                       | ç”¨äºè®¾ç½®é›†ç¾¤ key çš„ç±»å‹                                     |
| pd-server.metric-storage                 | ç”¨äºè®¾ç½®é›†ç¾¤ metrics çš„å­˜å‚¨åœ°å€                             |
| pd-server.dashboard-address              | ç”¨äºè®¾ç½® dashboard çš„åœ°å€                                   |
| replication-mode.replication-mode        | å¤‡ä»½çš„æ¨¡å¼                                                  |

å…·ä½“é…ç½®é¡¹æ„ä¹‰å¯å‚è€ƒ [PD é…ç½®æ–‡ä»¶æè¿°](https://docs.pingcap.com/zh/tidb/stable/pd-configuration-file/)ã€‚



### åœ¨çº¿ä¿®æ”¹ TiDB é…ç½®

åœ¨çº¿ä¿®æ”¹ TiDB é…ç½®çš„æ–¹å¼å’Œ TiKV/PD æœ‰æ‰€ä¸åŒï¼Œä½ å¯ä»¥é€šè¿‡ä¿®æ”¹ [ç³»ç»Ÿå˜é‡](https://docs.pingcap.com/zh/tidb/stable/system-variables/) æ¥å®ç°ã€‚

ä¸‹é¢ä¾‹å­å±•ç¤ºäº†å¦‚ä½•é€šè¿‡å˜é‡ `tidb_slow_log_threshold` åœ¨çº¿ä¿®æ”¹é…ç½®é¡¹ `slow-threshold`ã€‚

`slow-threshold` é»˜è®¤å€¼æ˜¯ 300 æ¯«ç§’ï¼Œå¯ä»¥é€šè¿‡è®¾ç½®ç³»ç»Ÿå˜é‡ `tidb_slow_log_threshold` å°†å…¶ä¿®æ”¹ä¸º 200 æ¯«ç§’ï¼š

```sql
set tidb_slow_log_threshold = 200;
Query OK, 0 rows affected (0.00 sec)
select @@tidb_slow_log_threshold;
+---------------------------+
| @@tidb_slow_log_threshold |
+---------------------------+
| 200                       |
+---------------------------+
1 row in set (0.00 sec)
```

æ”¯æŒåœ¨çº¿ä¿®æ”¹çš„é…ç½®é¡¹å’Œç›¸åº”çš„ TiDB ç³»ç»Ÿå˜é‡å¦‚ä¸‹ï¼š

| é…ç½®é¡¹                                                | å¯¹åº”å˜é‡                                   | ç®€ä»‹                                                         |
| :---------------------------------------------------- | :----------------------------------------- | :----------------------------------------------------------- |
| instance.tidb_enable_slow_log                         | tidb_enable_slow_log                       | æ…¢æ—¥å¿—çš„å¼€å…³                                                 |
| instance.tidb_slow_log_threshold                      | tidb_slow_log_threshold                    | æ…¢æ—¥å¿—é˜ˆå€¼                                                   |
| instance.tidb_expensive_query_time_threshold          | tidb_expensive_query_time_threshold        | expensive æŸ¥è¯¢é˜ˆå€¼                                           |
| instance.tidb_enable_collect_execution_info           | tidb_enable_collect_execution_info         | æ§åˆ¶æ˜¯å¦è®°å½•å„ä¸ªç®—å­çš„æ‰§è¡Œä¿¡æ¯                               |
| instance.tidb_record_plan_in_slow_log                 | tidb_record_plan_in_slow_log               | æ§åˆ¶æ˜¯å¦åœ¨æ…¢æ—¥å¿—ä¸­è®°å½•æ‰§è¡Œè®¡åˆ’                               |
| instance.tidb_force_priority                          | tidb_force_priority                        | è¯¥ TiDB å®ä¾‹çš„è¯­å¥ä¼˜å…ˆçº§                                     |
| instance.max_connections                              | max_connections                            | è¯¥ TiDB å®ä¾‹åŒæ—¶å…è®¸çš„æœ€å¤§å®¢æˆ·ç«¯è¿æ¥æ•°                       |
| instance.tidb_enable_ddl                              | tidb_enable_ddl                            | æ§åˆ¶è¯¥ TiDB å®ä¾‹æ˜¯å¦å¯ä»¥æˆä¸º DDL owner                       |
| pessimistic-txn.constraint-check-in-place-pessimistic | tidb_constraint_check_in_place_pessimistic | æ§åˆ¶æ‚²è§‚äº‹åŠ¡ä¸­å”¯ä¸€çº¦æŸæ£€æŸ¥æ˜¯å¦ä¼šè¢«æ¨è¿Ÿåˆ°ä¸‹ä¸€æ¬¡å¯¹è¯¥å”¯ä¸€ç´¢å¼•åŠ é”æ—¶æˆ–äº‹åŠ¡æäº¤æ—¶æ‰è¿›è¡Œ |



### åœ¨çº¿ä¿®æ”¹ TiFlash é…ç½®

ç›®å‰ï¼Œä½ å¯ä»¥é€šè¿‡ä¿®æ”¹ç³»ç»Ÿå˜é‡ [`tidb_max_tiflash_threads`](https://docs.pingcap.com/zh/tidb/stable/system-variables/#tidb_max_tiflash_threads-ä»-v610-ç‰ˆæœ¬å¼€å§‹å¼•å…¥) æ¥åœ¨çº¿ä¿®æ”¹ TiFlash é…ç½®é¡¹ `max_threads`ã€‚`tidb_max_tiflash_threads` è¡¨ç¤º TiFlash ä¸­ request æ‰§è¡Œçš„æœ€å¤§å¹¶å‘åº¦ã€‚

`tidb_max_tiflash_threads` é»˜è®¤å€¼æ˜¯ `-1`ï¼Œè¡¨ç¤ºæ­¤ç³»ç»Ÿå˜é‡æ— æ•ˆï¼Œç”± TiFlash çš„é…ç½®æ–‡ä»¶å†³å®š max_threadsã€‚ä½ å¯ä»¥é€šè¿‡è®¾ç½®ç³»ç»Ÿå˜é‡ `tidb_max_tiflash_threads` å°†å…¶ä¿®æ”¹ä¸º 10ï¼š

```sql
set tidb_max_tiflash_threads = 10;
Query OK, 0 rows affected (0.00 sec)
select @@tidb_max_tiflash_threads;
+----------------------------+
| @@tidb_max_tiflash_threads |
+----------------------------+
| 10                         |
+----------------------------+
1 row in set (0.00 sec)
```



## é›†ç¾¤è¿ç»´

>[å®˜æ–¹å‚è€ƒæ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/maintain-tidb-using-tiup/#tiup-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E6%93%8D%E4%BD%9C)

æœ¬æ–‡ä»‹ç»äº†ä½¿ç”¨ TiUP è¿ç»´ TiDB é›†ç¾¤çš„å¸¸è§æ“ä½œï¼ŒåŒ…æ‹¬æŸ¥çœ‹é›†ç¾¤åˆ—è¡¨ã€å¯åŠ¨é›†ç¾¤ã€æŸ¥çœ‹é›†ç¾¤çŠ¶æ€ã€ä¿®æ”¹é…ç½®å‚æ•°ã€å…³é—­é›†ç¾¤ã€é”€æ¯é›†ç¾¤ç­‰ã€‚

### æŸ¥çœ‹é›†ç¾¤åˆ—è¡¨

TiUP cluster ç»„ä»¶å¯ä»¥ç”¨æ¥ç®¡ç†å¤šä¸ª TiDB é›†ç¾¤ï¼Œåœ¨æ¯ä¸ª TiDB é›†ç¾¤éƒ¨ç½²å®Œæ¯•åï¼Œè¯¥é›†ç¾¤ä¼šå‡ºç°åœ¨ TiUP çš„é›†ç¾¤åˆ—è¡¨é‡Œï¼Œå¯ä»¥ä½¿ç”¨ list å‘½ä»¤æ¥æŸ¥çœ‹ã€‚

```bash
tiup cluster list
```

### å¯åŠ¨é›†ç¾¤

å¯åŠ¨é›†ç¾¤æ“ä½œä¼šæŒ‰ PD -> TiKV -> TiDB -> TiFlash -> TiCDC -> Prometheus -> Grafana -> Alertmanager çš„é¡ºåºå¯åŠ¨æ•´ä¸ª TiDB é›†ç¾¤æ‰€æœ‰ç»„ä»¶ï¼š

```bash
tiup cluster start ${cluster-name}
```

>æ³¨æ„ï¼šä½ éœ€è¦å°† `${cluster-name}` æ›¿æ¢æˆå®é™…çš„é›†ç¾¤åå­—ï¼Œè‹¥å¿˜è®°é›†ç¾¤åå­—ï¼Œå¯é€šè¿‡ `tiup cluster list` æŸ¥çœ‹ã€‚

è¯¥å‘½ä»¤æ”¯æŒé€šè¿‡ `-R` å’Œ `-N` å‚æ•°æ¥åªå¯åŠ¨éƒ¨åˆ†ç»„ä»¶ã€‚

ä¾‹å¦‚ï¼Œä¸‹åˆ—å‘½ä»¤åªå¯åŠ¨ PD ç»„ä»¶ï¼š

```bash
tiup cluster start ${cluster-name} -R pd
```

ä¸‹åˆ—å‘½ä»¤åªå¯åŠ¨ `1.2.3.4` å’Œ `1.2.3.5` è¿™ä¸¤å°æœºå™¨ä¸Šçš„ PD ç»„ä»¶ï¼š

```bash
tiup cluster start ${cluster-name} -N 1.2.3.4:2379,1.2.3.5:2379
```

>æ³¨æ„ï¼šè‹¥é€šè¿‡ `-R` å’Œ `-N` å¯åŠ¨æŒ‡å®šç»„ä»¶ï¼Œéœ€è¦ä¿è¯å¯åŠ¨é¡ºåºæ­£ç¡®ï¼ˆä¾‹å¦‚éœ€è¦å…ˆå¯åŠ¨ PD æ‰èƒ½å¯åŠ¨ TiKVï¼‰ï¼Œå¦åˆ™å¯èƒ½å¯¼è‡´å¯åŠ¨å¤±è´¥ã€‚

### æŸ¥çœ‹é›†ç¾¤çŠ¶æ€

todo

### ä¿®æ”¹é…ç½®å‚æ•°

é›†ç¾¤è¿è¡Œè¿‡ç¨‹ä¸­ï¼Œå¦‚æœéœ€è¦è°ƒæ•´æŸä¸ªç»„ä»¶çš„å‚æ•°ï¼Œå¯ä»¥ä½¿ç”¨ `edit-config` å‘½ä»¤æ¥ç¼–è¾‘å‚æ•°ã€‚å…·ä½“çš„æ“ä½œæ­¥éª¤å¦‚ä¸‹ï¼š

1. ä»¥ç¼–è¾‘æ¨¡å¼æ‰“å¼€è¯¥é›†ç¾¤çš„é…ç½®æ–‡ä»¶ï¼š

   ```bash
   tiup cluster edit-config ${cluster-name}
   ```

2. è®¾ç½®å‚æ•°ï¼š

   é¦–å…ˆç¡®å®šé…ç½®çš„ç”Ÿæ•ˆèŒƒå›´ï¼Œæœ‰ä»¥ä¸‹ä¸¤ç§ç”Ÿæ•ˆèŒƒå›´ï¼š

   - å¦‚æœé…ç½®çš„ç”Ÿæ•ˆèŒƒå›´ä¸ºè¯¥ç»„ä»¶å…¨å±€ï¼Œåˆ™é…ç½®åˆ° `server_configs`ã€‚ä¾‹å¦‚ï¼š

     ```plaintext
     server_configs:
       tidb:
         log.slow-threshold: 300
     ```

   - å¦‚æœé…ç½®çš„ç”Ÿæ•ˆèŒƒå›´ä¸ºæŸä¸ªèŠ‚ç‚¹ï¼Œåˆ™é…ç½®åˆ°å…·ä½“èŠ‚ç‚¹çš„ `config` ä¸­ã€‚ä¾‹å¦‚ï¼š

     ```plaintext
     tidb_servers:
     - host: 10.0.1.11
       port: 4000
       config:
           log.slow-threshold: 300
     ```

   å‚æ•°çš„æ ¼å¼å‚è€ƒ [TiUP é…ç½®å‚æ•°æ¨¡ç‰ˆ](https://github.com/pingcap/tiup/blob/master/embed/examples/cluster/topology.example.yaml)ã€‚

   **é…ç½®é¡¹å±‚æ¬¡ç»“æ„ä½¿ç”¨ `.` è¡¨ç¤º**ã€‚

   å…³äºç»„ä»¶çš„æ›´å¤šé…ç½®å‚æ•°è¯´æ˜ï¼Œå¯å‚è€ƒ [tidb `config.toml.example`](https://github.com/pingcap/tidb/blob/release-8.5/pkg/config/config.toml.example)ã€[tikv `config.toml.example`](https://github.com/tikv/tikv/blob/release-8.5/etc/config-template.toml) å’Œ [pd `config.toml.example`](https://github.com/tikv/pd/blob/release-8.5/conf/config.toml)ã€‚

3. æ‰§è¡Œ `reload` å‘½ä»¤æ»šåŠ¨åˆ†å‘é…ç½®ã€é‡å¯ç›¸åº”ç»„ä»¶ï¼š

   ```bash
   tiup cluster reload ${cluster-name} [-N <nodes>] [-R <roles>]
   ```

#### ç¤ºä¾‹

å¦‚æœè¦è°ƒæ•´ tidb-server ä¸­äº‹åŠ¡å¤§å°é™åˆ¶å‚æ•° `txn-total-size-limit` ä¸º `1G`ï¼Œè¯¥å‚æ•°ä½äº [performance](https://github.com/pingcap/tidb/blob/release-8.5/pkg/config/config.toml.example) æ¨¡å—ä¸‹ï¼Œè°ƒæ•´åçš„é…ç½®å¦‚ä¸‹ï¼š

```plaintext
server_configs:
  tidb:
    performance.txn-total-size-limit: 1073741824
```

ç„¶åæ‰§è¡Œ `tiup cluster reload ${cluster-name} -R tidb` å‘½ä»¤æ»šåŠ¨é‡å¯ã€‚

### Hotfix ç‰ˆæœ¬æ›¿æ¢

å¸¸è§„çš„å‡çº§é›†ç¾¤è¯·å‚è€ƒ[å‡çº§æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/upgrade-tidb-using-tiup/)ï¼Œä½†æ˜¯åœ¨æŸäº›åœºæ™¯ä¸‹ï¼ˆä¾‹å¦‚ Debugï¼‰ï¼Œå¯èƒ½éœ€è¦ç”¨ä¸€ä¸ªä¸´æ—¶çš„åŒ…æ›¿æ¢æ­£åœ¨è¿è¡Œçš„ç»„ä»¶ï¼Œæ­¤æ—¶å¯ä»¥ç”¨ `patch` å‘½ä»¤ï¼š

```bash
tiup cluster patch --help
Replace the remote package with a specified package and restart the service

Usage:
  tiup cluster patch <cluster-name> <package-path> [flags]

Flags:
  -h, --help                   å¸®åŠ©ä¿¡æ¯
  -N, --node strings           æŒ‡å®šè¢«æ›¿æ¢çš„èŠ‚ç‚¹
      --overwrite              åœ¨æœªæ¥çš„ scale-out æ“ä½œä¸­ä½¿ç”¨å½“å‰æŒ‡å®šçš„ä¸´æ—¶åŒ…
  -R, --role strings           æŒ‡å®šè¢«æ›¿æ¢çš„æœåŠ¡ç±»å‹
      --transfer-timeout int   transfer leader çš„è¶…æ—¶æ—¶é—´

Global Flags:
      --native-ssh        ä½¿ç”¨ç³»ç»Ÿé»˜è®¤çš„ SSH å®¢æˆ·ç«¯
      --wait-timeout int  ç­‰å¾…æ“ä½œè¶…æ—¶çš„æ—¶é—´
      --ssh-timeout int   SSH è¿æ¥çš„è¶…æ—¶æ—¶é—´
  -y, --yes               è·³è¿‡æ‰€æœ‰çš„ç¡®è®¤æ­¥éª¤
```

ä¾‹å¦‚ï¼Œæœ‰ä¸€ä¸ª TiDB å®ä¾‹çš„ hotfix åŒ…æ”¾åœ¨ `/tmp/tidb-hotfix.tar.gz` ç›®å½•ä¸‹ã€‚å¦‚æœæ­¤æ—¶æƒ³è¦æ›¿æ¢é›†ç¾¤ä¸Šçš„æ‰€æœ‰ TiDB å®ä¾‹ï¼Œåˆ™å¯ä»¥æ‰§è¡Œä»¥ä¸‹å‘½ä»¤ï¼š

```bash
tiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -R tidb
```

æˆ–è€…åªæ›¿æ¢å…¶ä¸­ä¸€ä¸ª TiDB å®ä¾‹ï¼š

```bash
tiup cluster patch test-cluster /tmp/tidb-hotfix.tar.gz -N 172.16.4.5:4000
```

### åˆ é™¤ TiDBã€TiProxy èŠ‚ç‚¹

>[å‚è€ƒå®˜æ–¹æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/tiup-component-cluster-scale-in/)

æŸ¥çœ‹é›†ç¾¤ test1 èŠ‚ç‚¹

```bash
tiup cluster display test1
```

åˆ é™¤ ID ä¸º `192.168.1.87:4000` çš„ TiDB èŠ‚ç‚¹

```bash
tiup cluster scale-in test1 -N 192.168.1.87:4000
```

åˆ é™¤ ID ä¸º `192.168.1.88:6000` çš„ TiProxy èŠ‚ç‚¹

```bash
tiup cluster scale-in test1 -N 192.168.1.88:6000
```

### æ·»åŠ  TiDB èŠ‚ç‚¹

æŠŠéƒ¨ç½²é›†ç¾¤æ—¶çš„ topology.yaml é…ç½®æ–‡ä»¶ä¸­çš„ globalã€server_configsã€monitored å¤åˆ¶åˆ° add-tidb.yaml é…ç½®æ–‡ä»¶ä¸­ï¼Œä¾‹å¦‚ï¼š

```yaml
# # Global variables are applied to all deployments and used as the default value of
# # the deployments if a specific deployment value is missing.
global:
  # # The user who runs the tidb cluster.
  user: "tidb"
  # # group is used to specify the group name the user belong to if it's not the same as user.
  # group: "tidb"
  # # systemd_mode is used to select whether to use sudo permissions. When its value is set to user, there is no need to add global.user to sudoers. The default value is system.
  # systemd_mode: "system"
  # # SSH port of servers in the managed cluster.
  ssh_port: 22
  # # Storage directory for cluster deployment files, startup scripts, and configuration files.
  deploy_dir: "/tidb-deploy"
  # # TiDB Cluster data storage directory
  data_dir: "/tidb-data"
  # # default listen_host for all components
  listen_host: 0.0.0.0
  # # Supported values: "amd64", "arm64" (default: "amd64")
  arch: "amd64"
  # # Resource Control is used to limit the resource of an instance.
  # # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html
  # # Supports using instance-level `resource_control` to override global `resource_control`.
  # resource_control:
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#MemoryLimit=bytes
  #   memory_limit: "2G"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#CPUQuota=
  #   # The percentage specifies how much CPU time the unit shall get at maximum, relative to the total CPU time available on one CPU. Use values > 100% for allotting CPU time on more than one CPU.
  #   # Example: CPUQuota=200% ensures that the executed processes will never get more than two CPU time.
  #   cpu_quota: "200%"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#IOReadBandwidthMax=device%20bytes
  #   io_read_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"
  #   io_write_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"

server_configs:
  tidb:
    log.level: "error"
    graceful-wait-before-shutdown: 15
  tikv:
    log-level: "error"
  pd:
    log-level: "error"

# # Monitored variables are applied to all the machines.
monitored:
  # # The communication port for reporting system information of each node in the TiDB cluster.
  node_exporter_port: 9100
  # # Blackbox_exporter communication port, used for TiDB cluster port monitoring.
  blackbox_exporter_port: 9115
  # # Storage directory for deployment files, startup scripts, and configuration files of monitoring components.
  # deploy_dir: "/tidb-deploy/monitored-9100"
  # # Data storage directory of monitoring components.
  # data_dir: "/tidb-data/monitored-9100"
  # # Log storage directory of the monitoring component.
  # log_dir: "/tidb-deploy/monitored-9100/log"

# # Server configs are used to specify the runtime configuration of TiDB components.
# # All configuration items can be found in TiDB docs:
# # - TiDB: https://docs.pingcap.com/tidb/stable/tidb-configuration-file
# # - TiKV: https://docs.pingcap.com/tidb/stable/tikv-configuration-file
# # - PD: https://docs.pingcap.com/tidb/stable/pd-configuration-file
# # - TiFlash: https://docs.pingcap.com/tidb/stable/tiflash-configuration
# #
# # All configuration items use points to represent the hierarchy, e.g:
# #   readpool.storage.use-unified-pool
# #           ^       ^
# # - example: https://github.com/pingcap/tiup/blob/master/examples/topology.example.yaml.
# # You can overwrite this configuration via the instance-level `config` field.
# server_configs:
  # tidb:
  # tikv:
  # pd:
  # tiflash:
  # tiflash-learner:
  #
  #
```

åœ¨ add-tidb.yaml é…ç½®æ–‡ä»¶ä¸­å†è¿½åŠ æ–°çš„ TiDB èŠ‚ç‚¹ä¿¡æ¯

```yaml
# # Server configs are used to specify the configuration of TiDB Servers.
tidb_servers:
  # # The ip address of the TiDB Server.
  - host: 192.168.1.87
    # # SSH port of the server.
    # ssh_port: 22
    # # The port for clients to access the TiDB cluster.
    # port: 4000
    # # TiDB Server status API port.
    # status_port: 10080
    # # TiDB Server deployment file, startup script, configuration file storage directory.
    # deploy_dir: "/tidb-deploy/tidb-4000"
    # # TiDB Server log file storage directory.
    # log_dir: "/tidb-deploy/tidb-4000/log"
```

ä½¿ç”¨ scale-out å‘½ä»¤éƒ¨ç½² TiDB æ–°èŠ‚ç‚¹

```bash
tiup cluster scale-out test1 add-tidb.yaml -uroot -p
```

### æ·»åŠ  TiProxy èŠ‚ç‚¹

>[å‚è€ƒå®˜æ–¹æ–‡æ¡£](https://docs.pingcap.com/zh/tidb/stable/tiproxy-overview/#%E4%B8%BA%E5%B7%B2%E6%9C%89%E9%9B%86%E7%BE%A4%E5%90%AF%E7%94%A8-tiproxy)

æŠŠéƒ¨ç½²é›†ç¾¤æ—¶çš„ topology.yaml é…ç½®æ–‡ä»¶ä¸­çš„ globalã€server_configsã€monitored å¤åˆ¶åˆ° add-tiproxy.yaml é…ç½®æ–‡ä»¶ä¸­ï¼Œä¾‹å¦‚ï¼š

```yaml
# # Global variables are applied to all deployments and used as the default value of
# # the deployments if a specific deployment value is missing.
global:
  # # The user who runs the tidb cluster.
  user: "tidb"
  # # group is used to specify the group name the user belong to if it's not the same as user.
  # group: "tidb"
  # # systemd_mode is used to select whether to use sudo permissions. When its value is set to user, there is no need to add global.user to sudoers. The default value is system.
  # systemd_mode: "system"
  # # SSH port of servers in the managed cluster.
  ssh_port: 22
  # # Storage directory for cluster deployment files, startup scripts, and configuration files.
  deploy_dir: "/tidb-deploy"
  # # TiDB Cluster data storage directory
  data_dir: "/tidb-data"
  # # default listen_host for all components
  listen_host: 0.0.0.0
  # # Supported values: "amd64", "arm64" (default: "amd64")
  arch: "amd64"
  # # Resource Control is used to limit the resource of an instance.
  # # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html
  # # Supports using instance-level `resource_control` to override global `resource_control`.
  # resource_control:
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#MemoryLimit=bytes
  #   memory_limit: "2G"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#CPUQuota=
  #   # The percentage specifies how much CPU time the unit shall get at maximum, relative to the total CPU time available on one CPU. Use values > 100% for allotting CPU time on more than one CPU.
  #   # Example: CPUQuota=200% ensures that the executed processes will never get more than two CPU time.
  #   cpu_quota: "200%"
  #   # See: https://www.freedesktop.org/software/systemd/man/systemd.resource-control.html#IOReadBandwidthMax=device%20bytes
  #   io_read_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"
  #   io_write_bandwidth_max: "/dev/disk/by-path/pci-0000:00:1f.2-scsi-0:0:0:0 100M"

server_configs:
  tidb:
    log.level: "error"
    graceful-wait-before-shutdown: 15
  tikv:
    log-level: "error"
  pd:
    log-level: "error"

# # Monitored variables are applied to all the machines.
monitored:
  # # The communication port for reporting system information of each node in the TiDB cluster.
  node_exporter_port: 9100
  # # Blackbox_exporter communication port, used for TiDB cluster port monitoring.
  blackbox_exporter_port: 9115
  # # Storage directory for deployment files, startup scripts, and configuration files of monitoring components.
  # deploy_dir: "/tidb-deploy/monitored-9100"
  # # Data storage directory of monitoring components.
  # data_dir: "/tidb-data/monitored-9100"
  # # Log storage directory of the monitoring component.
  # log_dir: "/tidb-deploy/monitored-9100/log"

# # Server configs are used to specify the runtime configuration of TiDB components.
# # All configuration items can be found in TiDB docs:
# # - TiDB: https://docs.pingcap.com/tidb/stable/tidb-configuration-file
# # - TiKV: https://docs.pingcap.com/tidb/stable/tikv-configuration-file
# # - PD: https://docs.pingcap.com/tidb/stable/pd-configuration-file
# # - TiFlash: https://docs.pingcap.com/tidb/stable/tiflash-configuration
# #
# # All configuration items use points to represent the hierarchy, e.g:
# #   readpool.storage.use-unified-pool
# #           ^       ^
# # - example: https://github.com/pingcap/tiup/blob/master/examples/topology.example.yaml.
# # You can overwrite this configuration via the instance-level `config` field.
# server_configs:
  # tidb:
  # tikv:
  # pd:
  # tiflash:
  # tiflash-learner:
  #
  #
```

åœ¨ add-tiproxy.yaml é…ç½®æ–‡ä»¶ä¸­å†è¿½åŠ æ–°çš„ TiDB èŠ‚ç‚¹ä¿¡æ¯

```yaml
tiproxy_servers:
  - host: 192.168.1.88
    deploy_dir: "/tiproxy-deploy"
    port: 6000
    status_port: 3080
```

ä½¿ç”¨ scale-out å‘½ä»¤éƒ¨ç½² TiProxy æ–°èŠ‚ç‚¹

```bash
tiup cluster scale-out test1 add-tiproxy.yaml -uroot -p
```

### é‡å‘½åé›†ç¾¤

éƒ¨ç½²å¹¶å¯åŠ¨é›†ç¾¤åï¼Œå¯ä»¥é€šè¿‡ `tiup cluster rename` å‘½ä»¤æ¥å¯¹é›†ç¾¤é‡å‘½åï¼š

```bash
tiup cluster rename ${cluster-name} ${new-name}
```

>æ³¨æ„
>
>- é‡å‘½åé›†ç¾¤ä¼šé‡å¯ç›‘æ§ï¼ˆPrometheus å’Œ Grafanaï¼‰ã€‚
>- é‡å‘½åé›†ç¾¤ä¹‹å Grafana å¯èƒ½ä¼šæ®‹ç•™ä¸€äº›æ—§é›†ç¾¤åçš„é¢æ¿ï¼Œéœ€è¦æ‰‹åŠ¨åˆ é™¤è¿™äº›é¢æ¿ã€‚

### å…³é—­é›†ç¾¤

å…³é—­é›†ç¾¤æ“ä½œä¼šæŒ‰ Alertmanager -> Grafana -> Prometheus -> TiCDC -> TiFlash -> TiDB -> TiKV -> PD çš„é¡ºåºå…³é—­æ•´ä¸ª TiDB é›†ç¾¤æ‰€æœ‰ç»„ä»¶ï¼ˆåŒæ—¶ä¹Ÿä¼šå…³é—­ç›‘æ§ç»„ä»¶ï¼‰ï¼š

```bash
tiup cluster stop ${cluster-name}
```

å’Œ `start` å‘½ä»¤ç±»ä¼¼ï¼Œ`stop` å‘½ä»¤ä¹Ÿæ”¯æŒé€šè¿‡ `-R` å’Œ `-N` å‚æ•°æ¥åªåœæ­¢éƒ¨åˆ†ç»„ä»¶ã€‚

ä¾‹å¦‚ï¼Œä¸‹åˆ—å‘½ä»¤åªåœæ­¢ TiDB ç»„ä»¶ï¼š

```bash
tiup cluster stop ${cluster-name} -R tidb
```

ä¸‹åˆ—å‘½ä»¤åªåœæ­¢ `1.2.3.4` å’Œ `1.2.3.5` è¿™ä¸¤å°æœºå™¨ä¸Šçš„ TiDB ç»„ä»¶ï¼š

```bash
tiup cluster stop ${cluster-name} -N 1.2.3.4:4000,1.2.3.5:4000
```

### æ¸…é™¤é›†ç¾¤æ•°æ®

æ­¤æ“ä½œä¼šå…³é—­æ‰€æœ‰æœåŠ¡ï¼Œå¹¶æ¸…ç©ºå…¶æ•°æ®ç›®å½•æˆ–/å’Œæ—¥å¿—ç›®å½•ï¼Œå¹¶ä¸”æ— æ³•æ¢å¤ï¼Œéœ€è¦**è°¨æ…æ“ä½œ**ã€‚

æ¸…ç©ºé›†ç¾¤æ‰€æœ‰æœåŠ¡çš„æ•°æ®ï¼Œä½†ä¿ç•™æ—¥å¿—ï¼š

```bash
tiup cluster clean ${cluster-name} --data
```

æ¸…ç©ºé›†ç¾¤æ‰€æœ‰æœåŠ¡çš„æ—¥å¿—ï¼Œä½†ä¿ç•™æ•°æ®ï¼š

```bash
tiup cluster clean ${cluster-name} --log
```

æ¸…ç©ºé›†ç¾¤æ‰€æœ‰æœåŠ¡çš„æ•°æ®å’Œæ—¥å¿—ï¼š

```bash
tiup cluster clean ${cluster-name} --all
```

æ¸…ç©º Prometheus ä»¥å¤–çš„æ‰€æœ‰æœåŠ¡çš„æ—¥å¿—å’Œæ•°æ®ï¼š

```bash
tiup cluster clean ${cluster-name} --all --ignore-role prometheus
```

æ¸…ç©ºèŠ‚ç‚¹ `172.16.13.11:9000` ä»¥å¤–çš„æ‰€æœ‰æœåŠ¡çš„æ—¥å¿—å’Œæ•°æ®ï¼š

```bash
tiup cluster clean ${cluster-name} --all --ignore-node 172.16.13.11:9000
```

æ¸…ç©ºéƒ¨ç½²åœ¨ `172.16.13.12` ä»¥å¤–çš„æ‰€æœ‰æœåŠ¡çš„æ—¥å¿—å’Œæ•°æ®ï¼š

```bash
tiup cluster clean ${cluster-name} --all --ignore-node 172.16.13.12
```

### é”€æ¯é›†ç¾¤

é”€æ¯é›†ç¾¤æ“ä½œä¼šå…³é—­æœåŠ¡ï¼Œæ¸…ç©ºæ•°æ®ç›®å½•å’Œéƒ¨ç½²ç›®å½•ï¼Œå¹¶ä¸”æ— æ³•æ¢å¤ï¼Œéœ€è¦**è°¨æ…æ“ä½œ**ã€‚

```bash
tiup cluster destroy ${cluster-name}
```



### æ‰©ç¼©å®¹

TiDB é›†ç¾¤å¯ä»¥åœ¨ä¸ä¸­æ–­çº¿ä¸ŠæœåŠ¡çš„æƒ…å†µä¸‹è¿›è¡Œæ‰©å®¹å’Œç¼©å®¹ã€‚

æœ¬æ–‡ä»‹ç»å¦‚ä½•ä½¿ç”¨ TiUP æ‰©å®¹ç¼©å®¹é›†ç¾¤ä¸­çš„ TiDBã€TiKVã€PDã€TiCDC æˆ–è€… TiFlash èŠ‚ç‚¹ã€‚

ä½ å¯ä»¥é€šè¿‡ `tiup cluster list` æŸ¥çœ‹å½“å‰çš„é›†ç¾¤åç§°åˆ—è¡¨ã€‚

#### æ‰©å®¹ TiDB/PD/TiKV èŠ‚ç‚¹

å¦‚æœè¦æ·»åŠ ä¸€ä¸ª TiDB èŠ‚ç‚¹ï¼ŒIP åœ°å€ä¸º 10.0.1.5ï¼Œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ­¥éª¤è¿›è¡Œæ“ä½œã€‚

>æ³¨æ„ï¼šæ·»åŠ  PD èŠ‚ç‚¹å’Œæ·»åŠ  TiDB èŠ‚ç‚¹çš„æ­¥éª¤ç±»ä¼¼ã€‚æ·»åŠ  TiKV èŠ‚ç‚¹å‰ï¼Œå»ºè®®é¢„å…ˆæ ¹æ®é›†ç¾¤çš„è´Ÿè½½æƒ…å†µè°ƒæ•´ PD è°ƒåº¦å‚æ•°ã€‚

1. ç¼–å†™æ‰©å®¹æ‹“æ‰‘é…ç½®

   >æ³¨æ„
   >
   >- é»˜è®¤æƒ…å†µä¸‹ï¼Œå¯ä»¥ä¸å¡«å†™ç«¯å£ä»¥åŠç›®å½•ä¿¡æ¯ã€‚ä½†åœ¨å•æœºå¤šå®ä¾‹åœºæ™¯ä¸‹ï¼Œåˆ™éœ€è¦åˆ†é…ä¸åŒçš„ç«¯å£ä»¥åŠç›®å½•ï¼Œå¦‚æœæœ‰ç«¯å£æˆ–ç›®å½•å†²çªï¼Œä¼šåœ¨éƒ¨ç½²æˆ–æ‰©å®¹æ—¶æé†’ã€‚
   >- ä» TiUP v1.0.0 å¼€å§‹ï¼Œæ‰©å®¹é…ç½®ä¼šç»§æ‰¿åŸé›†ç¾¤é…ç½®çš„ global éƒ¨åˆ†ã€‚

   åœ¨ scale-out.yml æ–‡ä»¶æ·»åŠ æ‰©å®¹æ‹“æ‰‘é…ç½®ï¼š

   TiDB é…ç½®æ–‡ä»¶å‚è€ƒï¼š

   ```yaml
   tidb_servers:
     - host: 10.0.1.5
       ssh_port: 22
       port: 4000
       status_port: 10080
       deploy_dir: /tidb-deploy/tidb-4000
       log_dir: /tidb-deploy/tidb-4000/log
   ```

   TiKV é…ç½®æ–‡ä»¶å‚è€ƒï¼š

   ```yaml
   tikv_servers:
     - host: 10.0.1.5
       ssh_port: 22
       port: 20160
       status_port: 20180
       deploy_dir: /tidb-deploy/tikv-20160
       data_dir: /tidb-data/tikv-20160
       log_dir: /tidb-deploy/tikv-20160/log
   ```

   PD é…ç½®æ–‡ä»¶å‚è€ƒï¼š

   ```ini
   pd_servers:
     - host: 10.0.1.5
       ssh_port: 22
       name: pd-1
       client_port: 2379
       peer_port: 2380
       deploy_dir: /tidb-deploy/pd-2379
       data_dir: /tidb-data/pd-2379
       log_dir: /tidb-deploy/pd-2379/log
   ```

   å¯ä»¥ä½¿ç”¨ `tiup cluster edit-config <cluster-name>` æŸ¥çœ‹å½“å‰é›†ç¾¤çš„é…ç½®ä¿¡æ¯ï¼Œå› ä¸ºå…¶ä¸­çš„ `global` å’Œ `server_configs` å‚æ•°é…ç½®é»˜è®¤ä¼šè¢« `scale-out.yml` ç»§æ‰¿ï¼Œå› æ­¤ä¹Ÿä¼šåœ¨ `scale-out.yml` ä¸­ç”Ÿæ•ˆã€‚

2. æ‰§è¡Œæ‰©å®¹å‘½ä»¤

   æ‰§è¡Œ scale-out å‘½ä»¤å‰ï¼Œå…ˆä½¿ç”¨ `check` åŠ `check --apply` å‘½ä»¤ï¼Œæ£€æŸ¥å’Œè‡ªåŠ¨ä¿®å¤é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

   >æ³¨æ„ï¼šé’ˆå¯¹ scale-out å‘½ä»¤çš„æ£€æŸ¥åŠŸèƒ½åœ¨ tiup cluster v1.9.3 åŠåç»­ç‰ˆæœ¬ä¸­æ”¯æŒï¼Œè¯·æ“ä½œå‰å…ˆå‡çº§ tiup cluster ç‰ˆæœ¬ã€‚

   ï¼ˆ1ï¼‰æ£€æŸ¥é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

   ```sh
   tiup cluster check <cluster-name> scale-out.yml --cluster --user root [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

   ï¼ˆ2ï¼‰è‡ªåŠ¨ä¿®å¤é›†ç¾¤å­˜åœ¨çš„æ½œåœ¨é£é™©ï¼š

   ```sh
   tiup cluster check <cluster-name> scale-out.yml --cluster --apply --user root [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

   ï¼ˆ3ï¼‰æ‰§è¡Œ scale-out å‘½ä»¤æ‰©å®¹ TiDB é›†ç¾¤ï¼š

   ```sh
   tiup cluster scale-out <cluster-name> scale-out.yml [-p] [-i /home/root/.ssh/gcp_rsa]
   ```

   ä»¥ä¸Šæ“ä½œç¤ºä¾‹ä¸­ï¼š

   - æ‰©å®¹é…ç½®æ–‡ä»¶ä¸º `scale-out.yml`ã€‚
   - `--user root` è¡¨ç¤ºé€šè¿‡ root ç”¨æˆ·ç™»å½•åˆ°ç›®æ ‡ä¸»æœºå®Œæˆé›†ç¾¤éƒ¨ç½²ï¼Œè¯¥ç”¨æˆ·éœ€è¦æœ‰ ssh åˆ°ç›®æ ‡æœºå™¨çš„æƒé™ï¼Œå¹¶ä¸”åœ¨ç›®æ ‡æœºå™¨æœ‰ sudo æƒé™ã€‚ä¹Ÿå¯ä»¥ç”¨å…¶ä»–æœ‰ ssh å’Œ sudo æƒé™çš„ç”¨æˆ·å®Œæˆéƒ¨ç½²ã€‚
   - [-i] åŠ [-p] ä¸ºå¯é€‰é¡¹ï¼Œå¦‚æœå·²ç»é…ç½®å…å¯†ç™»å½•ç›®æ ‡æœºï¼Œåˆ™ä¸éœ€å¡«å†™ã€‚å¦åˆ™é€‰æ‹©å…¶ä¸€å³å¯ï¼Œ[-i] ä¸ºå¯ç™»å½•åˆ°ç›®æ ‡æœºçš„ root ç”¨æˆ·ï¼ˆæˆ– --user æŒ‡å®šçš„å…¶ä»–ç”¨æˆ·ï¼‰çš„ç§é’¥ï¼Œä¹Ÿå¯ä½¿ç”¨ [-p] äº¤äº’å¼è¾“å…¥è¯¥ç”¨æˆ·çš„å¯†ç ã€‚

   é¢„æœŸæ—¥å¿—ç»“å°¾è¾“å‡º `Scaled cluster `<cluster-name>` out successfully` ä¿¡æ¯ï¼Œè¡¨ç¤ºæ‰©å®¹æ“ä½œæˆåŠŸã€‚

3. åˆ·æ–°é›†ç¾¤é…ç½®

   >æ³¨æ„
   >
   >- åˆ·æ–°é›†ç¾¤é…ç½®ä»…é€‚ç”¨äºæ‰©å®¹ PD èŠ‚ç‚¹ï¼Œæ‰©å®¹ TiDB æˆ– TiKV èŠ‚ç‚¹æ—¶æ— éœ€æ‰§è¡Œæ­¤æ“ä½œã€‚
   >- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ TiUP v1.15.0 æˆ–ä¹‹åç‰ˆæœ¬ï¼Œè¯·è·³è¿‡è¯¥æ“ä½œï¼Œå› ä¸º TiUP ä¼šå®Œæˆç›¸åº”æ“ä½œï¼›å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ TiUP v1.15.0 ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œåˆ™éœ€æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚

   ï¼ˆ1ï¼‰æ›´æ–°é›†ç¾¤é…ç½®ï¼š

   ```sh
   tiup cluster reload <cluster-name> --skip-restart
   ```

   ï¼ˆ2ï¼‰æ›´æ–° Prometheus é…ç½®å¹¶é‡å¯ï¼š

   ```sh
   tiup cluster reload <cluster-name> -R prometheus
   ```

4. æŸ¥çœ‹é›†ç¾¤çŠ¶æ€

   ```sh
   tiup cluster display <cluster-name>
   ```

   æ‰“å¼€æµè§ˆå™¨è®¿é—®ç›‘æ§å¹³å° [http://10.0.1.5:3000](http://10.0.1.5:3000/)ï¼Œç›‘æ§æ•´ä¸ªé›†ç¾¤å’Œæ–°å¢èŠ‚ç‚¹çš„çŠ¶æ€ã€‚

#### ç¼©å®¹ TiDB/PD/TiKV èŠ‚ç‚¹

å¦‚æœè¦ç§»é™¤ IP åœ°å€ä¸º 10.0.1.5 çš„ä¸€ä¸ª TiKV èŠ‚ç‚¹ï¼Œå¯ä»¥æŒ‰ç…§å¦‚ä¸‹æ­¥éª¤è¿›è¡Œæ“ä½œã€‚

>æ³¨æ„
>
>- ç§»é™¤ TiDBã€PD èŠ‚ç‚¹å’Œç§»é™¤ TiKV èŠ‚ç‚¹çš„æ­¥éª¤ç±»ä¼¼ã€‚
>- ç”±äº TiKV å’Œ TiFlash ç»„ä»¶æ˜¯å¼‚æ­¥ä¸‹çº¿çš„ï¼Œä¸”ä¸‹çº¿è¿‡ç¨‹è€—æ—¶è¾ƒé•¿ï¼Œæ‰€ä»¥ TiUP å¯¹ TiKV å’Œ TiFlash ç»„ä»¶åšäº†ç‰¹æ®Šå¤„ç†ï¼Œè¯¦æƒ…å‚è€ƒ [ä¸‹çº¿ç‰¹æ®Šå¤„ç†](https://docs.pingcap.com/zh/tidb/stable/tiup-component-cluster-scale-in/#ä¸‹çº¿ç‰¹æ®Šå¤„ç†)ã€‚
>- TiKV ä¸­çš„ PD Client ä¼šç¼“å­˜ PD èŠ‚ç‚¹çš„åˆ—è¡¨ã€‚å½“å‰ç‰ˆæœ¬çš„ TiKV æœ‰å®šæœŸè‡ªåŠ¨æ›´æ–° PD èŠ‚ç‚¹çš„æœºåˆ¶ï¼Œå¯ä»¥é™ä½ TiKV ç¼“å­˜çš„ PD èŠ‚ç‚¹åˆ—è¡¨è¿‡æ—§è¿™ä¸€é—®é¢˜å‡ºç°çš„æ¦‚ç‡ã€‚ä½†ä½ åº”å°½é‡é¿å…åœ¨æ‰©å®¹æ–° PD åç›´æ¥ä¸€æ¬¡æ€§ç¼©å®¹æ‰€æœ‰æ‰©å®¹å‰å°±å·²ç»å­˜åœ¨çš„ PD èŠ‚ç‚¹ã€‚å¦‚æœéœ€è¦ï¼Œè¯·ç¡®ä¿åœ¨ä¸‹çº¿æ‰€æœ‰ä¹‹å‰å­˜åœ¨çš„ PD èŠ‚ç‚¹å‰å°† PD çš„ leader åˆ‡æ¢è‡³æ–°æ‰©å®¹çš„ PD èŠ‚ç‚¹ã€‚

1. æŸ¥çœ‹èŠ‚ç‚¹ ID ä¿¡æ¯

   ```sh
   tiup cluster display <cluster-name>
   ```

2. æ‰§è¡Œç¼©å®¹æ“ä½œ

   ```sh
   tiup cluster scale-in <cluster-name> --node 10.0.1.5:20160
   ```

   å…¶ä¸­ `--node` å‚æ•°ä¸ºéœ€è¦ä¸‹çº¿èŠ‚ç‚¹çš„ IDã€‚

   é¢„æœŸè¾“å‡º Scaled cluster `<cluster-name>` in successfully ä¿¡æ¯ï¼Œè¡¨ç¤ºç¼©å®¹æ“ä½œæˆåŠŸã€‚

3. åˆ·æ–°é›†ç¾¤é…ç½®

   >æ³¨æ„
   >
   >- åˆ·æ–°é›†ç¾¤é…ç½®ä»…é€‚ç”¨äºç¼©å®¹ PD èŠ‚ç‚¹ï¼Œç¼©å®¹ TiDB æˆ– TiKV èŠ‚ç‚¹æ—¶æ— éœ€æ‰§è¡Œæ­¤æ“ä½œã€‚
   >- å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ TiUP v1.15.0 æˆ–ä¹‹åç‰ˆæœ¬ï¼Œè¯·è·³è¿‡è¯¥æ“ä½œï¼Œå› ä¸º TiUP ä¼šå®Œæˆç›¸åº”æ“ä½œï¼›å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ TiUP v1.15.0 ä¹‹å‰çš„ç‰ˆæœ¬ï¼Œåˆ™éœ€æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ã€‚

   ï¼ˆ1ï¼‰æ›´æ–°é›†ç¾¤é…ç½®ï¼š

   ```sh
   tiup cluster reload <cluster-name> --skip-restart
   ```

   ï¼ˆ2ï¼‰æ›´æ–° Prometheus é…ç½®å¹¶é‡å¯ï¼š

   ```sh
   tiup cluster reload <cluster-name> -R prometheus
   ```

4. æŸ¥çœ‹é›†ç¾¤çŠ¶æ€

   ä¸‹çº¿éœ€è¦ä¸€å®šæ—¶é—´ï¼Œä¸‹çº¿èŠ‚ç‚¹çš„çŠ¶æ€å˜ä¸º Tombstone å°±è¯´æ˜ä¸‹çº¿æˆåŠŸã€‚

   æ‰§è¡Œå¦‚ä¸‹å‘½ä»¤æ£€æŸ¥èŠ‚ç‚¹æ˜¯å¦ä¸‹çº¿æˆåŠŸï¼š

   ```sh
   tiup cluster display <cluster-name>
   ```

   æ‰“å¼€æµè§ˆå™¨è®¿é—®ç›‘æ§å¹³å° [http://10.0.1.5:3000](http://10.0.1.5:3000/)ï¼Œç›‘æ§æ•´ä¸ªé›†ç¾¤çš„çŠ¶æ€ã€‚

5. æ¸…ç† Tombstone èŠ‚ç‚¹

   ç”±äº TiKV å’Œ TiFlash ç»„ä»¶çš„ä¸‹çº¿æ˜¯å¼‚æ­¥çš„ï¼ˆéœ€è¦å…ˆé€šè¿‡ API æ‰§è¡Œç§»é™¤æ“ä½œï¼‰å¹¶ä¸”ä¸‹çº¿è¿‡ç¨‹è€—æ—¶è¾ƒé•¿ï¼ˆéœ€è¦æŒç»­è§‚å¯ŸèŠ‚ç‚¹æ˜¯å¦å·²ç»ä¸‹çº¿æˆåŠŸï¼‰ï¼Œæ‰€ä»¥å¯¹ TiKV å’Œ TiFlash ç»„ä»¶åšäº†ç‰¹æ®Šå¤„ç†ï¼š

   - å¯¹ TiKV å’Œ TiFlash ç»„ä»¶çš„æ“ä½œ
     - tiup-cluster é€šè¿‡ API å°†å…¶ä¸‹çº¿åç›´æ¥é€€å‡ºè€Œä¸ç­‰å¾…ä¸‹çº¿å®Œæˆ
     - æ‰§è¡Œ `tiup cluster display` æŸ¥çœ‹ä¸‹çº¿èŠ‚ç‚¹çš„çŠ¶æ€ï¼Œç­‰å¾…å…¶çŠ¶æ€å˜ä¸º Tombstone
     - æ‰§è¡Œ `tiup cluster prune` å‘½ä»¤æ¸…ç† Tombstone èŠ‚ç‚¹ï¼Œè¯¥å‘½ä»¤ä¼šæ‰§è¡Œä»¥ä¸‹æ“ä½œï¼š
       - åœæ­¢å·²ç»ä¸‹çº¿æ‰çš„èŠ‚ç‚¹çš„æœåŠ¡
       - æ¸…ç†å·²ç»ä¸‹çº¿æ‰çš„èŠ‚ç‚¹çš„ç›¸å…³æ•°æ®æ–‡ä»¶
       - æ›´æ–°é›†ç¾¤çš„æ‹“æ‰‘ï¼Œç§»é™¤å·²ç»ä¸‹çº¿æ‰çš„èŠ‚ç‚¹
   - å¯¹å…¶ä»–ç»„ä»¶çš„æ“ä½œ
     - ä¸‹çº¿ PD ç»„ä»¶æ—¶ï¼Œä¼šé€šè¿‡ API å°†æŒ‡å®šèŠ‚ç‚¹ä»é›†ç¾¤ä¸­åˆ é™¤æ‰ï¼ˆè¿™ä¸ªè¿‡ç¨‹å¾ˆå¿«ï¼‰ï¼Œç„¶ååœæ‰æŒ‡å®š PD çš„æœåŠ¡å¹¶ä¸”æ¸…é™¤è¯¥èŠ‚ç‚¹çš„ç›¸å…³æ•°æ®æ–‡ä»¶
     - ä¸‹çº¿å…¶ä»–ç»„ä»¶æ—¶ï¼Œç›´æ¥åœæ­¢å¹¶ä¸”æ¸…é™¤èŠ‚ç‚¹çš„ç›¸å…³æ•°æ®æ–‡ä»¶



## ä¿®æ”¹ root å¯†ç 

ä½¿ç”¨ MySQL å®¢æˆ·ç«¯è¿æ¥åˆ° TiDB å¹¶ä¿®æ”¹å¯†ç 

```sql
ALTER USER 'root'@'%' IDENTIFIED BY '123456';
FLUSH PRIVILEGES;
```



## tiup å‘½ä»¤



### æŸ¥çœ‹å½“å‰æ”¯æŒéƒ¨ç½²çš„æ‰€æœ‰ TiDB ç‰ˆæœ¬

```bash
tiup list tidb
```



### ä½¿ç”¨ TiUP `client` è¿æ¥ TiDB

```
tiup client
```



### æ¸…ç†æ‰€æœ‰é€šè¿‡ TiUP å®‰è£…çš„ç»„ä»¶åŠå…¶ç›¸å…³æ•°æ®

>å½»åº•åˆ é™¤ TiUP ç®¡ç†çš„æ‰€æœ‰ç»„ä»¶ï¼ˆå¦‚ TiDBã€PDã€TiKVã€TiDB Dashboard ç­‰ï¼‰åŠå…¶è¿è¡Œæ—¶äº§ç”Ÿçš„æ•°æ®ï¼ˆå¦‚æ—¥å¿—ã€ä¸´æ—¶æ–‡ä»¶ç­‰ï¼‰ã€‚

```bash
tiup clean --all
```



## tiup cluster å‘½ä»¤



### éƒ¨ç½²é›†ç¾¤

```bash
tiup cluster deploy <cluster-name> <version> ./topo.yaml --user root -p
```

- å‚æ•° `<cluster-name>` è¡¨ç¤ºè®¾ç½®é›†ç¾¤åç§°
- å‚æ•° `<version>` è¡¨ç¤ºè®¾ç½®é›†ç¾¤ç‰ˆæœ¬ï¼Œä¾‹å¦‚ `v8.5.1`ã€‚å¯ä»¥é€šè¿‡ `tiup list tidb` å‘½ä»¤æ¥æŸ¥çœ‹å½“å‰æ”¯æŒéƒ¨ç½²çš„ TiDB ç‰ˆæœ¬
- å‚æ•° `--user` è¡¨ç¤ºåˆå§‹åŒ–ç¯å¢ƒçš„ç”¨æˆ·
- å‚æ•° `-p` è¡¨ç¤ºåœ¨è¿æ¥ç›®æ ‡æœºå™¨æ—¶ä½¿ç”¨å¯†ç ç™»å½•

>æ³¨æ„ï¼šå¦‚æœä¸»æœºé€šè¿‡å¯†é’¥è¿›è¡Œ SSH è®¤è¯ï¼Œè¯·ä½¿ç”¨ `-i` å‚æ•°æŒ‡å®šå¯†é’¥æ–‡ä»¶è·¯å¾„ï¼Œ`-i` ä¸ `-p` ä¸å¯åŒæ—¶ä½¿ç”¨ã€‚

æŒ‰ç…§å¼•å¯¼ï¼Œè¾“å…¥â€yâ€åŠ root å¯†ç ï¼Œæ¥å®Œæˆéƒ¨ç½²ï¼š

```bash
Do you want to continue? [y/N]:  y
Input SSH password:
```



### å¯åŠ¨é›†ç¾¤

```bash
tiup cluster start <cluster-name>
```



### æ˜¾ç¤ºå·²ç»éƒ¨ç½²çš„é›†ç¾¤åˆ—è¡¨

```bash
tiup cluster list
```



### æŸ¥çœ‹é›†ç¾¤çš„æ‹“æ‰‘ç»“æ„å’ŒçŠ¶æ€

```bash
tiup cluster display <cluster-name>
```



### åœæ­¢é›†ç¾¤

```bash
tiup cluster stop <cluster-name>
```



### åˆ é™¤é›†ç¾¤æ‰€æœ‰æ•°æ®ï¼Œä½†ä¸åˆ é™¤é›†ç¾¤

```bash
tiup cluster clean <cluster-name> --all
```



### åˆ é™¤é›†ç¾¤

```bash
tiup cluster destroy <cluster-name>
```



## åŸºå‡†æµ‹è¯•

### æµ‹è¯•é…ç½®

ä½¿ç”¨è°·æ­Œ GCE E2 å®ä¾‹æµ‹è¯•ã€‚E2 å®ä¾‹é…ç½®å¦‚ä¸‹ï¼š

| **ç»„ä»¶** | **CPU** | **å†…å­˜** | **ç¡¬ç›˜ç±»å‹** | **ç½‘ç»œ**         | **å®ä¾‹æ•°é‡** |
| :------- | :------ | :------- | :----------- | :--------------- | :----------- |
| TiProxy  | 8 æ ¸    | 6 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |
| TiDB     | 8 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 3            |
| PD       | 4 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |
| TiKV     | 8 æ ¸    | 32 GB    | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 3            |
| ç›‘æ§     | 4 æ ¸    | 8 GB     | SSD          | ä¸‡å…†ç½‘å¡ï¼ˆ1 å—ï¼‰ | 1            |



### éƒ¨ç½²

å‚è€ƒæœ¬ç«™ <a href="/tidb/README.html#éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒé›†ç¾¤" target="_blank">é“¾æ¥</a> éƒ¨ç½²é›†ç¾¤ã€‚



