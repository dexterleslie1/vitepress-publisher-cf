# 常见错误



## validation Failed: 1: this action would add [2] total shards, but this cluster currently has [999]/[1000] maximum shards open;

>注意：下面`max_shards_per_node`参数设置方法适用于`elasticsearch7`和`elasticsearch8`。
>
>`https://blog.csdn.net/u011250186/article/details/139882388`

默认`elasticsearch`最大的分片数只有`1000`，并且已经占用了`999`片，但是此时`elasticsearch`创建新索引时还需要`2`个分片。也就是说`elasticsearch`的分片数不够用了。

查看当前默认最大分片数默认为`1000`

```bash
# 使用kibana查询
GET _cluster/settings?include_defaults=true

# 查询max_shards_per_node值默认为1000
```

编辑`/usr/share/elasticsearch/config/elasticsearch.yml`配置文件增加`max_shards_per_node`值为`2000`

```yml
cluster.name: "docker-cluster"
network.host: 0.0.0.0
cluster.max_shards_per_node: 2000
```

再次通过`kibana`查看配置此时`max_shards_per_node`值变为`2000`

```bash
GET _cluster/settings?include_defaults=true
```

详细设置请参考`https://gitee.com/dexterleslie/demonstration/tree/master/elasticsearch/elasticsearch7`



## 访问`kibana`时，提示`"Data too large, data for [<http_request>] would be ..."`错误

错误信息如下：

```json
{"statusCode":500,"error":"Internal Server Error","message":"[parent] Data too large, data for [<http_request>] would be [514390462/490.5mb], which is larger than the limit of [510027366/486.3mb], real usage: [514389880/490.5mb], new bytes reserved: [582/582b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=582/582b, model_inference=0/0b, eql_sequence=0/0b, accounting=10639028/10.1mb]: [circuit_breaking_exception] [parent] Data too large, data for [<http_request>] would be [514390462/490.5mb], which is larger than the limit of [510027366/486.3mb], real usage: [514389880/490.5mb], new bytes reserved: [582/582b], usages [request=0/0b, fielddata=0/0b, in_flight_requests=582/582b, model_inference=0/0b, eql_sequence=0/0b, accounting=10639028/10.1mb], with { bytes_wanted=514390462 & bytes_limit=510027366 & durability=\"PERMANENT\" }"}
```

经过分析，是`GC`回收后都无法释放`elasticsearch jvm`内存导致，解决办法：调整`elasticsearch`内存为`-Xmx1024m`或者更高值
